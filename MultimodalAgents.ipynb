{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQMYCh0JctoJsRpV0mtXlL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prem-cre/Multirag/blob/main/MultimodalAgents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Required Libraries\n",
        "!pip install -qU langchain langchain_groq langchain_huggingface\n",
        "!pip install -qU langchain-community langchain-google-community\n",
        "!pip install -qU tavily-python wikipedia-api beautifulsoup4 requests\n",
        "!pip install -qU tiktoken\n",
        "!pip install -qU lxml[html_clean]\n",
        "!pip install -qU faiss-cpu pypdf tiktoken tavily-python\n",
        "!pip install -qU wikipedia # Added wikipedia package\n",
        "!pip install langchain-google-genai\n"
      ],
      "metadata": {
        "id": "QCFCOahJhYt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_7N01vRtuiK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b56d291-e680-4c1c-c862-e3432a2d8880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All services initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 2: Core Imports and Configuration\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import hashlib\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from dataclasses import field\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from tavily import TavilyClient\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "# Configure API Keys\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_api_key')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('tavily')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = userdata.get('GOOGLE_CSE_ID')\n",
        "\n",
        "# Initialize services\n",
        "# llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0.1)\n",
        "# embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# Initialize Gemini service (hypothetical example)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # 👈 switch from \"gemini-pro\"\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "\n",
        "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "google_search_wrapper = GoogleSearchAPIWrapper(k=7)\n",
        "wikipedia_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_wrapper)\n",
        "\n",
        "print(\"✅ All services initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Data Models for Legal Research\n",
        "\n",
        "class SourceCredibility(Enum):\n",
        "    \"\"\"Credibility levels for sources\"\"\"\n",
        "    OFFICIAL = \"official\"\n",
        "    ACADEMIC = \"academic\"\n",
        "    REPUTABLE = \"reputable\"\n",
        "    GENERAL = \"general\"\n",
        "    UNVERIFIED = \"unverified\"\n",
        "\n",
        "@dataclass\n",
        "class LegalSource:\n",
        "    \"\"\"Represents a legal source with metadata\"\"\"\n",
        "    url: str\n",
        "    title: str\n",
        "    content: str\n",
        "    credibility: SourceCredibility\n",
        "    # date_accessed: datetime = field(default_factory=datetime.now)\n",
        "    # date_published: Optional[str] = None\n",
        "    author: Optional[str] = None\n",
        "    jurisdiction: Optional[str] = None\n",
        "    citation: Optional[str] = None\n",
        "    hash: Optional[str] = None\n",
        "    relevance_score: float = 0.0\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.hash = hashlib.md5(self.content.encode()).hexdigest()[:8]\n",
        "\n",
        "@dataclass\n",
        "class EvidenceItem:\n",
        "    \"\"\"Represents a piece of evidence in the legal research\"\"\"\n",
        "    claim: str\n",
        "    supporting_sources: List[LegalSource]\n",
        "    confidence_score: float\n",
        "    reasoning: str\n",
        "    contradictions: List[Dict[str, Any]] = field(default_factory=list)\n",
        "    verification_status: str = \"pending\"\n",
        "    legal_basis: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class LegalResearchResult:\n",
        "    \"\"\"Complete legal research result with chain of evidence\"\"\"\n",
        "    query: str\n",
        "    summary: str\n",
        "    evidence_chain: List[EvidenceItem]\n",
        "    legal_precedents: List[Dict[str, Any]]\n",
        "    jurisdictional_notes: Dict[str, str]\n",
        "    confidence_assessment: Dict[str, float]\n",
        "    citations: List[str]\n",
        "    # timestamp: datetime = field(default_factory=datetime.now)"
      ],
      "metadata": {
        "id": "Uth_vk2CEZSG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Define Enhanced Research Tools\n",
        "\n",
        "@tool\n",
        "def legal_document_search(query: str, jurisdiction: str = \"Indian\") -> str:\n",
        "    \"\"\"\n",
        "    Search legal documents, cases, and statutes with enhanced Indian law focus.\n",
        "    Returns relevant legal information.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Enhanced search query for Indian legal context\n",
        "        legal_query = f\"{jurisdiction} law legal {query} case judgment statute act\"\n",
        "\n",
        "        results = tavily_client.search(\n",
        "            query=legal_query,\n",
        "            search_depth=\"advanced\",\n",
        "            max_results=8,\n",
        "            include_domains=[\"indiankanoon.org\", \"scconline.com\", \"lawmin.gov.in\", \"legislative.gov.in\"],\n",
        "        )\n",
        "\n",
        "        # Return the raw results directly without formatting or filtering citations\n",
        "        return json.dumps(results.get('results', []), indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error searching legal documents: {str(e)}\"})\n",
        "\n",
        "@tool\n",
        "def google_legal_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Calls Google Search API for specialized legal search focusing on Indian legal databases.\n",
        "    Searches specifically in indiankanoon.org and scconline.com domains.\n",
        "    Returns relevant legal information.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add site restrictions for Indian legal databases\n",
        "        search_query = f\"{query} site:indiankanoon.org OR site:scconline.com\"\n",
        "        search_results = google_search_wrapper.results(search_query, num_results=10)\n",
        "\n",
        "        # Return the raw results directly\n",
        "        return json.dumps(search_results, indent=2)\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Google Search: {str(e)}\"\n",
        "\n",
        "@tool\n",
        "def wikipedia_legal_concepts(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Searches Wikipedia for legal concepts, landmark cases, and constitutional matters.\n",
        "    Provides background information and case summaries.\n",
        "    Returns the raw content.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        wiki_result = wikipedia_tool.invoke(query)\n",
        "\n",
        "        # Return the raw wiki result\n",
        "        return wiki_result\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Wikipedia: {str(e)}\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "@tool\n",
        "def fact_check_legal_claim(claim: str) -> str:\n",
        "    \"\"\"\n",
        "    Comprehensive fact-checking of legal claims with Indian law focus.\n",
        "    Returns detailed verification data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Enhanced queries for Indian legal context\n",
        "        supporting_query = f'\"{claim}\" Indian law legal valid true correct Supreme Court High Court'\n",
        "        contradicting_query = f'\"{claim}\" Indian law legal invalid false incorrect exception limitation'\n",
        "\n",
        "        supporting = tavily_client.search(supporting_query, max_results=6)\n",
        "        contradicting = tavily_client.search(contradicting_query, max_results=4)\n",
        "\n",
        "        # Return the raw search results for supporting and contradicting evidence\n",
        "        result = {\n",
        "            'claim': claim,\n",
        "            'supporting_evidence_raw': supporting.get('results', []),\n",
        "            'contradicting_evidence_raw': contradicting.get('results', []),\n",
        "            'verification_summary': f\"Found {len(supporting.get('results', []))} potential supporting and {len(contradicting.get('results', []))} potential contradicting sources\"\n",
        "        }\n",
        "\n",
        "        return json.dumps(result, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error fact-checking claim: {str(e)}\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "wyRdVy3qPRoG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5491448",
        "outputId": "37d9b312-b729-4908-ddf0-bd538ece23a6"
      },
      "source": [
        "# @title Test Tool Output (Raw) for all Tools\n",
        "\n",
        "# Define test queries relevant to each tool\n",
        "test_queries = {\n",
        "    \"legal_document_search\": \"recent Supreme Court judgment on fundamental rights\",\n",
        "    \"google_legal_search\": \"Maharashtra Rent Control Act 1999\",\n",
        "    \"wikipedia_legal_concepts\": \"Doctrine of Basic Structure Indian Constitution\",\n",
        "    \"verify_legal_citation\": \"AIR 2020 SC 123\", # Example valid citation\n",
        "    \"fact_check_legal_claim\": \"Section 498A IPC is non-bailable\",\n",
        "    # Removed test for extract_legal_precedents\n",
        "}\n",
        "\n",
        "print(\"--- Testing Individual Tool Outputs ---\")\n",
        "print(\"Note: Examining raw output before LLM processing.\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Test legal_document_search tool\n",
        "print(\"\\nTesting legal_document_search...\")\n",
        "query = test_queries[\"legal_document_search\"]\n",
        "print(f\"Query: {query}\")\n",
        "search_output = legal_document_search.invoke(query)\n",
        "print(\"Raw Output:\")\n",
        "print(search_output[:100] + \"...\" if len(search_output) > 1000 else search_output) # Print truncated output for brevity\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Test google_legal_search tool\n",
        "print(\"\\nTesting google_legal_search...\")\n",
        "query = test_queries[\"google_legal_search\"]\n",
        "print(f\"Query: {query}\")\n",
        "google_output = google_legal_search.invoke(query)\n",
        "print(\"Raw Output:\")\n",
        "print(google_output[:100] + \"...\" if len(google_output) > 1000 else google_output)\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Test wikipedia_legal_concepts tool\n",
        "print(\"\\nTesting wikipedia_legal_concepts...\")\n",
        "query = test_queries[\"wikipedia_legal_concepts\"]\n",
        "print(f\"Query: {query}\")\n",
        "wiki_output = wikipedia_legal_concepts.invoke(query)\n",
        "print(\"Raw Output:\")\n",
        "print(wiki_output[:1000] + \"...\" if len(wiki_output) > 1000 else wiki_output)\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "\n",
        "# Test fact_check_legal_claim tool\n",
        "print(\"\\nTesting fact_check_legal_claim...\")\n",
        "claim = test_queries[\"fact_check_legal_claim\"]\n",
        "print(f\"Claim: {claim}\")\n",
        "fact_check_output = fact_check_legal_claim.invoke(claim)\n",
        "print(\"Raw Output:\")\n",
        "print(fact_check_output[:100] + \"...\" if len(fact_check_output) > 1000 else fact_check_output)\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "print(\"\\n--- Individual Tool Testing Complete ---\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Individual Tool Outputs ---\n",
            "Note: Examining raw output before LLM processing.\n",
            "----------------------------------------\n",
            "\n",
            "Testing legal_document_search...\n",
            "Query: recent Supreme Court judgment on fundamental rights\n",
            "Raw Output:\n",
            "[\n",
            "  {\n",
            "    \"url\": \"https://indiankanoon.org/search/?formInput=infringement%20of%20fundamental%20right...\n",
            "--------------------\n",
            "\n",
            "Testing google_legal_search...\n",
            "Query: Maharashtra Rent Control Act 1999\n",
            "Raw Output:\n",
            "[\n",
            "  {\n",
            "    \"title\": \"Section 16 in The Maharashtra Rent Control Act, 1999\",\n",
            "    \"link\": \"https://indi...\n",
            "--------------------\n",
            "\n",
            "Testing wikipedia_legal_concepts...\n",
            "Query: Doctrine of Basic Structure Indian Constitution\n",
            "Raw Output:\n",
            "Page: Basic structure doctrine\n",
            "Summary: The basic structure doctrine is a common law legal doctrine that the constitution of a sovereign state has certain characteristics that cannot be erased by its legislature. The doctrine is recognised in India, Bangladesh, Pakistan, and  Uganda. It was developed by the Supreme Court of India in a series of constitutional law cases in the 1960s and 1970s that culminated in Kesavananda Bharati v. State of Kerala, where the doctrine was formally adopted. Bangladesh is perhaps the only legal system in the world that recognizes this doctrine in an expressed, written and rigid constitutional manner through Article 7B of its Constitution.\n",
            "In Kesavananda Bharati, Justice Hans Raj Khanna propounded that the Constitution of India contains certain basic features that cannot be altered or destroyed through amendments by the Parliament of India. Key among these \"basic features\", as expounded by Justice Khanna, are the fundamental rights guaranteed to individua\n",
            "--------------------\n",
            "\n",
            "Testing fact_check_legal_claim...\n",
            "Claim: Section 498A IPC is non-bailable\n",
            "Raw Output:\n",
            "{\n",
            "  \"claim\": \"Section 498A IPC is non-bailable\",\n",
            "  \"supporting_evidence_raw\": [\n",
            "    {\n",
            "      \"url\": \"...\n",
            "--------------------\n",
            "\n",
            "--- Individual Tool Testing Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Legal Research Agent with Structured Output (Fixed)\n",
        "\n",
        "class EnhancedLegalResearchAgent:\n",
        "    \"\"\"Advanced legal research agent with structured analysis and strong prompting\"\"\"\n",
        "\n",
        "    def __init__(self, llm, tools):\n",
        "        self.llm = llm\n",
        "        self.tools = tools\n",
        "        self.memory = ConversationBufferWindowMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True,\n",
        "            k=10\n",
        "        )\n",
        "\n",
        "        # Get tool names for the prompt\n",
        "        tool_names = [tool.name for tool in tools]\n",
        "        tool_descriptions = \"\\n\".join([f\"- {tool.name}: {tool.description}\" for tool in tools])\n",
        "\n",
        "        # Enhanced comprehensive prompt with structured output requirements\n",
        "        self.prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are an expert Indian legal research assistant with comprehensive knowledge of Indian law, statutes, and legal procedures. You provide thorough, well-structured legal analysis.\n",
        "\n",
        "## YOUR APPROACH TO LEGAL RESEARCH:\n",
        "\n",
        "1. **Query Analysis**: Identify legal issues, applicable laws, jurisdiction, and key legal concepts\n",
        "2. **Comprehensive Research**: Search relevant cases, statutes, acts, and legal documents\n",
        "3. **Source Verification**: Verify credibility and authenticity of all sources\n",
        "4. **Precedent Analysis**: Extract and analyze relevant legal precedents and landmark cases\n",
        "5. **Fact Verification**: Cross-check all legal claims against multiple authoritative sources\n",
        "6. **Evidence Synthesis**: Build a logical chain of evidence with proper legal reasoning\n",
        "7. **Confidence Assessment**: Evaluate the strength and reliability of findings\n",
        "\n",
        "## AVAILABLE TOOLS:\n",
        "{tool_descriptions}\n",
        "\n",
        "You have access to the following tools: {tool_names}\n",
        "\n",
        "## STRUCTURED OUTPUT FORMAT:\n",
        "\n",
        "Your final analysis MUST be structured with these EXACT headings:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 6. CITATIONS AND REFERENCES\n",
        "- Minimum 5-6 authoritative citations\n",
        "- Format: Case name, Citation, Court, Year\n",
        "- Include statutory references\n",
        "- Academic sources (if used)\n",
        "\n",
        "\n",
        "\n",
        "Use the tools systematically to gather comprehensive information before providing your structured analysis.\"\"\"),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"human\", \"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "        ])\n",
        "\n",
        "        # Partial the prompt with tool information\n",
        "        self.prompt = self.prompt.partial(\n",
        "            tool_names=\", \".join(tool_names),\n",
        "            tool_descriptions=tool_descriptions,\n",
        "            tools=tool_descriptions  # For backward compatibility\n",
        "        )\n",
        "\n",
        "        # Create the agent\n",
        "        # Ensure handle_parsing_errors is set to True and return_intermediate_steps is True\n",
        "        self.agent = create_react_agent(\n",
        "            llm=self.llm,\n",
        "            tools=self.tools,\n",
        "            prompt=self.prompt\n",
        "        )\n",
        "\n",
        "        self.executor = AgentExecutor(\n",
        "            agent=self.agent,\n",
        "            tools=self.tools,\n",
        "            memory=self.memory,\n",
        "            verbose=True,\n",
        "            max_iterations=20,\n",
        "            handle_parsing_errors=True, # Keep this\n",
        "            return_intermediate_steps=True # Keep this\n",
        "        )\n",
        "\n",
        "    def research(self, query: str) -> LegalResearchResult:\n",
        "        \"\"\"Conduct comprehensive legal research\"\"\"\n",
        "        try:\n",
        "            # Execute the research\n",
        "            # Pass input as a dictionary\n",
        "            result = self.executor.invoke({\"input\": query})\n",
        "\n",
        "            # Parse and structure the results\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error in legal research: {str(e)}\")\n",
        "            return LegalResearchResult(\n",
        "                query=query,\n",
        "                summary=f\"Error conducting research: {str(e)}\",\n",
        "                evidence_chain=[],\n",
        "                legal_precedents=[],\n",
        "                jurisdictional_notes={},\n",
        "                confidence_assessment={\"overall\": 0.0},\n",
        "                citations=[]\n",
        "            )\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "tq7z6cbsYp2l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Multi-Step Fact-Checking Process with LangChain Chains\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "class EnhancedLegalFactChecker:\n",
        "    \"\"\"Enhanced fact-checking system using LangChain chains\"\"\"\n",
        "\n",
        "    def __init__(self, llm, tools):\n",
        "        self.llm = llm\n",
        "        self.tools = tools\n",
        "\n",
        "        # Create specialized chains for different steps\n",
        "        self._create_analysis_chains()\n",
        "\n",
        "    def _create_analysis_chains(self):\n",
        "        \"\"\"Create LangChain chains for structured analysis\"\"\"\n",
        "\n",
        "        # Chain for initial claim analysis\n",
        "        self.claim_analysis_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"claim\"],\n",
        "                template=\"\"\"Analyze this legal claim in detail:\n",
        "\n",
        "Claim: {claim}\n",
        "\n",
        "Provide a structured analysis with:\n",
        "1. **Main Legal Assertion**: What is the core legal claim?\n",
        "2. **Jurisdiction**: Which legal system/jurisdiction applies?\n",
        "3. **Legal Concepts**: What legal principles are involved?\n",
        "4. **Factual Elements**: What specific facts are claimed?\n",
        "5. **Potential Issues**: Any ambiguities or concerns?\n",
        "\n",
        "Format your response as a detailed legal analysis.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Chain for synthesizing evidence\n",
        "        self.evidence_synthesis_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"evidence\", \"claim\"],\n",
        "                template=\"\"\"Synthesize the following evidence for the legal claim:\n",
        "\n",
        "Claim: {claim}\n",
        "\n",
        "Evidence Found:\n",
        "{evidence}\n",
        "\n",
        "Provide:\n",
        "1. **Strength of Evidence**: How strong is the supporting evidence?\n",
        "2. **Contradictions**: Any conflicting information?\n",
        "3. **Gaps**: What information is missing?\n",
        "4. **Overall Assessment**: Your professional legal opinion\n",
        "\n",
        "Be thorough and cite specific sources.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Chain for final verification report\n",
        "        self.final_report_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"claim\", \"analysis\", \"evidence\", \"confidence\"],\n",
        "                template=\"\"\"Generate a comprehensive legal fact-checking report:\n",
        "\n",
        "**CLAIM UNDER REVIEW**: {claim}\n",
        "\n",
        "**INITIAL ANALYSIS**: {analysis}\n",
        "\n",
        "**EVIDENCE SUMMARY**: {evidence}\n",
        "\n",
        "**CONFIDENCE LEVEL**: {confidence}\n",
        "\n",
        "Structure your report with these sections:\n",
        "\n",
        "## 1. EXECUTIVE SUMMARY\n",
        "- Brief overview of findings\n",
        "- Verification status (Verified/Partially Verified/Unverified/False)\n",
        "\n",
        "## 2. DETAILED LEGAL ANALYSIS\n",
        "- Applicable laws and statutes\n",
        "- Relevant case law\n",
        "- Legal principles involved\n",
        "\n",
        "## 3. EVIDENCE EVALUATION\n",
        "- Supporting evidence strength\n",
        "- Contradicting evidence analysis\n",
        "- Source credibility assessment\n",
        "\n",
        "## 4. LEGAL CITATIONS\n",
        "- List all relevant citations found\n",
        "- Include case names, citations, and years **IMPORTANT MANDATORY**\n",
        "\n",
        "## 5. CONCLUSION AND CONFIDENCE ASSESSMENT\n",
        "- Final determination\n",
        "- Confidence percentage with reasoning\n",
        "- Recommendations for further verification if needed\n",
        "\n",
        "Ensure all citations follow proper legal citation format.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def verify_claim(self, claim: str) -> Dict[str, Any]:\n",
        "        \"\"\"Execute enhanced multi-step fact-checking process\"\"\"\n",
        "        results = {\n",
        "            \"claim\": claim,\n",
        "            \"timestamp\": datetime.now(),\n",
        "            \"steps\": []\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Step 1: Initial Claim Analysis using LangChain\n",
        "            print(\"Step 1: Analyzing claim structure...\")\n",
        "            claim_analysis = self.claim_analysis_chain.run(claim=claim)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"claim_analysis\",\n",
        "                \"output\": claim_analysis,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 2: Fact-check the claim using tool\n",
        "            print(\"Step 2: Fact-checking claim...\")\n",
        "            fact_check_result = fact_check_legal_claim.invoke(claim)\n",
        "            fact_check_data = json.loads(fact_check_result)\n",
        "            print(fact_check_data)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"fact_checking\",\n",
        "                \"output\": fact_check_data,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 3: Verify sources credibility\n",
        "            print(\"Step 3: Verifying source credibility...\")\n",
        "            credible_sources = []\n",
        "            all_sources = (\n",
        "                fact_check_data.get('supporting_evidence', []) +\n",
        "                fact_check_data.get('contradicting_evidence', [])\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"source_verification\",\n",
        "                \"output\": all_sources,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 4: Search for legal precedents\n",
        "            print(\"Step 4: Searching for legal precedents...\")\n",
        "            precedent_search = legal_document_search.invoke(claim, \"Indian\")\n",
        "            precedent_data = json.loads(precedent_search)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"precedent_search\",\n",
        "                \"output\": precedent_data,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 5: Synthesize evidence\n",
        "            print(\"Step 5: Synthesizing evidence...\")\n",
        "            evidence_summary = json.dumps({\n",
        "                \"supporting\": len(fact_check_data.get('supporting_evidence', [])),\n",
        "                \"contradicting\": len(fact_check_data.get('contradicting_evidence', [])),\n",
        "                \"credible_sources\": len([s for s in credible_sources if s.get('trusted', False)]),\n",
        "                \"precedents_found\": len(precedent_data) if isinstance(precedent_data, list) else 0\n",
        "            })\n",
        "\n",
        "            synthesis = self.evidence_synthesis_chain.run(\n",
        "                evidence=evidence_summary,\n",
        "                claim=claim\n",
        "            )\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"evidence_synthesis\",\n",
        "                \"output\": synthesis,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "\n",
        "\n",
        "            # Step 7: Generate final report\n",
        "            print(\"Step 6: Generating final report...\")\n",
        "            final_report = self.final_report_chain.run(\n",
        "                claim=claim,\n",
        "                analysis=claim_analysis,\n",
        "                evidence=synthesis\n",
        "            )\n",
        "\n",
        "            results[\"final_report\"] = final_report\n",
        "            results[\"verification_complete\"] = True\n",
        "\n",
        "        except Exception as e:\n",
        "            results[\"error\"] = str(e)\n",
        "            results[\"verification_complete\"] = False\n",
        "\n",
        "\n",
        "        return results\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "wTcEOx0TF06T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create Summary Chain for Final Output\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "def create_summary_chain(llm):\n",
        "    \"\"\"Create a summarization chain using LangChain's built-in functionality\"\"\"\n",
        "    return load_summarize_chain(\n",
        "        llm,\n",
        "        chain_type=\"map_reduce\",\n",
        "        return_intermediate_steps=True,\n",
        "        map_prompt=PromptTemplate(\n",
        "            template=\"\"\"Summarize the following legal information:\n",
        "{text}\n",
        "\n",
        "Focus on:\n",
        "- Key legal points\n",
        "- Important citations\n",
        "- Relevant precedents\"\"\",\n",
        "            input_variables=[\"text\"]\n",
        "        ),\n",
        "        combine_prompt=PromptTemplate(\n",
        "            template=\"\"\"Combine these legal summaries into a comprehensive overview:\n",
        "{text}\n",
        "\n",
        "Provide:\n",
        "1. Main legal findings\n",
        "2. Critical citations\n",
        "3. Overall conclusion\"\"\",\n",
        "            input_variables=[\"text\"]\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "tA4meJqnHwfa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tools = [\n",
        "    legal_document_search,\n",
        "    google_legal_search,\n",
        "    fact_check_legal_claim,\n",
        "    wikipedia_legal_concepts\n",
        "\n",
        "]\n",
        "\n",
        "# @title Instantiate and Run the Legal Fact-Checker and Research Agent\n",
        "\n",
        "print(\"Initializing Legal Fact-Checker and Research Agent...\")\n",
        "# Re-using the 'llm' and 'all_tools' defined in previous sections\n",
        "fact_checker = EnhancedLegalFactChecker(llm=llm, tools=all_tools)\n",
        "legal_research_agent = EnhancedLegalResearchAgent(llm=llm, tools=all_tools) # Also removed from agent tools\n",
        "print(\"Legal Fact-Checker and Research Agent initialized.\")\n",
        "\n",
        "# --- Define a sample legal claim to fact-check and research ---\n",
        "# Example 1: A claim that is likely true (or easily verifiable)\n",
        "claim_1 = \"In the United States, a contract requires an offer, acceptance, and consideration to be legally binding.\"\n",
        "# Example 2: A more nuanced or potentially disputable claim\n",
        "claim_2 = \"A non-compete clause in an employment contract is generally unenforceable in California if it restricts an employee's ability to practice a lawful profession, trade, or business.\"\n",
        "# Example 3: A claim that might have contradictions or require deeper analysis\n",
        "claim_3 = \"All verbal agreements for real estate sales are unenforceable in all U.S. states.\"\n",
        "# Example 4: Indian Law Claim (matches previous example)\n",
        "claim_4 = \"The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\"\n",
        "\n",
        "\n",
        "# @title Execute Comprehensive Legal Research (using the agent)\n",
        "def execute_legal_research(claim, agent, fact_checker):\n",
        "    \"\"\"Execute comprehensive legal research with structured output\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"🔍 COMPREHENSIVE LEGAL RESEARCH REPORT\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"\\n📋 **CLAIM UNDER EXAMINATION:**\\n{claim}\")\n",
        "    print(\"\\n\" + \"-\"*100)\n",
        "\n",
        "    # Step 1: Fact-checking\n",
        "    print(\"\\n⚖️ **EXECUTING MULTI-STEP FACT-CHECKING PROCESS...**\\n\")\n",
        "    # Use the fact_checker directly for the fact-checking steps\n",
        "    fact_check_result = fact_checker.verify_claim(claim)\n",
        "\n",
        "    # Display fact-checking steps\n",
        "    if fact_check_result.get(\"verification_steps\"):\n",
        "        for i, step in enumerate(fact_check_result[\"verification_steps\"], 1):\n",
        "            step_name = step.get('step', 'Unknown Step').replace(\"_\", \" \").title()\n",
        "            print(f\"\\n📌 Step {i}: {step_name}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            if step.get(\"error\"):\n",
        "                 print(f\"  ❌ Error: {step['error']}\")\n",
        "            elif step.get(\"analysis\"):\n",
        "                # Corrected f-string syntax\n",
        "                analysis_text = step['analysis']\n",
        "                print(f\"  **Analysis:**\\n{analysis_text[:500]}...\" if len(analysis_text) > 500 else analysis_text)\n",
        "            elif step.get(\"sources_found\"):\n",
        "                 data = step[\"sources_found\"]\n",
        "                 print(f\"✓ Supporting Evidence: {len(data.get('supporting_evidence_raw', []))} sources\")\n",
        "                 print(f\"✗ Contradicting Evidence: {len(data.get('contradicting_evidence_raw', []))} sources\")\n",
        "                 print(f\"📊 Initial Confidence: {data.get('verification_summary', 'N/A')}\") # Display summary from tool output\n",
        "            elif step.get(\"credible_sources\"):\n",
        "                 credible = len([s for s in step[\"credible_sources\"] if s.get('trusted', False) or s.get('credibility') in ['official', 'academic', 'reputable']])\n",
        "                 print(f\"🔐 Credible Sources Verified: {credible}/{len(step['credible_sources'])}\")\n",
        "            elif step.get(\"contradictions_found\") is not None:\n",
        "                 print(f\"  **Contradictions Found:** {step['contradictions_found']}\")\n",
        "            elif step.get(\"confidence_score\") is not None:\n",
        "                 print(f\"  **Confidence Score for Step:** {step['confidence_score']:.2%}\")\n",
        "\n",
        "\n",
        "    # Display final confidence score from fact checker\n",
        "    print(f\"\\n\\n🎯 **FINAL FACT-CHECKING CONFIDENCE SCORE: {fact_check_result.get('final_confidence', 0):.2%}**\")\n",
        "\n",
        "    # Step 2: Legal Research (using the agent)\n",
        "    print(\"\\n\\n\" + \"-\"*100)\n",
        "    print(\"📚 **CONDUCTING IN-DEPTH LEGAL RESEARCH (using Agent)...**\\n\")\n",
        "\n",
        "    # The agent will use its tools to perform the research based on the query\n",
        "    research_result = agent.research(claim)\n",
        "\n",
        "    # Display structured legal research output from the agent's final answer\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"📑 **STRUCTURED LEGAL ANALYSIS (from Agent)**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    # Parse and display the structured output from the agent's summary\n",
        "    output_text = research_result.summary\n",
        "\n",
        "    # Extract sections using regex or string parsing (adjust patterns if needed based on agent output)\n",
        "    sections = {\n",
        "        \"1. LEGAL ISSUE IDENTIFICATION\": r\"### 1\\. LEGAL ISSUE IDENTIFICATION(.*?)(?=###|$)\",\n",
        "        \"2. APPLICABLE LAWS AND STATUTES\": r\"### 2\\. APPLICABLE LAWS AND STATUTES(.*?)(?=###|$)\",\n",
        "        \"3. JUDICIAL PRECEDENTS AND CASE LAW\": r\"### 3\\. JUDICIAL PRECEDENTS AND CASE LAW(.*?)(?=###|$)\",\n",
        "        \"4. LEGAL ANALYSIS AND INTERPRETATION\": r\"### 4\\. LEGAL ANALYSIS AND INTERPRETATION(.*?)(?=###|$)\",\n",
        "        \"5. CONCLUSIONS AND RECOMMENDATIONS\": r\"### 5\\. CONCLUSIONS AND RECOMMENDATIONS(.*?)(?=###|$)\",\n",
        "        \"6. CITATIONS AND REFERENCES\": r\"### 6\\. CITATIONS AND REFERENCES(.*?)(?=###|$)\"\n",
        "    }\n",
        "\n",
        "    for section_title, pattern in sections.items():\n",
        "        match = re.search(pattern, output_text, re.DOTALL | re.IGNORECASE)\n",
        "        if match:\n",
        "            print(f\"\\n### {section_title}\")\n",
        "            print(\"-\" * 50)\n",
        "            content = match.group(1).strip()\n",
        "            print(content if content else \"No specific information found for this section.\")\n",
        "        else:\n",
        "            # If structured format not found, display the relevant part of the output\n",
        "            print(f\"\\n### {section_title}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"Could not find section '{section_title}' in agent output. Full output snippet:\")\n",
        "            # Find a relevant snippet around where the section *should* be\n",
        "            snippet_start = output_text.find(section_title) - 100\n",
        "            snippet_end = output_text.find(section_title) + 200\n",
        "            print(output_text[max(0, snippet_start):min(len(output_text), snippet_end)] + \"...\")\n",
        "\n",
        "\n",
        "    # Display citations and evidence sources collected by the agent\n",
        "    print(\"\\n\\n\" + \"=\"*100)\n",
        "    print(\"📖 **LEGAL CITATIONS AND EVIDENCE SOURCES (from Agent)**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    if research_result.citations:\n",
        "        print(\"\\n**Agent-Extracted Citations:**\")\n",
        "        for i, citation in enumerate(research_result.citations[:10], 1):\n",
        "            print(f\"{i}. {citation}\")\n",
        "    else:\n",
        "        print(\"\\nNo specific citations extracted by the agent.\")\n",
        "\n",
        "    if research_result.evidence_chain:\n",
        "        print(\"\\n**Evidence Sources Used by Agent (Sample):**\")\n",
        "        for i, evidence in enumerate(research_result.evidence_chain[:5], 1):\n",
        "            print(f\"\\n{i}. Claim: {evidence.claim}\")\n",
        "            if evidence.supporting_sources:\n",
        "                source = evidence.supporting_sources[0]\n",
        "                print(f\"   Source URL: {source.url}\")\n",
        "                print(f\"   Credibility: {source.credibility.value}\")\n",
        "                print(f\"   Relevance Score: {source.relevance_score:.2f}\")\n",
        "    else:\n",
        "        print(\"\\nNo evidence sources recorded by the agent.\")\n",
        "\n",
        "\n",
        "    # Final assessment summary\n",
        "    print(\"\\n\\n\" + \"=\"*100)\n",
        "    print(\"📊 **FINAL ASSESSMENT SUMMARY**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    # You can combine insights from both fact_check_result and research_result here\n",
        "    print(f\"\\n**Fact-Checking Confidence Level:** {fact_check_result.get('final_confidence', 0):.2%}\")\n",
        "    print(f\"**Agent's Confidence Assessment:** {research_result.confidence_assessment.get('overall', 0):.2%}\")\n",
        "    print(f\"**Agent's Research Completeness:** {research_result.confidence_assessment.get('completeness', 0):.2%}\")\n",
        "    print(f\"**Agent's Source Quality Assessment:** {research_result.confidence_assessment.get('source_quality', 0):.2%}\")\n",
        "\n",
        "    # You could add a final summary generated by an LLM chain here if needed\n",
        "    # Example: final_summary = summary_chain.run(text=research_result.summary + json.dumps(fact_check_result))\n",
        "    # print(\"\\n**Overall Summary:**\\n\", final_summary)\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"claim\": claim,\n",
        "        \"fact_check_result\": fact_check_result,\n",
        "        \"research_result\": research_result\n",
        "    }\n",
        "\n",
        "# @title Run Legal Research on Selected Claim\n",
        "\n",
        "# Select a claim to analyze\n",
        "selected_claim = claim_4  # Using the Indian Law Claim\n",
        "\n",
        "print(\"🏛️ INDIAN LEGAL RESEARCH SYSTEM\")\n",
        "print(\"=\"*100)\n",
        "print(f\"\\n🔍 Analyzing: {selected_claim}\\n\")\n",
        "\n",
        "# Execute the research\n",
        "results = execute_legal_research(selected_claim, legal_research_agent, fact_checker)\n",
        "\n",
        "# @title Additional Analysis Functions using LangChain (Optional)\n",
        "\n",
        "# These functions can be used independently after execute_legal_research\n",
        "# They are not part of the automated execute_legal_research flow above\n",
        "# unless explicitly called within it.\n",
        "\n",
        "# Example: Generate Legal Opinion based on results (requires a summary chain or direct LLM call)\n",
        "# def generate_legal_opinion(llm, claim, research_results):\n",
        "#     \"\"\"Generate a formal legal opinion using LangChain\"\"\"\n",
        "#     # This would need a prompt and potentially structured input from research_results\n",
        "#     pass\n",
        "\n",
        "# Example: Create Citation Formatter (if needed for final presentation)\n",
        "# def format_citations_properly(citations):\n",
        "#     \"\"\"Format legal citations according to Indian legal citation standards\"\"\"\n",
        "#     pass\n",
        "\n",
        "\n",
        "# @title Save Research Results (Optional)\n",
        "\n",
        "def save_research_results(results, filename=\"legal_research_report.json\"):\n",
        "    \"\"\"Save the research results to a JSON file\"\"\"\n",
        "\n",
        "    # Prepare data for JSON serialization - be mindful of complex objects\n",
        "    save_data = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"claim\": results[\"claim\"],\n",
        "        \"fact_checking_confidence\": results[\"fact_check_result\"].get(\"final_confidence\", 0),\n",
        "        \"fact_checking_steps_count\": len(results[\"fact_check_result\"].get(\"verification_steps\", [])),\n",
        "        \"agent_research_summary\": results[\"research_result\"].summary,\n",
        "        \"agent_extracted_citations\": results[\"research_result\"].citations[:10] if results[\"research_result\"].citations else [],\n",
        "        \"agent_evidence_sources_count\": len(results[\"research_result\"].evidence_chain),\n",
        "        \"agent_jurisdictional_notes\": results[\"research_result\"].jurisdictional_notes,\n",
        "        \"agent_confidence_assessment\": results[\"research_result\"].confidence_assessment,\n",
        "        # Potentially include summarized steps from fact_check_result if needed\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(save_data, f, indent=2)\n",
        "        print(f\"\\n✅ Research results summary saved to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error saving research results: {str(e)}\")\n",
        "\n",
        "\n",
        "# Save the results (optional)\n",
        "save_research_results(results)\n",
        "\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*100)\n",
        "print(\"✅ LEGAL RESEARCH AND FACT-CHECKING PROCESS COMPLETE\")\n",
        "print(\"=\"*100)\n",
        "print(\"\\nThe system has executed the legal research and fact-checking process.\")\n",
        "print(\"Review the output above for the detailed report, analysis, and confidence scores.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_QX0KA7GzGn",
        "outputId": "dd752619-c602-4464-b8bf-32c1987f38b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Legal Fact-Checker and Research Agent...\n",
            "Legal Fact-Checker and Research Agent initialized.\n",
            "🏛️ INDIAN LEGAL RESEARCH SYSTEM\n",
            "====================================================================================================\n",
            "\n",
            "🔍 Analyzing: The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "🔍 COMPREHENSIVE LEGAL RESEARCH REPORT\n",
            "====================================================================================================\n",
            "\n",
            "📋 **CLAIM UNDER EXAMINATION:**\n",
            "The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "⚖️ **EXECUTING MULTI-STEP FACT-CHECKING PROCESS...**\n",
            "\n",
            "Step 1: Analyzing claim structure...\n",
            "Step 2: Fact-checking claim...\n",
            "{'claim': 'The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.', 'supporting_evidence_raw': [{'title': '提交表单显示Please verify the CAPTCHA before proceed怎么办？', 'url': 'https://www.zhihu.com/question/640631824', 'content': '提交表单显示Please verify the CAPTCHA before proceed怎么办？ - 知乎 Image 1) \\u200b  提交表单显示Please verify the CAPTCHA before proceed怎么办？ 提交表单显示Please verify the CAPTCHA before proceed怎么办？ 本人因为旅游需要打印电子签证，但是提交后显示Please verify the CAPTCHA before proceed，换了好几个浏览器都一样。…显示全部 \\u200b #### 5 个回答 Image 2: Smile \\u200b 关注 \\u200b赞同 4\\u200b\\u200b1 条评论 \\u200b收藏\\u200b喜欢 Image 3: 苏大戟 \\u200b 关注 Image 5 \\u200b赞同 3\\u200b\\u200b1 条评论 \\u200b收藏\\u200b喜欢 Image 6: 凌君 \\u200b 关注 \\u200b赞同 7\\u200b\\u200b添加评论 \\u200b收藏\\u200b喜欢 收起\\u200b Image 7: QR Code of Downloading Zhihu App 下载知乎客户端 与世界分享知识、经验和见解 Image 8: 广告 如何用一个button实现提交表单+弹框显示表单反馈结果？ 1 个回答 Image 9: 广告 京 ICP 证 110745 号 · 京 ICP 备 13052560 号 - 1 · 京公网安备 11010802020088 号 · 互联网新闻信息服务许可证：11220250001 · [京网文[2022]2674-081 号](https://www.zhihu.com/certificates) · 药品医疗器械网络信息服务备案（京）网药械信息备字（2022）第00334号 · 广播电视节目制作经营许可证:（京）字第06591号 · 互联网宗教信息服务许可证：京（2022）0000078 · 服务热线：400-919-0001 · Investor Relations ·  © 2025 知乎 北京智者天下科技有限公司版权所有 · 违法和不良信息举报：010-82716601 · 举报邮箱：jubao@zhihu.com Image 10: 本站提供适老化无障碍服务 Image 11', 'score': 0.03222541, 'raw_content': None}, {'title': '9 Strategies for Staying Healthy While Working a Desk Job', 'url': 'https://cathe.com/9-strategies-for-staying-healthy-while-working-a-desk-job/', 'content': 'Here are some tips that will help you stay healthy while sitting at a desk all day long: If you’re sitting at a desk all day without getting up every hour for movement breaks, try this. Sitting all day can be tough on your body – make sure you’re sitting in a supportive chair. If your job involves sitting at a desk all day, it’s important to take breaks because extended periods of sedentary behavior are associated with an increased risk for metabolic syndrome (a cluster of conditions including high blood pressure and obesity). Staying well hydrated helps lower the risk of developing blood clots too, a risk if you sit too much. 3 Ways Sitting Less Can Improve Your Work Day and Work Performance', 'score': 0.02074295, 'raw_content': None}, {'title': 'Workout DVD, Fitness DVD, Exercise DVDs and Videos', 'url': 'https://cathe.com/', 'content': \"Take Cathe Everywhere ### Cathe’s STS 2.0 Workout Program # Get Instant Access to Every Cathe Workout Video If you want to access your Cathe Live or OnDemand videos, or the Workout Blender on your browser, you first need to click the orange button below if you are not logged in. We’ve listed all of the links below that you will need to learn how to use and access\\xa0 your Cathe OnDemand and Cathe Live workout videos. * Cathe Workout Rotations #### Cathe's STS 2.0 Muscle & Recovery - 25 Workouts For Only $7.20 each\\\\* #### Cathe 2025 August Workout Rotation #### Cathe’s July 2025 Workout Rotation #### Cathe’s June 2025 Workout Rotation #### Cathe’s May 2025 Workout Rotation\", 'score': 0.018449089, 'raw_content': None}, {'title': 'Journal of the Mechanics and Physics of Solids 在力学界是 ... - 知乎', 'url': 'https://www.zhihu.com/question/26721583', 'content': 'Journal of the Mechanics and Physics of Solids 在力学界是个什么水平的杂志？ - 知乎 Image 1) \\u200b  Journal of the Mechanics and Physics of Solids 在力学界是个什么水平的杂志？ Journal of the Mechanics and Physics of Solids 在力学界是个什么水平的杂志？ 老师跟我们秀优越 ，说发了篇paper在 中国每年只有不到10个 能发的杂志上，想知道这个杂志究竟什么水准？显示全部 \\u200b #### 11 个回答 Image 2: 知乎用户 \\u200b 关注 \\u200b赞同 43\\u200b\\u200b13 条评论 Image 3: 诛纸人 诛纸人 \\u200b 关注 \\u200b赞同 15\\u200b\\u200b1 条评论 Image 4: 知乎用户 知乎用户 JOURNAL OF THE MECHANICS AND PHYSICS OF SOLIDS \\u200b赞同 10\\u200b\\u200b添加评论 Image 5: QR Code of Downloading Zhihu App 下载知乎客户端 与世界分享知识、经验和见解 Image 6: 广告 有什么关于力学前沿的期刊 杂志 论文 公众号 等等？ 5 个回答 流体力学湍流现在国内一般都投什么top期刊？国内有哪些团队还在研究基础理论？ 1 个回答 《力学进展》这本杂志是正儿八经的论文期刊吗？ 2 个回答 Journal of Cosmology and Astroparticle Physics 如何？ 1 个回答 Image 7: 广告 Image 8: 本站提供适老化无障碍服务 Image 9', 'score': 0.017138867, 'raw_content': None}, {'title': 'Walking Upstairs Burns Calories, but Walking Downstairs is Healthy …', 'url': 'https://cathe.com/walking-upstairs-burns-more-calories-but-walking-downstairs-is-healthy-too-heres-why/', 'content': '### The Health Benefits of Going Down a Flight of Stairs During the 12 weeks, one group went either up or downstairs at scheduled times so the researchers could look at the impact each stair taking direction had on metabolic markers of health. Contrary to what you might think, the subjects experienced greater improvements in health markers when they walked down the stairs as opposed to climbing flights of stairs. The subjects who went downstairs also experienced greater improvements in markers of metabolic health relative to those who climbed up the stairs. In fact, the ability to climb a flight of stairs without being too winded is a marker of cardiovascular health. Research shows short exercise breaks, like going up and down the stairs, has health benefits.', 'score': 0.01595695, 'raw_content': None}, {'title': 'sci投稿Declaration of interest怎么写? - 知乎', 'url': 'https://www.zhihu.com/question/497551602', 'content': 'COI/Declaration of Interest forms from all the authors of an article is req… #### 15 个回答 **Declaration of interests** ☒ The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. ☐The authors declare the following financial interests/personal relationships which may be considered as potential competing interests: Declaration of interest是很多作者容易忽视的一点，因为担心利益冲突声明中所披露出的利益关系会影响论文的发表。但对于可能存在的利益冲突隐瞒不报，其实只是埋下了更大隐患。**即使文章成功发表，一旦被发现，将面临论文被撤稿和作者被指控学术不端的双重严重后果。** no other author has reported a potential conflict of interest relevant to this article. All authors disclosed no relevant relationships. 投稿sci后到了required reviews completed 阶段后是一种怎样的心情？ 52 个回答 SCI论文中写Experimental section部分时该如何取舍？ 1 个回答 sci投稿结果是Immediate Reject with Referral，意思时论文写的太差了吗？ 4 个回答 如何写好 SCI 论文的 Introduction 部分？ 17 个回答', 'score': 0.015378678, 'raw_content': None}], 'contradicting_evidence_raw': [{'url': 'https://judgments.ecourts.gov.in/KBJ/?p=home/intro', 'title': 'The Basic Structure Judgment - Home', 'content': 'This led to the landmark Kesavananda Bharati judgment, which upheld the basic structure doctrine and placed limits on the power of the Parliament to amend the Constitution. The case was filed by Sri Kesavananda Bharati, the head of a Hindu religious mutt in Kerala, challenging the constitutional validity of the 24th, 25th and 29th Amendments to the Indian Constitution, which sought to curtail the powers of the judiciary and the fundamental rights of citizens. The Supreme Court, in a historic 7:6 majority decision, propounded the basic structure doctrine of the Constitution, which holds that certain fundamental features of the Constitution, such as democracy, secularism, federalism, and the rule of law, cannot be amended by parliament. The significance of the Kesavananda Bharati case lies in the fact that it established the doctrine of basic structure of the Indian Constitution.', 'score': 0.8467682, 'raw_content': None}, {'url': 'https://vajiramandravi.com/upsc-exam/basic-structure/', 'title': 'Basic Structure Doctrine, Meaning, Significance, Evolution', 'content': \"The Basic Structure Doctrine, established by the Indian judiciary in the 1973 Kesavananda Bharati case, holds that certain fundamental features of the Indian Constitution cannot be amended by Parliament, even under Article 368. The\\\\*\\\\*Basic Structure Doctrine\\\\*\\\\*is a judicial principle in Indian constitutional law that prevents the Parliament from altering the fundamental framework of the Constitution. \\\\* \\\\*\\\\*Kesavananda Bharati vs State of Kerala (1973):\\\\*\\\\*The Court upheld Parliament's amendment power but introduced the basic structure doctrine, limiting amendments that undermine constitutional principles. \\\\* \\\\*\\\\*Minerva Mills vs Union of India (1980):\\\\*\\\\*The Court invalidated parts of the 42nd Amendment, affirming judicial review as integral to the Constitution's basic structure. The\\\\*\\\\*Elements of the Basic Structure Doctrine\\\\*\\\\*are fundamental principles that protect the core of the Constitution, ensuring that its essence remains intact despite amendments.\", 'score': 0.8033131, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Kesavananda_Bharati_v._State_of_Kerala', 'title': 'Kesavananda Bharati v. State of Kerala - Wikipedia', 'content': 'State of Kerala & Anr.** (Writ Petition (Civil) 135 of 1970), also known as the **Kesavananda Bharati judgement**, was a landmark decision of the Supreme Court of India that outlined the basic structure doctrine \"Basic structure doctrine (Constitution of India)\") of the Indian Constitution. State of Punjab*, which held that constitutional amendments through Article 368 were subject to fundamental rights review, but only if they could affect the \\'basic structure of the Constitution\\'. In conclusion, the learned Judge held that though the power of amendment was wide, it did not comprehend the power to totally abrogate or emasculate or damage any of the fundamental rights or the essential elements of the basic structure of the Constitution or to destroy the identity of the Constitution.', 'score': 0.6884899, 'raw_content': None}, {'url': 'https://verfassungsblog.de/50-years-of-kesavananda-bharti/', 'title': '50 Years of Kesavananda Bharti - Verfassungsblog', 'content': 'The basic structure doctrine provides that the power of the legislature to amend the Constitution is not plenary or unlimited. Reversing this position, the *Kesavananda Bharti* court clarified (*see* conclusions of the majority opinions) that while the Parliament may amend every provision of the Constitution, it cannot amend them in a way that would destroy or damage the basic structure of the Constitution. The basic structure doctrine provides a critical external check against the abuse of the power to amend the Constitution. Under the present Indian government, both the ideas of constitutional supremacy and judicial independence are being threatened, thereby inviting a challenge to the appropriateness of the basic structure doctrine. Explore posts related to this: BJP, Indian Constitution, Parliamentary Sovereignty, basic structure doctrine', 'score': 0.6778372, 'raw_content': None}], 'verification_summary': 'Found 6 potential supporting and 4 potential contradicting sources'}\n",
            "Step 3: Verifying source credibility...\n",
            "Step 4: Searching for legal precedents...\n",
            "\n",
            "\n",
            "🎯 **FINAL FACT-CHECKING CONFIDENCE SCORE: 0.00%**\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "📚 **CONDUCTING IN-DEPTH LEGAL RESEARCH (using Agent)...**\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "Error in legal research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>\n",
            "\n",
            "====================================================================================================\n",
            "📑 **STRUCTURED LEGAL ANALYSIS (from Agent)**\n",
            "====================================================================================================\n",
            "\n",
            "### 1. LEGAL ISSUE IDENTIFICATION\n",
            "--------------------------------------------------\n",
            "Could not find section '1. LEGAL ISSUE IDENTIFICATION' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 2. APPLICABLE LAWS AND STATUTES\n",
            "--------------------------------------------------\n",
            "Could not find section '2. APPLICABLE LAWS AND STATUTES' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 3. JUDICIAL PRECEDENTS AND CASE LAW\n",
            "--------------------------------------------------\n",
            "Could not find section '3. JUDICIAL PRECEDENTS AND CASE LAW' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 4. LEGAL ANALYSIS AND INTERPRETATION\n",
            "--------------------------------------------------\n",
            "Could not find section '4. LEGAL ANALYSIS AND INTERPRETATION' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 5. CONCLUSIONS AND RECOMMENDATIONS\n",
            "--------------------------------------------------\n",
            "Could not find section '5. CONCLUSIONS AND RECOMMENDATIONS' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 6. CITATIONS AND REFERENCES\n",
            "--------------------------------------------------\n",
            "Could not find section '6. CITATIONS AND REFERENCES' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "📖 **LEGAL CITATIONS AND EVIDENCE SOURCES (from Agent)**\n",
            "====================================================================================================\n",
            "\n",
            "No specific citations extracted by the agent.\n",
            "\n",
            "No evidence sources recorded by the agent.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "📊 **FINAL ASSESSMENT SUMMARY**\n",
            "====================================================================================================\n",
            "\n",
            "**Fact-Checking Confidence Level:** 0.00%\n",
            "**Agent's Confidence Assessment:** 0.00%\n",
            "**Agent's Research Completeness:** 0.00%\n",
            "**Agent's Source Quality Assessment:** 0.00%\n",
            "\n",
            "✅ Research results summary saved to legal_research_report.json\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "✅ LEGAL RESEARCH AND FACT-CHECKING PROCESS COMPLETE\n",
            "====================================================================================================\n",
            "\n",
            "The system has executed the legal research and fact-checking process.\n",
            "Review the output above for the detailed report, analysis, and confidence scores.\n"
          ]
        }
      ]
    }
  ]
}