{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQMYCh0JctoJsRpV0mtXlL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prem-cre/Multirag/blob/main/MultimodalAgents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Required Libraries\n",
        "!pip install -qU langchain langchain_groq langchain_huggingface\n",
        "!pip install -qU langchain-community langchain-google-community\n",
        "!pip install -qU tavily-python wikipedia-api beautifulsoup4 requests\n",
        "!pip install -qU tiktoken\n",
        "!pip install -qU lxml[html_clean]\n",
        "!pip install -qU faiss-cpu pypdf tiktoken tavily-python\n",
        "!pip install -qU wikipedia # Added wikipedia package\n",
        "!pip install langchain-google-genai\n"
      ],
      "metadata": {
        "id": "QCFCOahJhYt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_7N01vRtuiK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b56d291-e680-4c1c-c862-e3432a2d8880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All services initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 2: Core Imports and Configuration\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import hashlib\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from dataclasses import field\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from tavily import TavilyClient\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "# Configure API Keys\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_api_key')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('tavily')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = userdata.get('GOOGLE_CSE_ID')\n",
        "\n",
        "# Initialize services\n",
        "# llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0.1)\n",
        "# embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# Initialize Gemini service (hypothetical example)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # üëà switch from \"gemini-pro\"\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "\n",
        "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "google_search_wrapper = GoogleSearchAPIWrapper(k=7)\n",
        "wikipedia_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_wrapper)\n",
        "\n",
        "print(\"‚úÖ All services initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Data Models for Legal Research\n",
        "\n",
        "class SourceCredibility(Enum):\n",
        "    \"\"\"Credibility levels for sources\"\"\"\n",
        "    OFFICIAL = \"official\"\n",
        "    ACADEMIC = \"academic\"\n",
        "    REPUTABLE = \"reputable\"\n",
        "    GENERAL = \"general\"\n",
        "    UNVERIFIED = \"unverified\"\n",
        "\n",
        "@dataclass\n",
        "class LegalSource:\n",
        "    \"\"\"Represents a legal source with metadata\"\"\"\n",
        "    url: str\n",
        "    title: str\n",
        "    content: str\n",
        "    credibility: SourceCredibility\n",
        "    # date_accessed: datetime = field(default_factory=datetime.now)\n",
        "    # date_published: Optional[str] = None\n",
        "    author: Optional[str] = None\n",
        "    jurisdiction: Optional[str] = None\n",
        "    citation: Optional[str] = None\n",
        "    hash: Optional[str] = None\n",
        "    relevance_score: float = 0.0\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.hash = hashlib.md5(self.content.encode()).hexdigest()[:8]\n",
        "\n",
        "@dataclass\n",
        "class EvidenceItem:\n",
        "    \"\"\"Represents a piece of evidence in the legal research\"\"\"\n",
        "    claim: str\n",
        "    supporting_sources: List[LegalSource]\n",
        "    confidence_score: float\n",
        "    reasoning: str\n",
        "    contradictions: List[Dict[str, Any]] = field(default_factory=list)\n",
        "    verification_status: str = \"pending\"\n",
        "    legal_basis: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class LegalResearchResult:\n",
        "    \"\"\"Complete legal research result with chain of evidence\"\"\"\n",
        "    query: str\n",
        "    summary: str\n",
        "    evidence_chain: List[EvidenceItem]\n",
        "    legal_precedents: List[Dict[str, Any]]\n",
        "    jurisdictional_notes: Dict[str, str]\n",
        "    confidence_assessment: Dict[str, float]\n",
        "    citations: List[str]\n",
        "    # timestamp: datetime = field(default_factory=datetime.now)"
      ],
      "metadata": {
        "id": "Uth_vk2CEZSG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Define Enhanced Research Tools\n",
        "\n",
        "@tool\n",
        "def legal_document_search(query: str, jurisdiction: str = \"Indian\") -> str:\n",
        "    \"\"\"\n",
        "    Search legal documents, cases, and statutes with enhanced Indian law focus.\n",
        "    Returns relevant legal information.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Enhanced search query for Indian legal context\n",
        "        legal_query = f\"{jurisdiction} law legal {query} case judgment statute act\"\n",
        "\n",
        "        results = tavily_client.search(\n",
        "            query=legal_query,\n",
        "            search_depth=\"advanced\",\n",
        "            max_results=8,\n",
        "            include_domains=[\"indiankanoon.org\", \"scconline.com\", \"lawmin.gov.in\", \"legislative.gov.in\"],\n",
        "        )\n",
        "\n",
        "        # Return the raw results directly without formatting or filtering citations\n",
        "        return json.dumps(results.get('results', []), indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error searching legal documents: {str(e)}\"})\n",
        "\n",
        "@tool\n",
        "def google_legal_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Calls Google Search API for specialized legal search focusing on Indian legal databases.\n",
        "    Searches specifically in indiankanoon.org and scconline.com domains.\n",
        "    Returns relevant legal information.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add site restrictions for Indian legal databases\n",
        "        search_query = f\"{query} site:indiankanoon.org OR site:scconline.com\"\n",
        "        search_results = google_search_wrapper.results(search_query, num_results=10)\n",
        "\n",
        "        # Return the raw results directly\n",
        "        return json.dumps(search_results, indent=2)\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Google Search: {str(e)}\"\n",
        "\n",
        "@tool\n",
        "def wikipedia_legal_concepts(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Searches Wikipedia for legal concepts, landmark cases, and constitutional matters.\n",
        "    Provides background information and case summaries.\n",
        "    Returns the raw content.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        wiki_result = wikipedia_tool.invoke(query)\n",
        "\n",
        "        # Return the raw wiki result\n",
        "        return wiki_result\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Wikipedia: {str(e)}\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "@tool\n",
        "def fact_check_legal_claim(claim: str) -> str:\n",
        "    \"\"\"\n",
        "    Comprehensive fact-checking of legal claims with Indian law focus.\n",
        "    Returns detailed verification data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Enhanced queries for Indian legal context\n",
        "        supporting_query = f'\"{claim}\" Indian law legal valid true correct Supreme Court High Court'\n",
        "        contradicting_query = f'\"{claim}\" Indian law legal invalid false incorrect exception limitation'\n",
        "\n",
        "        supporting = tavily_client.search(supporting_query, max_results=6)\n",
        "        contradicting = tavily_client.search(contradicting_query, max_results=4)\n",
        "\n",
        "        # Return the raw search results for supporting and contradicting evidence\n",
        "        result = {\n",
        "            'claim': claim,\n",
        "            'supporting_evidence_raw': supporting.get('results', []),\n",
        "            'contradicting_evidence_raw': contradicting.get('results', []),\n",
        "            'verification_summary': f\"Found {len(supporting.get('results', []))} potential supporting and {len(contradicting.get('results', []))} potential contradicting sources\"\n",
        "        }\n",
        "\n",
        "        return json.dumps(result, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error fact-checking claim: {str(e)}\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "wyRdVy3qPRoG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5491448",
        "outputId": "37d9b312-b729-4908-ddf0-bd538ece23a6"
      },
      "source": [
        "# @title Test Tool Output (Raw) for all Tools\n",
        "\n",
        "# Define test queries relevant to each tool\n",
        "test_queries = {\n",
        "    \"legal_document_search\": \"recent Supreme Court judgment on fundamental rights\",\n",
        "    \"google_legal_search\": \"Maharashtra Rent Control Act 1999\",\n",
        "    \"wikipedia_legal_concepts\": \"Doctrine of Basic Structure Indian Constitution\",\n",
        "    \"verify_legal_citation\": \"AIR 2020 SC 123\", # Example valid citation\n",
        "    \"fact_check_legal_claim\": \"Section 498A IPC is non-bailable\",\n",
        "    # Removed test for extract_legal_precedents\n",
        "}\n",
        "\n",
        "print(\"--- Testing Individual Tool Outputs ---\")\n",
        "print(\"Note: Examining raw output before LLM processing.\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Test legal_document_search tool\n",
        "print(\"\\nTesting legal_document_search...\")\n",
        "query = test_queries[\"legal_document_search\"]\n",
        "print(f\"Query: {query}\")\n",
        "search_output = legal_document_search.invoke(query)\n",
        "print(\"Raw Output:\")\n",
        "print(search_output[:100] + \"...\" if len(search_output) > 1000 else search_output) # Print truncated output for brevity\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Test google_legal_search tool\n",
        "print(\"\\nTesting google_legal_search...\")\n",
        "query = test_queries[\"google_legal_search\"]\n",
        "print(f\"Query: {query}\")\n",
        "google_output = google_legal_search.invoke(query)\n",
        "print(\"Raw Output:\")\n",
        "print(google_output[:100] + \"...\" if len(google_output) > 1000 else google_output)\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Test wikipedia_legal_concepts tool\n",
        "print(\"\\nTesting wikipedia_legal_concepts...\")\n",
        "query = test_queries[\"wikipedia_legal_concepts\"]\n",
        "print(f\"Query: {query}\")\n",
        "wiki_output = wikipedia_legal_concepts.invoke(query)\n",
        "print(\"Raw Output:\")\n",
        "print(wiki_output[:1000] + \"...\" if len(wiki_output) > 1000 else wiki_output)\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "\n",
        "# Test fact_check_legal_claim tool\n",
        "print(\"\\nTesting fact_check_legal_claim...\")\n",
        "claim = test_queries[\"fact_check_legal_claim\"]\n",
        "print(f\"Claim: {claim}\")\n",
        "fact_check_output = fact_check_legal_claim.invoke(claim)\n",
        "print(\"Raw Output:\")\n",
        "print(fact_check_output[:100] + \"...\" if len(fact_check_output) > 1000 else fact_check_output)\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "print(\"\\n--- Individual Tool Testing Complete ---\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Individual Tool Outputs ---\n",
            "Note: Examining raw output before LLM processing.\n",
            "----------------------------------------\n",
            "\n",
            "Testing legal_document_search...\n",
            "Query: recent Supreme Court judgment on fundamental rights\n",
            "Raw Output:\n",
            "[\n",
            "  {\n",
            "    \"url\": \"https://indiankanoon.org/search/?formInput=infringement%20of%20fundamental%20right...\n",
            "--------------------\n",
            "\n",
            "Testing google_legal_search...\n",
            "Query: Maharashtra Rent Control Act 1999\n",
            "Raw Output:\n",
            "[\n",
            "  {\n",
            "    \"title\": \"Section 16 in The Maharashtra Rent Control Act, 1999\",\n",
            "    \"link\": \"https://indi...\n",
            "--------------------\n",
            "\n",
            "Testing wikipedia_legal_concepts...\n",
            "Query: Doctrine of Basic Structure Indian Constitution\n",
            "Raw Output:\n",
            "Page: Basic structure doctrine\n",
            "Summary: The basic structure doctrine is a common law legal doctrine that the constitution of a sovereign state has certain characteristics that cannot be erased by its legislature. The doctrine is recognised in India, Bangladesh, Pakistan, and  Uganda. It was developed by the Supreme Court of India in a series of constitutional law cases in the 1960s and 1970s that culminated in Kesavananda Bharati v. State of Kerala, where the doctrine was formally adopted. Bangladesh is perhaps the only legal system in the world that recognizes this doctrine in an expressed, written and rigid constitutional manner through Article 7B of its Constitution.\n",
            "In Kesavananda Bharati, Justice Hans Raj Khanna propounded that the Constitution of India contains certain basic features that cannot be altered or destroyed through amendments by the Parliament of India. Key among these \"basic features\", as expounded by Justice Khanna, are the fundamental rights guaranteed to individua\n",
            "--------------------\n",
            "\n",
            "Testing fact_check_legal_claim...\n",
            "Claim: Section 498A IPC is non-bailable\n",
            "Raw Output:\n",
            "{\n",
            "  \"claim\": \"Section 498A IPC is non-bailable\",\n",
            "  \"supporting_evidence_raw\": [\n",
            "    {\n",
            "      \"url\": \"...\n",
            "--------------------\n",
            "\n",
            "--- Individual Tool Testing Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Legal Research Agent with Structured Output (Fixed)\n",
        "\n",
        "class EnhancedLegalResearchAgent:\n",
        "    \"\"\"Advanced legal research agent with structured analysis and strong prompting\"\"\"\n",
        "\n",
        "    def __init__(self, llm, tools):\n",
        "        self.llm = llm\n",
        "        self.tools = tools\n",
        "        self.memory = ConversationBufferWindowMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True,\n",
        "            k=10\n",
        "        )\n",
        "\n",
        "        # Get tool names for the prompt\n",
        "        tool_names = [tool.name for tool in tools]\n",
        "        tool_descriptions = \"\\n\".join([f\"- {tool.name}: {tool.description}\" for tool in tools])\n",
        "\n",
        "        # Enhanced comprehensive prompt with structured output requirements\n",
        "        self.prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are an expert Indian legal research assistant with comprehensive knowledge of Indian law, statutes, and legal procedures. You provide thorough, well-structured legal analysis.\n",
        "\n",
        "## YOUR APPROACH TO LEGAL RESEARCH:\n",
        "\n",
        "1. **Query Analysis**: Identify legal issues, applicable laws, jurisdiction, and key legal concepts\n",
        "2. **Comprehensive Research**: Search relevant cases, statutes, acts, and legal documents\n",
        "3. **Source Verification**: Verify credibility and authenticity of all sources\n",
        "4. **Precedent Analysis**: Extract and analyze relevant legal precedents and landmark cases\n",
        "5. **Fact Verification**: Cross-check all legal claims against multiple authoritative sources\n",
        "6. **Evidence Synthesis**: Build a logical chain of evidence with proper legal reasoning\n",
        "7. **Confidence Assessment**: Evaluate the strength and reliability of findings\n",
        "\n",
        "## AVAILABLE TOOLS:\n",
        "{tool_descriptions}\n",
        "\n",
        "You have access to the following tools: {tool_names}\n",
        "\n",
        "## STRUCTURED OUTPUT FORMAT:\n",
        "\n",
        "Your final analysis MUST be structured with these EXACT headings:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 6. CITATIONS AND REFERENCES\n",
        "- Minimum 5-6 authoritative citations\n",
        "- Format: Case name, Citation, Court, Year\n",
        "- Include statutory references\n",
        "- Academic sources (if used)\n",
        "\n",
        "\n",
        "\n",
        "Use the tools systematically to gather comprehensive information before providing your structured analysis.\"\"\"),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"human\", \"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "        ])\n",
        "\n",
        "        # Partial the prompt with tool information\n",
        "        self.prompt = self.prompt.partial(\n",
        "            tool_names=\", \".join(tool_names),\n",
        "            tool_descriptions=tool_descriptions,\n",
        "            tools=tool_descriptions  # For backward compatibility\n",
        "        )\n",
        "\n",
        "        # Create the agent\n",
        "        # Ensure handle_parsing_errors is set to True and return_intermediate_steps is True\n",
        "        self.agent = create_react_agent(\n",
        "            llm=self.llm,\n",
        "            tools=self.tools,\n",
        "            prompt=self.prompt\n",
        "        )\n",
        "\n",
        "        self.executor = AgentExecutor(\n",
        "            agent=self.agent,\n",
        "            tools=self.tools,\n",
        "            memory=self.memory,\n",
        "            verbose=True,\n",
        "            max_iterations=20,\n",
        "            handle_parsing_errors=True, # Keep this\n",
        "            return_intermediate_steps=True # Keep this\n",
        "        )\n",
        "\n",
        "    def research(self, query: str) -> LegalResearchResult:\n",
        "        \"\"\"Conduct comprehensive legal research\"\"\"\n",
        "        try:\n",
        "            # Execute the research\n",
        "            # Pass input as a dictionary\n",
        "            result = self.executor.invoke({\"input\": query})\n",
        "\n",
        "            # Parse and structure the results\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error in legal research: {str(e)}\")\n",
        "            return LegalResearchResult(\n",
        "                query=query,\n",
        "                summary=f\"Error conducting research: {str(e)}\",\n",
        "                evidence_chain=[],\n",
        "                legal_precedents=[],\n",
        "                jurisdictional_notes={},\n",
        "                confidence_assessment={\"overall\": 0.0},\n",
        "                citations=[]\n",
        "            )\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "tq7z6cbsYp2l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Multi-Step Fact-Checking Process with LangChain Chains\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "class EnhancedLegalFactChecker:\n",
        "    \"\"\"Enhanced fact-checking system using LangChain chains\"\"\"\n",
        "\n",
        "    def __init__(self, llm, tools):\n",
        "        self.llm = llm\n",
        "        self.tools = tools\n",
        "\n",
        "        # Create specialized chains for different steps\n",
        "        self._create_analysis_chains()\n",
        "\n",
        "    def _create_analysis_chains(self):\n",
        "        \"\"\"Create LangChain chains for structured analysis\"\"\"\n",
        "\n",
        "        # Chain for initial claim analysis\n",
        "        self.claim_analysis_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"claim\"],\n",
        "                template=\"\"\"Analyze this legal claim in detail:\n",
        "\n",
        "Claim: {claim}\n",
        "\n",
        "Provide a structured analysis with:\n",
        "1. **Main Legal Assertion**: What is the core legal claim?\n",
        "2. **Jurisdiction**: Which legal system/jurisdiction applies?\n",
        "3. **Legal Concepts**: What legal principles are involved?\n",
        "4. **Factual Elements**: What specific facts are claimed?\n",
        "5. **Potential Issues**: Any ambiguities or concerns?\n",
        "\n",
        "Format your response as a detailed legal analysis.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Chain for synthesizing evidence\n",
        "        self.evidence_synthesis_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"evidence\", \"claim\"],\n",
        "                template=\"\"\"Synthesize the following evidence for the legal claim:\n",
        "\n",
        "Claim: {claim}\n",
        "\n",
        "Evidence Found:\n",
        "{evidence}\n",
        "\n",
        "Provide:\n",
        "1. **Strength of Evidence**: How strong is the supporting evidence?\n",
        "2. **Contradictions**: Any conflicting information?\n",
        "3. **Gaps**: What information is missing?\n",
        "4. **Overall Assessment**: Your professional legal opinion\n",
        "\n",
        "Be thorough and cite specific sources.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Chain for final verification report\n",
        "        self.final_report_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"claim\", \"analysis\", \"evidence\", \"confidence\"],\n",
        "                template=\"\"\"Generate a comprehensive legal fact-checking report:\n",
        "\n",
        "**CLAIM UNDER REVIEW**: {claim}\n",
        "\n",
        "**INITIAL ANALYSIS**: {analysis}\n",
        "\n",
        "**EVIDENCE SUMMARY**: {evidence}\n",
        "\n",
        "**CONFIDENCE LEVEL**: {confidence}\n",
        "\n",
        "Structure your report with these sections:\n",
        "\n",
        "## 1. EXECUTIVE SUMMARY\n",
        "- Brief overview of findings\n",
        "- Verification status (Verified/Partially Verified/Unverified/False)\n",
        "\n",
        "## 2. DETAILED LEGAL ANALYSIS\n",
        "- Applicable laws and statutes\n",
        "- Relevant case law\n",
        "- Legal principles involved\n",
        "\n",
        "## 3. EVIDENCE EVALUATION\n",
        "- Supporting evidence strength\n",
        "- Contradicting evidence analysis\n",
        "- Source credibility assessment\n",
        "\n",
        "## 4. LEGAL CITATIONS\n",
        "- List all relevant citations found\n",
        "- Include case names, citations, and years **IMPORTANT MANDATORY**\n",
        "\n",
        "## 5. CONCLUSION AND CONFIDENCE ASSESSMENT\n",
        "- Final determination\n",
        "- Confidence percentage with reasoning\n",
        "- Recommendations for further verification if needed\n",
        "\n",
        "Ensure all citations follow proper legal citation format.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def verify_claim(self, claim: str) -> Dict[str, Any]:\n",
        "        \"\"\"Execute enhanced multi-step fact-checking process\"\"\"\n",
        "        results = {\n",
        "            \"claim\": claim,\n",
        "            \"timestamp\": datetime.now(),\n",
        "            \"steps\": []\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Step 1: Initial Claim Analysis using LangChain\n",
        "            print(\"Step 1: Analyzing claim structure...\")\n",
        "            claim_analysis = self.claim_analysis_chain.run(claim=claim)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"claim_analysis\",\n",
        "                \"output\": claim_analysis,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 2: Fact-check the claim using tool\n",
        "            print(\"Step 2: Fact-checking claim...\")\n",
        "            fact_check_result = fact_check_legal_claim.invoke(claim)\n",
        "            fact_check_data = json.loads(fact_check_result)\n",
        "            print(fact_check_data)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"fact_checking\",\n",
        "                \"output\": fact_check_data,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 3: Verify sources credibility\n",
        "            print(\"Step 3: Verifying source credibility...\")\n",
        "            credible_sources = []\n",
        "            all_sources = (\n",
        "                fact_check_data.get('supporting_evidence', []) +\n",
        "                fact_check_data.get('contradicting_evidence', [])\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"source_verification\",\n",
        "                \"output\": all_sources,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 4: Search for legal precedents\n",
        "            print(\"Step 4: Searching for legal precedents...\")\n",
        "            precedent_search = legal_document_search.invoke(claim, \"Indian\")\n",
        "            precedent_data = json.loads(precedent_search)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"precedent_search\",\n",
        "                \"output\": precedent_data,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 5: Synthesize evidence\n",
        "            print(\"Step 5: Synthesizing evidence...\")\n",
        "            evidence_summary = json.dumps({\n",
        "                \"supporting\": len(fact_check_data.get('supporting_evidence', [])),\n",
        "                \"contradicting\": len(fact_check_data.get('contradicting_evidence', [])),\n",
        "                \"credible_sources\": len([s for s in credible_sources if s.get('trusted', False)]),\n",
        "                \"precedents_found\": len(precedent_data) if isinstance(precedent_data, list) else 0\n",
        "            })\n",
        "\n",
        "            synthesis = self.evidence_synthesis_chain.run(\n",
        "                evidence=evidence_summary,\n",
        "                claim=claim\n",
        "            )\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"evidence_synthesis\",\n",
        "                \"output\": synthesis,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "\n",
        "\n",
        "            # Step 7: Generate final report\n",
        "            print(\"Step 6: Generating final report...\")\n",
        "            final_report = self.final_report_chain.run(\n",
        "                claim=claim,\n",
        "                analysis=claim_analysis,\n",
        "                evidence=synthesis\n",
        "            )\n",
        "\n",
        "            results[\"final_report\"] = final_report\n",
        "            results[\"verification_complete\"] = True\n",
        "\n",
        "        except Exception as e:\n",
        "            results[\"error\"] = str(e)\n",
        "            results[\"verification_complete\"] = False\n",
        "\n",
        "\n",
        "        return results\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "wTcEOx0TF06T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create Summary Chain for Final Output\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "def create_summary_chain(llm):\n",
        "    \"\"\"Create a summarization chain using LangChain's built-in functionality\"\"\"\n",
        "    return load_summarize_chain(\n",
        "        llm,\n",
        "        chain_type=\"map_reduce\",\n",
        "        return_intermediate_steps=True,\n",
        "        map_prompt=PromptTemplate(\n",
        "            template=\"\"\"Summarize the following legal information:\n",
        "{text}\n",
        "\n",
        "Focus on:\n",
        "- Key legal points\n",
        "- Important citations\n",
        "- Relevant precedents\"\"\",\n",
        "            input_variables=[\"text\"]\n",
        "        ),\n",
        "        combine_prompt=PromptTemplate(\n",
        "            template=\"\"\"Combine these legal summaries into a comprehensive overview:\n",
        "{text}\n",
        "\n",
        "Provide:\n",
        "1. Main legal findings\n",
        "2. Critical citations\n",
        "3. Overall conclusion\"\"\",\n",
        "            input_variables=[\"text\"]\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "tA4meJqnHwfa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tools = [\n",
        "    legal_document_search,\n",
        "    google_legal_search,\n",
        "    fact_check_legal_claim,\n",
        "    wikipedia_legal_concepts\n",
        "\n",
        "]\n",
        "\n",
        "# @title Instantiate and Run the Legal Fact-Checker and Research Agent\n",
        "\n",
        "print(\"Initializing Legal Fact-Checker and Research Agent...\")\n",
        "# Re-using the 'llm' and 'all_tools' defined in previous sections\n",
        "fact_checker = EnhancedLegalFactChecker(llm=llm, tools=all_tools)\n",
        "legal_research_agent = EnhancedLegalResearchAgent(llm=llm, tools=all_tools) # Also removed from agent tools\n",
        "print(\"Legal Fact-Checker and Research Agent initialized.\")\n",
        "\n",
        "# --- Define a sample legal claim to fact-check and research ---\n",
        "# Example 1: A claim that is likely true (or easily verifiable)\n",
        "claim_1 = \"In the United States, a contract requires an offer, acceptance, and consideration to be legally binding.\"\n",
        "# Example 2: A more nuanced or potentially disputable claim\n",
        "claim_2 = \"A non-compete clause in an employment contract is generally unenforceable in California if it restricts an employee's ability to practice a lawful profession, trade, or business.\"\n",
        "# Example 3: A claim that might have contradictions or require deeper analysis\n",
        "claim_3 = \"All verbal agreements for real estate sales are unenforceable in all U.S. states.\"\n",
        "# Example 4: Indian Law Claim (matches previous example)\n",
        "claim_4 = \"The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\"\n",
        "\n",
        "\n",
        "# @title Execute Comprehensive Legal Research (using the agent)\n",
        "def execute_legal_research(claim, agent, fact_checker):\n",
        "    \"\"\"Execute comprehensive legal research with structured output\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"üîç COMPREHENSIVE LEGAL RESEARCH REPORT\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"\\nüìã **CLAIM UNDER EXAMINATION:**\\n{claim}\")\n",
        "    print(\"\\n\" + \"-\"*100)\n",
        "\n",
        "    # Step 1: Fact-checking\n",
        "    print(\"\\n‚öñÔ∏è **EXECUTING MULTI-STEP FACT-CHECKING PROCESS...**\\n\")\n",
        "    # Use the fact_checker directly for the fact-checking steps\n",
        "    fact_check_result = fact_checker.verify_claim(claim)\n",
        "\n",
        "    # Display fact-checking steps\n",
        "    if fact_check_result.get(\"verification_steps\"):\n",
        "        for i, step in enumerate(fact_check_result[\"verification_steps\"], 1):\n",
        "            step_name = step.get('step', 'Unknown Step').replace(\"_\", \" \").title()\n",
        "            print(f\"\\nüìå Step {i}: {step_name}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            if step.get(\"error\"):\n",
        "                 print(f\"  ‚ùå Error: {step['error']}\")\n",
        "            elif step.get(\"analysis\"):\n",
        "                # Corrected f-string syntax\n",
        "                analysis_text = step['analysis']\n",
        "                print(f\"  **Analysis:**\\n{analysis_text[:500]}...\" if len(analysis_text) > 500 else analysis_text)\n",
        "            elif step.get(\"sources_found\"):\n",
        "                 data = step[\"sources_found\"]\n",
        "                 print(f\"‚úì Supporting Evidence: {len(data.get('supporting_evidence_raw', []))} sources\")\n",
        "                 print(f\"‚úó Contradicting Evidence: {len(data.get('contradicting_evidence_raw', []))} sources\")\n",
        "                 print(f\"üìä Initial Confidence: {data.get('verification_summary', 'N/A')}\") # Display summary from tool output\n",
        "            elif step.get(\"credible_sources\"):\n",
        "                 credible = len([s for s in step[\"credible_sources\"] if s.get('trusted', False) or s.get('credibility') in ['official', 'academic', 'reputable']])\n",
        "                 print(f\"üîê Credible Sources Verified: {credible}/{len(step['credible_sources'])}\")\n",
        "            elif step.get(\"contradictions_found\") is not None:\n",
        "                 print(f\"  **Contradictions Found:** {step['contradictions_found']}\")\n",
        "            elif step.get(\"confidence_score\") is not None:\n",
        "                 print(f\"  **Confidence Score for Step:** {step['confidence_score']:.2%}\")\n",
        "\n",
        "\n",
        "    # Display final confidence score from fact checker\n",
        "    print(f\"\\n\\nüéØ **FINAL FACT-CHECKING CONFIDENCE SCORE: {fact_check_result.get('final_confidence', 0):.2%}**\")\n",
        "\n",
        "    # Step 2: Legal Research (using the agent)\n",
        "    print(\"\\n\\n\" + \"-\"*100)\n",
        "    print(\"üìö **CONDUCTING IN-DEPTH LEGAL RESEARCH (using Agent)...**\\n\")\n",
        "\n",
        "    # The agent will use its tools to perform the research based on the query\n",
        "    research_result = agent.research(claim)\n",
        "\n",
        "    # Display structured legal research output from the agent's final answer\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"üìë **STRUCTURED LEGAL ANALYSIS (from Agent)**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    # Parse and display the structured output from the agent's summary\n",
        "    output_text = research_result.summary\n",
        "\n",
        "    # Extract sections using regex or string parsing (adjust patterns if needed based on agent output)\n",
        "    sections = {\n",
        "        \"1. LEGAL ISSUE IDENTIFICATION\": r\"### 1\\. LEGAL ISSUE IDENTIFICATION(.*?)(?=###|$)\",\n",
        "        \"2. APPLICABLE LAWS AND STATUTES\": r\"### 2\\. APPLICABLE LAWS AND STATUTES(.*?)(?=###|$)\",\n",
        "        \"3. JUDICIAL PRECEDENTS AND CASE LAW\": r\"### 3\\. JUDICIAL PRECEDENTS AND CASE LAW(.*?)(?=###|$)\",\n",
        "        \"4. LEGAL ANALYSIS AND INTERPRETATION\": r\"### 4\\. LEGAL ANALYSIS AND INTERPRETATION(.*?)(?=###|$)\",\n",
        "        \"5. CONCLUSIONS AND RECOMMENDATIONS\": r\"### 5\\. CONCLUSIONS AND RECOMMENDATIONS(.*?)(?=###|$)\",\n",
        "        \"6. CITATIONS AND REFERENCES\": r\"### 6\\. CITATIONS AND REFERENCES(.*?)(?=###|$)\"\n",
        "    }\n",
        "\n",
        "    for section_title, pattern in sections.items():\n",
        "        match = re.search(pattern, output_text, re.DOTALL | re.IGNORECASE)\n",
        "        if match:\n",
        "            print(f\"\\n### {section_title}\")\n",
        "            print(\"-\" * 50)\n",
        "            content = match.group(1).strip()\n",
        "            print(content if content else \"No specific information found for this section.\")\n",
        "        else:\n",
        "            # If structured format not found, display the relevant part of the output\n",
        "            print(f\"\\n### {section_title}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"Could not find section '{section_title}' in agent output. Full output snippet:\")\n",
        "            # Find a relevant snippet around where the section *should* be\n",
        "            snippet_start = output_text.find(section_title) - 100\n",
        "            snippet_end = output_text.find(section_title) + 200\n",
        "            print(output_text[max(0, snippet_start):min(len(output_text), snippet_end)] + \"...\")\n",
        "\n",
        "\n",
        "    # Display citations and evidence sources collected by the agent\n",
        "    print(\"\\n\\n\" + \"=\"*100)\n",
        "    print(\"üìñ **LEGAL CITATIONS AND EVIDENCE SOURCES (from Agent)**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    if research_result.citations:\n",
        "        print(\"\\n**Agent-Extracted Citations:**\")\n",
        "        for i, citation in enumerate(research_result.citations[:10], 1):\n",
        "            print(f\"{i}. {citation}\")\n",
        "    else:\n",
        "        print(\"\\nNo specific citations extracted by the agent.\")\n",
        "\n",
        "    if research_result.evidence_chain:\n",
        "        print(\"\\n**Evidence Sources Used by Agent (Sample):**\")\n",
        "        for i, evidence in enumerate(research_result.evidence_chain[:5], 1):\n",
        "            print(f\"\\n{i}. Claim: {evidence.claim}\")\n",
        "            if evidence.supporting_sources:\n",
        "                source = evidence.supporting_sources[0]\n",
        "                print(f\"   Source URL: {source.url}\")\n",
        "                print(f\"   Credibility: {source.credibility.value}\")\n",
        "                print(f\"   Relevance Score: {source.relevance_score:.2f}\")\n",
        "    else:\n",
        "        print(\"\\nNo evidence sources recorded by the agent.\")\n",
        "\n",
        "\n",
        "    # Final assessment summary\n",
        "    print(\"\\n\\n\" + \"=\"*100)\n",
        "    print(\"üìä **FINAL ASSESSMENT SUMMARY**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    # You can combine insights from both fact_check_result and research_result here\n",
        "    print(f\"\\n**Fact-Checking Confidence Level:** {fact_check_result.get('final_confidence', 0):.2%}\")\n",
        "    print(f\"**Agent's Confidence Assessment:** {research_result.confidence_assessment.get('overall', 0):.2%}\")\n",
        "    print(f\"**Agent's Research Completeness:** {research_result.confidence_assessment.get('completeness', 0):.2%}\")\n",
        "    print(f\"**Agent's Source Quality Assessment:** {research_result.confidence_assessment.get('source_quality', 0):.2%}\")\n",
        "\n",
        "    # You could add a final summary generated by an LLM chain here if needed\n",
        "    # Example: final_summary = summary_chain.run(text=research_result.summary + json.dumps(fact_check_result))\n",
        "    # print(\"\\n**Overall Summary:**\\n\", final_summary)\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"claim\": claim,\n",
        "        \"fact_check_result\": fact_check_result,\n",
        "        \"research_result\": research_result\n",
        "    }\n",
        "\n",
        "# @title Run Legal Research on Selected Claim\n",
        "\n",
        "# Select a claim to analyze\n",
        "selected_claim = claim_4  # Using the Indian Law Claim\n",
        "\n",
        "print(\"üèõÔ∏è INDIAN LEGAL RESEARCH SYSTEM\")\n",
        "print(\"=\"*100)\n",
        "print(f\"\\nüîç Analyzing: {selected_claim}\\n\")\n",
        "\n",
        "# Execute the research\n",
        "results = execute_legal_research(selected_claim, legal_research_agent, fact_checker)\n",
        "\n",
        "# @title Additional Analysis Functions using LangChain (Optional)\n",
        "\n",
        "# These functions can be used independently after execute_legal_research\n",
        "# They are not part of the automated execute_legal_research flow above\n",
        "# unless explicitly called within it.\n",
        "\n",
        "# Example: Generate Legal Opinion based on results (requires a summary chain or direct LLM call)\n",
        "# def generate_legal_opinion(llm, claim, research_results):\n",
        "#     \"\"\"Generate a formal legal opinion using LangChain\"\"\"\n",
        "#     # This would need a prompt and potentially structured input from research_results\n",
        "#     pass\n",
        "\n",
        "# Example: Create Citation Formatter (if needed for final presentation)\n",
        "# def format_citations_properly(citations):\n",
        "#     \"\"\"Format legal citations according to Indian legal citation standards\"\"\"\n",
        "#     pass\n",
        "\n",
        "\n",
        "# @title Save Research Results (Optional)\n",
        "\n",
        "def save_research_results(results, filename=\"legal_research_report.json\"):\n",
        "    \"\"\"Save the research results to a JSON file\"\"\"\n",
        "\n",
        "    # Prepare data for JSON serialization - be mindful of complex objects\n",
        "    save_data = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"claim\": results[\"claim\"],\n",
        "        \"fact_checking_confidence\": results[\"fact_check_result\"].get(\"final_confidence\", 0),\n",
        "        \"fact_checking_steps_count\": len(results[\"fact_check_result\"].get(\"verification_steps\", [])),\n",
        "        \"agent_research_summary\": results[\"research_result\"].summary,\n",
        "        \"agent_extracted_citations\": results[\"research_result\"].citations[:10] if results[\"research_result\"].citations else [],\n",
        "        \"agent_evidence_sources_count\": len(results[\"research_result\"].evidence_chain),\n",
        "        \"agent_jurisdictional_notes\": results[\"research_result\"].jurisdictional_notes,\n",
        "        \"agent_confidence_assessment\": results[\"research_result\"].confidence_assessment,\n",
        "        # Potentially include summarized steps from fact_check_result if needed\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(save_data, f, indent=2)\n",
        "        print(f\"\\n‚úÖ Research results summary saved to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error saving research results: {str(e)}\")\n",
        "\n",
        "\n",
        "# Save the results (optional)\n",
        "save_research_results(results)\n",
        "\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*100)\n",
        "print(\"‚úÖ LEGAL RESEARCH AND FACT-CHECKING PROCESS COMPLETE\")\n",
        "print(\"=\"*100)\n",
        "print(\"\\nThe system has executed the legal research and fact-checking process.\")\n",
        "print(\"Review the output above for the detailed report, analysis, and confidence scores.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_QX0KA7GzGn",
        "outputId": "dd752619-c602-4464-b8bf-32c1987f38b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Legal Fact-Checker and Research Agent...\n",
            "Legal Fact-Checker and Research Agent initialized.\n",
            "üèõÔ∏è INDIAN LEGAL RESEARCH SYSTEM\n",
            "====================================================================================================\n",
            "\n",
            "üîç Analyzing: The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "üîç COMPREHENSIVE LEGAL RESEARCH REPORT\n",
            "====================================================================================================\n",
            "\n",
            "üìã **CLAIM UNDER EXAMINATION:**\n",
            "The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "‚öñÔ∏è **EXECUTING MULTI-STEP FACT-CHECKING PROCESS...**\n",
            "\n",
            "Step 1: Analyzing claim structure...\n",
            "Step 2: Fact-checking claim...\n",
            "{'claim': 'The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.', 'supporting_evidence_raw': [{'title': 'Êèê‰∫§Ë°®ÂçïÊòæÁ§∫Please verify the CAPTCHA before proceedÊÄé‰πàÂäûÔºü', 'url': 'https://www.zhihu.com/question/640631824', 'content': 'Êèê‰∫§Ë°®ÂçïÊòæÁ§∫Please verify the CAPTCHA before proceedÊÄé‰πàÂäûÔºü - Áü•‰πé Image 1) \\u200b  Êèê‰∫§Ë°®ÂçïÊòæÁ§∫Please verify the CAPTCHA before proceedÊÄé‰πàÂäûÔºü Êèê‰∫§Ë°®ÂçïÊòæÁ§∫Please verify the CAPTCHA before proceedÊÄé‰πàÂäûÔºü Êú¨‰∫∫Âõ†‰∏∫ÊóÖÊ∏∏ÈúÄË¶ÅÊâìÂç∞ÁîµÂ≠êÁ≠æËØÅÔºå‰ΩÜÊòØÊèê‰∫§ÂêéÊòæÁ§∫Please verify the CAPTCHA before proceedÔºåÊç¢‰∫ÜÂ•ΩÂá†‰∏™ÊµèËßàÂô®ÈÉΩ‰∏ÄÊ†∑„ÄÇ‚Ä¶ÊòæÁ§∫ÂÖ®ÈÉ® \\u200b #### 5 ‰∏™ÂõûÁ≠î Image 2: Smile \\u200b ÂÖ≥Ê≥® \\u200bËµûÂêå 4\\u200b\\u200b1 Êù°ËØÑËÆ∫ \\u200bÊî∂Ëóè\\u200bÂñúÊ¨¢ Image 3: ËãèÂ§ßÊàü \\u200b ÂÖ≥Ê≥® Image 5 \\u200bËµûÂêå 3\\u200b\\u200b1 Êù°ËØÑËÆ∫ \\u200bÊî∂Ëóè\\u200bÂñúÊ¨¢ Image 6: ÂáåÂêõ \\u200b ÂÖ≥Ê≥® \\u200bËµûÂêå 7\\u200b\\u200bÊ∑ªÂä†ËØÑËÆ∫ \\u200bÊî∂Ëóè\\u200bÂñúÊ¨¢ Êî∂Ëµ∑\\u200b Image 7: QR Code of Downloading Zhihu App ‰∏ãËΩΩÁü•‰πéÂÆ¢Êà∑Á´Ø ‰∏é‰∏ñÁïåÂàÜ‰∫´Áü•ËØÜ„ÄÅÁªèÈ™åÂíåËßÅËß£ Image 8: ÂπøÂëä Â¶Ç‰ΩïÁî®‰∏Ä‰∏™buttonÂÆûÁé∞Êèê‰∫§Ë°®Âçï+ÂºπÊ°ÜÊòæÁ§∫Ë°®ÂçïÂèçÈ¶àÁªìÊûúÔºü 1 ‰∏™ÂõûÁ≠î Image 9: ÂπøÂëä ‰∫¨ ICP ËØÅ 110745 Âè∑ ¬∑ ‰∫¨ ICP Â§á 13052560 Âè∑ - 1 ¬∑ ‰∫¨ÂÖ¨ÁΩëÂÆâÂ§á 11010802020088 Âè∑ ¬∑ ‰∫íËÅîÁΩëÊñ∞Èóª‰ø°ÊÅØÊúçÂä°ËÆ∏ÂèØËØÅÔºö11220250001 ¬∑ [‰∫¨ÁΩëÊñá[2022]2674-081 Âè∑](https://www.zhihu.com/certificates) ¬∑ ËçØÂìÅÂåªÁñóÂô®Ê¢∞ÁΩëÁªú‰ø°ÊÅØÊúçÂä°Â§áÊ°àÔºà‰∫¨ÔºâÁΩëËçØÊ¢∞‰ø°ÊÅØÂ§áÂ≠óÔºà2022ÔºâÁ¨¨00334Âè∑ ¬∑ ÂπøÊí≠ÁîµËßÜËäÇÁõÆÂà∂‰ΩúÁªèËê•ËÆ∏ÂèØËØÅ:Ôºà‰∫¨ÔºâÂ≠óÁ¨¨06591Âè∑ ¬∑ ‰∫íËÅîÁΩëÂÆóÊïô‰ø°ÊÅØÊúçÂä°ËÆ∏ÂèØËØÅÔºö‰∫¨Ôºà2022Ôºâ0000078 ¬∑ ÊúçÂä°ÁÉ≠Á∫øÔºö400-919-0001 ¬∑ Investor Relations ¬∑  ¬© 2025 Áü•‰πé Âåó‰∫¨Êô∫ËÄÖÂ§©‰∏ãÁßëÊäÄÊúâÈôêÂÖ¨Âè∏ÁâàÊùÉÊâÄÊúâ ¬∑ ËøùÊ≥ïÂíå‰∏çËâØ‰ø°ÊÅØ‰∏æÊä•Ôºö010-82716601 ¬∑ ‰∏æÊä•ÈÇÆÁÆ±Ôºöjubao@zhihu.com Image 10: Êú¨Á´ôÊèê‰æõÈÄÇËÄÅÂåñÊó†ÈöúÁ¢çÊúçÂä° Image 11', 'score': 0.03222541, 'raw_content': None}, {'title': '9 Strategies for Staying Healthy While Working a Desk Job', 'url': 'https://cathe.com/9-strategies-for-staying-healthy-while-working-a-desk-job/', 'content': 'Here are some tips that will help you stay healthy while sitting at a desk all day long: If you‚Äôre sitting at a desk all day without getting up every hour for movement breaks, try this. Sitting all day can be tough on your body ‚Äì make sure you‚Äôre sitting in a supportive chair. If your job involves sitting at a desk all day, it‚Äôs important to take breaks because extended periods of sedentary behavior are associated with an increased risk for metabolic syndrome (a cluster of conditions including high blood pressure and obesity). Staying well hydrated helps lower the risk of developing blood clots too, a risk if you sit too much. 3 Ways Sitting Less Can Improve Your Work Day and Work Performance', 'score': 0.02074295, 'raw_content': None}, {'title': 'Workout DVD, Fitness DVD, Exercise DVDs and Videos', 'url': 'https://cathe.com/', 'content': \"Take Cathe Everywhere ### Cathe‚Äôs STS 2.0 Workout Program # Get Instant Access to Every Cathe Workout Video If you want to access your Cathe Live or OnDemand videos, or the Workout Blender on your browser, you first need to click the orange button below if you are not logged in. We‚Äôve listed all of the links below that you will need to learn how to use and access\\xa0 your Cathe OnDemand and Cathe Live workout videos. * Cathe Workout Rotations #### Cathe's STS 2.0 Muscle & Recovery - 25 Workouts For Only $7.20 each\\\\* #### Cathe 2025 August Workout Rotation #### Cathe‚Äôs July 2025 Workout Rotation #### Cathe‚Äôs June 2025 Workout Rotation #### Cathe‚Äôs May 2025 Workout Rotation\", 'score': 0.018449089, 'raw_content': None}, {'title': 'Journal of the Mechanics and Physics of Solids Âú®ÂäõÂ≠¶ÁïåÊòØ ... - Áü•‰πé', 'url': 'https://www.zhihu.com/question/26721583', 'content': 'Journal of the Mechanics and Physics of Solids Âú®ÂäõÂ≠¶ÁïåÊòØ‰∏™‰ªÄ‰πàÊ∞¥Âπ≥ÁöÑÊùÇÂøóÔºü - Áü•‰πé Image 1) \\u200b  Journal of the Mechanics and Physics of Solids Âú®ÂäõÂ≠¶ÁïåÊòØ‰∏™‰ªÄ‰πàÊ∞¥Âπ≥ÁöÑÊùÇÂøóÔºü Journal of the Mechanics and Physics of Solids Âú®ÂäõÂ≠¶ÁïåÊòØ‰∏™‰ªÄ‰πàÊ∞¥Âπ≥ÁöÑÊùÇÂøóÔºü ËÄÅÂ∏àË∑üÊàë‰ª¨ÁßÄ‰ºòË∂ä ÔºåËØ¥Âèë‰∫ÜÁØápaperÂú® ‰∏≠ÂõΩÊØèÂπ¥Âè™Êúâ‰∏çÂà∞10‰∏™ ËÉΩÂèëÁöÑÊùÇÂøó‰∏äÔºåÊÉ≥Áü•ÈÅìËøô‰∏™ÊùÇÂøóÁ©∂Á´ü‰ªÄ‰πàÊ∞¥ÂáÜÔºüÊòæÁ§∫ÂÖ®ÈÉ® \\u200b #### 11 ‰∏™ÂõûÁ≠î Image 2: Áü•‰πéÁî®Êà∑ \\u200b ÂÖ≥Ê≥® \\u200bËµûÂêå 43\\u200b\\u200b13 Êù°ËØÑËÆ∫ Image 3: ËØõÁ∫∏‰∫∫ ËØõÁ∫∏‰∫∫ \\u200b ÂÖ≥Ê≥® \\u200bËµûÂêå 15\\u200b\\u200b1 Êù°ËØÑËÆ∫ Image 4: Áü•‰πéÁî®Êà∑ Áü•‰πéÁî®Êà∑ JOURNAL OF THE MECHANICS AND PHYSICS OF SOLIDS \\u200bËµûÂêå 10\\u200b\\u200bÊ∑ªÂä†ËØÑËÆ∫ Image 5: QR Code of Downloading Zhihu App ‰∏ãËΩΩÁü•‰πéÂÆ¢Êà∑Á´Ø ‰∏é‰∏ñÁïåÂàÜ‰∫´Áü•ËØÜ„ÄÅÁªèÈ™åÂíåËßÅËß£ Image 6: ÂπøÂëä Êúâ‰ªÄ‰πàÂÖ≥‰∫éÂäõÂ≠¶ÂâçÊ≤øÁöÑÊúüÂàä ÊùÇÂøó ËÆ∫Êñá ÂÖ¨‰ºóÂè∑ Á≠âÁ≠âÔºü 5 ‰∏™ÂõûÁ≠î ÊµÅ‰ΩìÂäõÂ≠¶ÊπçÊµÅÁé∞Âú®ÂõΩÂÜÖ‰∏ÄËà¨ÈÉΩÊäï‰ªÄ‰πàtopÊúüÂàäÔºüÂõΩÂÜÖÊúâÂì™‰∫õÂõ¢ÈòüËøòÂú®Á†îÁ©∂Âü∫Á°ÄÁêÜËÆ∫Ôºü 1 ‰∏™ÂõûÁ≠î „ÄäÂäõÂ≠¶ËøõÂ±ï„ÄãËøôÊú¨ÊùÇÂøóÊòØÊ≠£ÂÑøÂÖ´ÁªèÁöÑËÆ∫ÊñáÊúüÂàäÂêóÔºü 2 ‰∏™ÂõûÁ≠î Journal of Cosmology and Astroparticle Physics Â¶Ç‰ΩïÔºü 1 ‰∏™ÂõûÁ≠î Image 7: ÂπøÂëä Image 8: Êú¨Á´ôÊèê‰æõÈÄÇËÄÅÂåñÊó†ÈöúÁ¢çÊúçÂä° Image 9', 'score': 0.017138867, 'raw_content': None}, {'title': 'Walking Upstairs Burns Calories, but Walking Downstairs is Healthy ‚Ä¶', 'url': 'https://cathe.com/walking-upstairs-burns-more-calories-but-walking-downstairs-is-healthy-too-heres-why/', 'content': '### The Health Benefits of Going Down a Flight of Stairs During the 12 weeks, one group went either up or downstairs at scheduled times so the researchers could look at the impact each stair taking direction had on metabolic markers of health. Contrary to what you might think, the subjects experienced greater improvements in health markers when they walked down the stairs as opposed to climbing flights of stairs. The subjects who went downstairs also experienced greater improvements in markers of metabolic health relative to those who climbed up the stairs. In fact, the ability to climb a flight of stairs without being too winded is a marker of cardiovascular health. Research shows short exercise breaks, like going up and down the stairs, has health benefits.', 'score': 0.01595695, 'raw_content': None}, {'title': 'sciÊäïÁ®øDeclaration of interestÊÄé‰πàÂÜô? - Áü•‰πé', 'url': 'https://www.zhihu.com/question/497551602', 'content': 'COI/Declaration of Interest forms from all the authors of an article is req‚Ä¶ #### 15 ‰∏™ÂõûÁ≠î **Declaration of interests** ‚òí The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. ‚òêThe authors declare the following financial interests/personal relationships which may be considered as potential competing interests: Declaration of interestÊòØÂæàÂ§ö‰ΩúËÄÖÂÆπÊòìÂøΩËßÜÁöÑ‰∏ÄÁÇπÔºåÂõ†‰∏∫ÊãÖÂøÉÂà©ÁõäÂÜ≤Á™ÅÂ£∞Êòé‰∏≠ÊâÄÊä´Èú≤Âá∫ÁöÑÂà©ÁõäÂÖ≥Á≥ª‰ºöÂΩ±ÂìçËÆ∫ÊñáÁöÑÂèëË°®„ÄÇ‰ΩÜÂØπ‰∫éÂèØËÉΩÂ≠òÂú®ÁöÑÂà©ÁõäÂÜ≤Á™ÅÈöêÁûí‰∏çÊä•ÔºåÂÖ∂ÂÆûÂè™ÊòØÂüã‰∏ã‰∫ÜÊõ¥Â§ßÈöêÊÇ£„ÄÇ**Âç≥‰ΩøÊñáÁ´†ÊàêÂäüÂèëË°®Ôºå‰∏ÄÊó¶Ë¢´ÂèëÁé∞ÔºåÂ∞ÜÈù¢‰∏¥ËÆ∫ÊñáË¢´Êí§Á®øÂíå‰ΩúËÄÖË¢´ÊåáÊéßÂ≠¶ÊúØ‰∏çÁ´ØÁöÑÂèåÈáç‰∏•ÈáçÂêéÊûú„ÄÇ** no other author has reported a potential conflict of interest relevant to this article. All authors disclosed no relevant relationships. ÊäïÁ®øsciÂêéÂà∞‰∫Ürequired reviews completed Èò∂ÊÆµÂêéÊòØ‰∏ÄÁßçÊÄéÊ†∑ÁöÑÂøÉÊÉÖÔºü 52 ‰∏™ÂõûÁ≠î SCIËÆ∫Êñá‰∏≠ÂÜôExperimental sectionÈÉ®ÂàÜÊó∂ËØ•Â¶Ç‰ΩïÂèñËàçÔºü 1 ‰∏™ÂõûÁ≠î sciÊäïÁ®øÁªìÊûúÊòØImmediate Reject with ReferralÔºåÊÑèÊÄùÊó∂ËÆ∫ÊñáÂÜôÁöÑÂ§™Â∑Æ‰∫ÜÂêóÔºü 4 ‰∏™ÂõûÁ≠î Â¶Ç‰ΩïÂÜôÂ•Ω SCI ËÆ∫ÊñáÁöÑ Introduction ÈÉ®ÂàÜÔºü 17 ‰∏™ÂõûÁ≠î', 'score': 0.015378678, 'raw_content': None}], 'contradicting_evidence_raw': [{'url': 'https://judgments.ecourts.gov.in/KBJ/?p=home/intro', 'title': 'The Basic Structure Judgment - Home', 'content': 'This led to the landmark Kesavananda Bharati judgment, which upheld the basic structure doctrine and placed limits on the power of the Parliament to amend the Constitution. The case was filed by Sri Kesavananda Bharati, the head of a Hindu religious mutt in Kerala, challenging the constitutional validity of the 24th, 25th and 29th Amendments to the Indian Constitution, which sought to curtail the powers of the judiciary and the fundamental rights of citizens. The Supreme Court, in a historic 7:6 majority decision, propounded the basic structure doctrine of the Constitution, which holds that certain fundamental features of the Constitution, such as democracy, secularism, federalism, and the rule of law, cannot be amended by parliament. The significance of the Kesavananda Bharati case lies in the fact that it established the doctrine of basic structure of the Indian Constitution.', 'score': 0.8467682, 'raw_content': None}, {'url': 'https://vajiramandravi.com/upsc-exam/basic-structure/', 'title': 'Basic Structure Doctrine, Meaning, Significance, Evolution', 'content': \"The Basic Structure Doctrine, established by the Indian judiciary in the 1973 Kesavananda Bharati case, holds that certain fundamental features of the Indian Constitution cannot be amended by Parliament, even under Article 368. The\\\\*\\\\*Basic Structure Doctrine\\\\*\\\\*is a judicial principle in Indian constitutional law that prevents the Parliament from altering the fundamental framework of the Constitution. \\\\* \\\\*\\\\*Kesavananda Bharati vs State of Kerala (1973):\\\\*\\\\*The Court upheld Parliament's amendment power but introduced the basic structure doctrine, limiting amendments that undermine constitutional principles. \\\\* \\\\*\\\\*Minerva Mills vs Union of India (1980):\\\\*\\\\*The Court invalidated parts of the 42nd Amendment, affirming judicial review as integral to the Constitution's basic structure. The\\\\*\\\\*Elements of the Basic Structure Doctrine\\\\*\\\\*are fundamental principles that protect the core of the Constitution, ensuring that its essence remains intact despite amendments.\", 'score': 0.8033131, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Kesavananda_Bharati_v._State_of_Kerala', 'title': 'Kesavananda Bharati v. State of Kerala - Wikipedia', 'content': 'State of Kerala & Anr.** (Writ Petition (Civil) 135 of 1970), also known as the **Kesavananda Bharati judgement**, was a landmark decision of the Supreme Court of India that outlined the basic structure doctrine \"Basic structure doctrine (Constitution of India)\") of the Indian Constitution. State of Punjab*, which held that constitutional amendments through Article 368 were subject to fundamental rights review, but only if they could affect the \\'basic structure of the Constitution\\'. In conclusion, the learned Judge held that though the power of amendment was wide, it did not comprehend the power to totally abrogate or emasculate or damage any of the fundamental rights or the essential elements of the basic structure of the Constitution or to destroy the identity of the Constitution.', 'score': 0.6884899, 'raw_content': None}, {'url': 'https://verfassungsblog.de/50-years-of-kesavananda-bharti/', 'title': '50 Years of Kesavananda Bharti - Verfassungsblog', 'content': 'The basic structure doctrine provides that the power of the legislature to amend the Constitution is not plenary or unlimited. Reversing this position, the *Kesavananda Bharti* court clarified (*see* conclusions of the majority opinions) that while the Parliament may amend every provision of the Constitution, it cannot amend them in a way that would destroy or damage the basic structure of the Constitution. The basic structure doctrine provides a critical external check against the abuse of the power to amend the Constitution. Under the present Indian government, both the ideas of constitutional supremacy and judicial independence are being threatened, thereby inviting a challenge to the appropriateness of the basic structure doctrine. Explore posts related to this: BJP, Indian Constitution, Parliamentary Sovereignty, basic structure doctrine', 'score': 0.6778372, 'raw_content': None}], 'verification_summary': 'Found 6 potential supporting and 4 potential contradicting sources'}\n",
            "Step 3: Verifying source credibility...\n",
            "Step 4: Searching for legal precedents...\n",
            "\n",
            "\n",
            "üéØ **FINAL FACT-CHECKING CONFIDENCE SCORE: 0.00%**\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "üìö **CONDUCTING IN-DEPTH LEGAL RESEARCH (using Agent)...**\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "Error in legal research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>\n",
            "\n",
            "====================================================================================================\n",
            "üìë **STRUCTURED LEGAL ANALYSIS (from Agent)**\n",
            "====================================================================================================\n",
            "\n",
            "### 1. LEGAL ISSUE IDENTIFICATION\n",
            "--------------------------------------------------\n",
            "Could not find section '1. LEGAL ISSUE IDENTIFICATION' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 2. APPLICABLE LAWS AND STATUTES\n",
            "--------------------------------------------------\n",
            "Could not find section '2. APPLICABLE LAWS AND STATUTES' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 3. JUDICIAL PRECEDENTS AND CASE LAW\n",
            "--------------------------------------------------\n",
            "Could not find section '3. JUDICIAL PRECEDENTS AND CASE LAW' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 4. LEGAL ANALYSIS AND INTERPRETATION\n",
            "--------------------------------------------------\n",
            "Could not find section '4. LEGAL ANALYSIS AND INTERPRETATION' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 5. CONCLUSIONS AND RECOMMENDATIONS\n",
            "--------------------------------------------------\n",
            "Could not find section '5. CONCLUSIONS AND RECOMMENDATIONS' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "### 6. CITATIONS AND REFERENCES\n",
            "--------------------------------------------------\n",
            "Could not find section '6. CITATIONS AND REFERENCES' in agent output. Full output snippet:\n",
            "Error conducting research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>...\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "üìñ **LEGAL CITATIONS AND EVIDENCE SOURCES (from Agent)**\n",
            "====================================================================================================\n",
            "\n",
            "No specific citations extracted by the agent.\n",
            "\n",
            "No evidence sources recorded by the agent.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "üìä **FINAL ASSESSMENT SUMMARY**\n",
            "====================================================================================================\n",
            "\n",
            "**Fact-Checking Confidence Level:** 0.00%\n",
            "**Agent's Confidence Assessment:** 0.00%\n",
            "**Agent's Research Completeness:** 0.00%\n",
            "**Agent's Source Quality Assessment:** 0.00%\n",
            "\n",
            "‚úÖ Research results summary saved to legal_research_report.json\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "‚úÖ LEGAL RESEARCH AND FACT-CHECKING PROCESS COMPLETE\n",
            "====================================================================================================\n",
            "\n",
            "The system has executed the legal research and fact-checking process.\n",
            "Review the output above for the detailed report, analysis, and confidence scores.\n"
          ]
        }
      ]
    }
  ]
}