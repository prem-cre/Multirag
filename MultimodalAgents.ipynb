{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoJCwLPNGXUtOyaT1P2N/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prem-cre/Multirag/blob/main/MultimodalAgents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Required Libraries\n",
        "!pip install -qU langchain langchain_groq langchain_huggingface\n",
        "!pip install -qU langchain-community langchain-google-community\n",
        "!pip install -qU tavily-python wikipedia-api beautifulsoup4 requests\n",
        "!pip install -qU tiktoken\n",
        "!pip install -qU lxml[html_clean]\n",
        "!pip install -qU faiss-cpu pypdf tiktoken tavily-python\n",
        "!pip install -qU wikipedia # Added wikipedia package"
      ],
      "metadata": {
        "id": "QCFCOahJhYt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7N01vRtuiK5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 2: Core Imports and Configuration\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from tavily import TavilyClient\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure API Keys\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_api_key')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('tavily')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = userdata.get('GOOGLE_CSE_ID')\n",
        "\n",
        "# Initialize services\n",
        "llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0.1)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "google_search_wrapper = GoogleSearchAPIWrapper(k=7)\n",
        "wikipedia_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_wrapper)\n",
        "\n",
        "print(\"âœ… All services initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Data Models for Legal Research\n",
        "\n",
        "class SourceCredibility(Enum):\n",
        "    \"\"\"Credibility levels for sources\"\"\"\n",
        "    OFFICIAL = \"official\"\n",
        "    ACADEMIC = \"academic\"\n",
        "    REPUTABLE = \"reputable\"\n",
        "    GENERAL = \"general\"\n",
        "    UNVERIFIED = \"unverified\"\n",
        "\n",
        "@dataclass\n",
        "class LegalSource:\n",
        "    \"\"\"Represents a legal source with metadata\"\"\"\n",
        "    url: str\n",
        "    title: str\n",
        "    content: str\n",
        "    credibility: SourceCredibility\n",
        "    # date_accessed: datetime = field(default_factory=datetime.now)\n",
        "    # date_published: Optional[str] = None\n",
        "    author: Optional[str] = None\n",
        "    jurisdiction: Optional[str] = None\n",
        "    citation: Optional[str] = None\n",
        "    hash: Optional[str] = None\n",
        "    relevance_score: float = 0.0\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.hash = hashlib.md5(self.content.encode()).hexdigest()[:8]\n",
        "\n",
        "@dataclass\n",
        "class EvidenceItem:\n",
        "    \"\"\"Represents a piece of evidence in the legal research\"\"\"\n",
        "    claim: str\n",
        "    supporting_sources: List[LegalSource]\n",
        "    confidence_score: float\n",
        "    reasoning: str\n",
        "    contradictions: List[Dict[str, Any]] = field(default_factory=list)\n",
        "    verification_status: str = \"pending\"\n",
        "    legal_basis: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class LegalResearchResult:\n",
        "    \"\"\"Complete legal research result with chain of evidence\"\"\"\n",
        "    query: str\n",
        "    summary: str\n",
        "    evidence_chain: List[EvidenceItem]\n",
        "    legal_precedents: List[Dict[str, Any]]\n",
        "    jurisdictional_notes: Dict[str, str]\n",
        "    confidence_assessment: Dict[str, float]\n",
        "    citations: List[str]\n",
        "    # timestamp: datetime = field(default_factory=datetime.now)"
      ],
      "metadata": {
        "id": "Uth_vk2CEZSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Define Enhanced Research Tools\n",
        "\n",
        "@tool\n",
        "def legal_document_search(query: str, jurisdiction: str = \"Indian\") -> str:\n",
        "    \"\"\"\n",
        "    Search legal documents, cases, and statutes with enhanced Indian law focus.\n",
        "    Returns relevant legal information with proper citations.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Enhanced search query for Indian legal context\n",
        "        legal_query = f\"{jurisdiction} law legal {query} case judgment statute act\"\n",
        "\n",
        "        results = tavily_client.search(\n",
        "            query=legal_query,\n",
        "            search_depth=\"advanced\",\n",
        "            max_results=8,\n",
        "            include_domains=[\"indiankanoon.org\", \"scconline.com\", \"lawmin.gov.in\", \"legislative.gov.in\"],\n",
        "        )\n",
        "\n",
        "        formatted_results = []\n",
        "        for idx, r in enumerate(results.get('results', [])):\n",
        "            formatted_results.append({\n",
        "                'rank': idx + 1,\n",
        "                'title': r.get('title'),\n",
        "                'url': r.get('url'),\n",
        "                'content': r.get('content'),\n",
        "                'score': r.get('score', 0),\n",
        "                'snippet': r.get('content', '')[:200] + \"...\"\n",
        "            })\n",
        "\n",
        "        return json.dumps(formatted_results, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error searching legal documents: {str(e)}\"})\n",
        "\n",
        "@tool\n",
        "def google_legal_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Calls Google Search API for specialized legal search focusing on Indian legal databases.\n",
        "    Searches specifically in indiankanoon.org and scconline.com domains.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add site restrictions for Indian legal databases\n",
        "        search_query = f\"{query} site:indiankanoon.org OR site:scconline.com\"\n",
        "        search_results = google_search_wrapper.results(search_query, num_results=10)\n",
        "\n",
        "        formatted_results = []\n",
        "        for res in search_results:\n",
        "            formatted_results.append({\n",
        "                'title': res.get('title', 'N/A'),\n",
        "                'snippet': res.get('snippet', 'N/A'),\n",
        "                'link': res.get('link', 'N/A'),\n",
        "                'source': 'Google Search - Indian Legal Databases'\n",
        "            })\n",
        "\n",
        "        return json.dumps(formatted_results, indent=2)\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Google Search: {str(e)}\"\n",
        "\n",
        "@tool\n",
        "def wikipedia_legal_concepts(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Searches Wikipedia for legal concepts, landmark cases, and constitutional matters.\n",
        "    Provides background information and case summaries.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        wiki_result = wikipedia_tool.invoke(query)\n",
        "\n",
        "        # Structure the result\n",
        "        result = {\n",
        "            'query': query,\n",
        "            'content': wiki_result[:1000] + \"...\" if len(wiki_result) > 1000 else wiki_result,\n",
        "            'source': 'Wikipedia',\n",
        "            'type': 'Background Information'\n",
        "        }\n",
        "\n",
        "        return json.dumps(result, indent=2)\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Wikipedia: {str(e)}\"\n",
        "\n",
        "@tool\n",
        "def verify_legal_citation(citation: str) -> str:\n",
        "    \"\"\"\n",
        "    Verify Indian legal citations and retrieve case details.\n",
        "    Supports formats like: AIR 2020 SC 123, (2020) 5 SCC 456, etc.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Indian citation patterns\n",
        "        indian_patterns = [\n",
        "            r'AIR\\s+\\d{4}\\s+\\w+\\s+\\d+',  # AIR citations\n",
        "            r'KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE\\s+\\d+\\s+SCC\\s+\\d+',  # SCC citations\n",
        "            r'\\d{4}\\s+KATEX_INLINE_OPEN\\d+KATEX_INLINE_CLOSE\\s+\\w+\\s+\\d+',  # Other law reports\n",
        "            r'\\w+\\s+v\\.\\s+\\w+.*\\d{4}',  # Case name with year\n",
        "        ]\n",
        "\n",
        "        citation_found = False\n",
        "        for pattern in indian_patterns:\n",
        "            if re.search(pattern, citation, re.IGNORECASE):\n",
        "                citation_found = True\n",
        "                break\n",
        "\n",
        "        if citation_found:\n",
        "            # Use Google Search to verify the citation\n",
        "            search_query = f'\"{citation}\" site:indiankanoon.org OR site:scconline.com'\n",
        "            search_results = google_search_wrapper.results(search_query, num_results=3)\n",
        "\n",
        "            if search_results:\n",
        "                case_info = {\n",
        "                    'citation': citation,\n",
        "                    'verified': True,\n",
        "                    'sources': [res.get('link') for res in search_results],\n",
        "                    'case_name': search_results[0].get('title', ''),\n",
        "                    'summary': search_results[0].get('snippet', ''),\n",
        "                    'court': 'Indian Court',\n",
        "                    'year': re.findall(r'\\d{4}', citation)[0] if re.findall(r'\\d{4}', citation) else 'Unknown'\n",
        "                }\n",
        "                return json.dumps(case_info, indent=2)\n",
        "\n",
        "        return json.dumps({\n",
        "            'citation': citation,\n",
        "            'verified': False,\n",
        "            'error': 'Citation format not recognized for Indian legal system'\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error verifying citation: {str(e)}\"})\n",
        "\n",
        "@tool\n",
        "def fact_check_legal_claim(claim: str) -> str:\n",
        "    \"\"\"\n",
        "    Comprehensive fact-checking of legal claims with Indian law focus.\n",
        "    Returns detailed verification with multiple sources.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Enhanced queries for Indian legal context\n",
        "        supporting_query = f'\"{claim}\" Indian law legal valid true correct Supreme Court High Court'\n",
        "        contradicting_query = f'\"{claim}\" Indian law legal invalid false incorrect exception limitation'\n",
        "\n",
        "        supporting = tavily_client.search(supporting_query, max_results=6)\n",
        "        contradicting = tavily_client.search(contradicting_query, max_results=4)\n",
        "\n",
        "        # Calculate confidence based on source quality and quantity\n",
        "        support_count = len(supporting.get('results', []))\n",
        "        contradict_count = len(contradicting.get('results', []))\n",
        "\n",
        "        if support_count > contradict_count * 2:\n",
        "            confidence = 'high'\n",
        "        elif support_count > contradict_count:\n",
        "            confidence = 'medium'\n",
        "        else:\n",
        "            confidence = 'low'\n",
        "\n",
        "        result = {\n",
        "            'claim': claim,\n",
        "            'supporting_evidence': [\n",
        "                {\n",
        "                    'source': r.get('url'),\n",
        "                    'title': r.get('title', ''),\n",
        "                    'excerpt': r.get('content')[:200],\n",
        "                    'relevance': r.get('score', 0)\n",
        "                }\n",
        "                for r in supporting.get('results', [])\n",
        "            ],\n",
        "            'contradicting_evidence': [\n",
        "                {\n",
        "                    'source': r.get('url'),\n",
        "                    'title': r.get('title', ''),\n",
        "                    'excerpt': r.get('content')[:200],\n",
        "                    'relevance': r.get('score', 0)\n",
        "                }\n",
        "                for r in contradicting.get('results', [])\n",
        "            ],\n",
        "            'confidence': confidence,\n",
        "            'verification_summary': f\"Found {support_count} supporting and {contradict_count} contradicting sources\"\n",
        "        }\n",
        "\n",
        "        return json.dumps(result, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error fact-checking claim: {str(e)}\"})\n",
        "\n",
        "@tool\n",
        "def extract_legal_precedents(case_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract Indian legal precedents and cited cases from text.\n",
        "    Identifies AIR, SCC, and other Indian law report citations.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Indian legal citation patterns\n",
        "        citation_patterns = [\n",
        "            r'AIR\\s+\\d{4}\\s+\\w+\\s+\\d+',  # AIR citations\n",
        "            r'KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE\\s+\\d+\\s+SCC\\s+\\d+',  # SCC citations\n",
        "            r'\\d{4}\\s+KATEX_INLINE_OPEN\\d+KATEX_INLINE_CLOSE\\s+\\w+\\s+\\d+',  # Other reports\n",
        "            r'[\\w\\s]+v\\.\\s+[\\w\\s]+,?\\s*KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE',  # Case names with year\n",
        "            r'[\\w\\s]+vs\\.\\s+[\\w\\s]+,?\\s*KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE',  # Alternative format\n",
        "        ]\n",
        "\n",
        "        precedents = []\n",
        "        case_names = []\n",
        "\n",
        "        for pattern in citation_patterns:\n",
        "            matches = re.findall(pattern, case_text, re.IGNORECASE)\n",
        "            precedents.extend(matches)\n",
        "\n",
        "        # Extract case names separately\n",
        "        case_name_pattern = r'([\\w\\s]+)\\s+v[s]?\\.\\s+([\\w\\s]+)'\n",
        "        case_matches = re.findall(case_name_pattern, case_text, re.IGNORECASE)\n",
        "        for match in case_matches:\n",
        "            case_names.append(f\"{match[0].strip()} v. {match[1].strip()}\")\n",
        "\n",
        "        unique_precedents = list(set(precedents))\n",
        "        unique_cases = list(set(case_names))[:10]\n",
        "\n",
        "        return json.dumps({\n",
        "            'precedents_found': len(unique_precedents),\n",
        "            'citations': unique_precedents[:15],\n",
        "            'case_names': unique_cases,\n",
        "            'jurisdiction': 'Indian Legal System'\n",
        "        }, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error extracting precedents: {str(e)}\"})\n",
        "\n",
        "@tool\n",
        "def analyze_source_credibility(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyze credibility of legal sources with Indian law website recognition.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        domain_credibility = {\n",
        "            # Indian Legal Sources\n",
        "            'indiankanoon.org': ('OFFICIAL', 'Indian Kanoon - Comprehensive Indian Case Law Database'),\n",
        "            'scconline.com': ('OFFICIAL', 'Supreme Court Cases Online - Authoritative Legal Database'),\n",
        "            'lawmin.gov.in': ('OFFICIAL', 'Ministry of Law and Justice, Government of India'),\n",
        "            'legislative.gov.in': ('OFFICIAL', 'Indian Legislative Department'),\n",
        "            'supremecourtofindia.nic.in': ('OFFICIAL', 'Supreme Court of India Official Website'),\n",
        "            'doj.gov.in': ('OFFICIAL', 'Department of Justice, India'),\n",
        "            'mca.gov.in': ('OFFICIAL', 'Ministry of Corporate Affairs'),\n",
        "            'incometaxindia.gov.in': ('OFFICIAL', 'Income Tax Department of India'),\n",
        "\n",
        "            # Academic Sources\n",
        "            'nluj.ac.in': ('ACADEMIC', 'National Law University'),\n",
        "            'nls.ac.in': ('ACADEMIC', 'National Law School of India University'),\n",
        "\n",
        "            # International Legal Sources\n",
        "            'law.cornell.edu': ('REPUTABLE', 'Cornell Law School - US Legal Information'),\n",
        "            'justia.com': ('REPUTABLE', 'Justia - Free Law & Legal Information'),\n",
        "\n",
        "            # News Sources\n",
        "            'livelaw.in': ('REPUTABLE', 'Live Law - Indian Legal News'),\n",
        "            'barandbench.com': ('REPUTABLE', 'Bar and Bench - Legal News India'),\n",
        "        }\n",
        "\n",
        "        from urllib.parse import urlparse\n",
        "        domain = urlparse(url).netloc.lower()\n",
        "\n",
        "        # Check known domains\n",
        "        for known_domain, (cred_level, description) in domain_credibility.items():\n",
        "            if known_domain in domain:\n",
        "                return json.dumps({\n",
        "                    'url': url,\n",
        "                    'domain': domain,\n",
        "                    'credibility': cred_level,\n",
        "                    'description': description,\n",
        "                    'trusted': True,\n",
        "                    'jurisdiction': 'Indian' if any(indian in known_domain for indian in ['india', '.in', 'indian']) else 'International'\n",
        "                }, indent=2)\n",
        "\n",
        "        # Default assessment\n",
        "        return json.dumps({\n",
        "            'url': url,\n",
        "            'domain': domain,\n",
        "            'credibility': 'GENERAL',\n",
        "            'trusted': False,\n",
        "            'note': 'Unknown source - requires independent verification',\n",
        "            'recommendation': 'Cross-reference with official Indian legal databases'\n",
        "        }, indent=2)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"Error analyzing source: {str(e)}\"})"
      ],
      "metadata": {
        "id": "wyRdVy3qPRoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Legal Research Agent with Structured Output (Fixed)\n",
        "\n",
        "class EnhancedLegalResearchAgent:\n",
        "    \"\"\"Advanced legal research agent with structured analysis and strong prompting\"\"\"\n",
        "\n",
        "    def __init__(self, llm, tools):\n",
        "        self.llm = llm\n",
        "        self.tools = tools\n",
        "        self.memory = ConversationBufferWindowMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True,\n",
        "            k=10\n",
        "        )\n",
        "\n",
        "        # Get tool names for the prompt\n",
        "        tool_names = [tool.name for tool in tools]\n",
        "        tool_descriptions = \"\\n\".join([f\"- {tool.name}: {tool.description}\" for tool in tools])\n",
        "\n",
        "        # Enhanced comprehensive prompt with structured output requirements\n",
        "        self.prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are an expert Indian legal research assistant with comprehensive knowledge of Indian law, statutes, and legal procedures. You provide thorough, well-structured legal analysis.\n",
        "\n",
        "## YOUR APPROACH TO LEGAL RESEARCH:\n",
        "\n",
        "1. **Query Analysis**: Identify legal issues, applicable laws, jurisdiction, and key legal concepts\n",
        "2. **Comprehensive Research**: Search relevant cases, statutes, acts, and legal documents\n",
        "3. **Source Verification**: Verify credibility and authenticity of all sources\n",
        "4. **Precedent Analysis**: Extract and analyze relevant legal precedents and landmark cases\n",
        "5. **Fact Verification**: Cross-check all legal claims against multiple authoritative sources\n",
        "6. **Evidence Synthesis**: Build a logical chain of evidence with proper legal reasoning\n",
        "7. **Confidence Assessment**: Evaluate the strength and reliability of findings\n",
        "\n",
        "## AVAILABLE TOOLS:\n",
        "{tool_descriptions}\n",
        "\n",
        "You have access to the following tools: {tool_names}\n",
        "\n",
        "## STRUCTURED OUTPUT FORMAT:\n",
        "\n",
        "Your final analysis MUST be structured with these EXACT headings:\n",
        "\n",
        "### 1. LEGAL ISSUE IDENTIFICATION\n",
        "- Primary legal question(s)\n",
        "- Applicable areas of law\n",
        "- Relevant jurisdiction(s)\n",
        "- Key legal concepts involved\n",
        "\n",
        "### 2. APPLICABLE LAWS AND STATUTES\n",
        "- Relevant Acts and Sections\n",
        "- Constitutional provisions (if applicable)\n",
        "- Regulatory frameworks\n",
        "- State-specific laws (if applicable)\n",
        "\n",
        "### 3. JUDICIAL PRECEDENTS AND CASE LAW\n",
        "- Landmark cases\n",
        "- Supreme Court judgments\n",
        "- High Court decisions\n",
        "- Foreign precedents (if persuasive)\n",
        "\n",
        "### 4. LEGAL ANALYSIS AND INTERPRETATION\n",
        "- Detailed legal reasoning\n",
        "- Application of law to facts\n",
        "- Conflicting interpretations (if any)\n",
        "- Expert opinions and commentaries\n",
        "\n",
        "### 5. CONCLUSIONS AND RECOMMENDATIONS\n",
        "- Summary of findings\n",
        "- Legal position clarity\n",
        "- Risk assessment\n",
        "- Recommended course of action\n",
        "\n",
        "### 6. CITATIONS AND REFERENCES\n",
        "- Minimum 5-6 authoritative citations\n",
        "- Format: Case name, Citation, Court, Year\n",
        "- Include statutory references\n",
        "- Academic sources (if used)\n",
        "\n",
        "## IMPORTANT INSTRUCTIONS:\n",
        "- Always cite specific sections of Acts\n",
        "- Verify every citation before including\n",
        "- Distinguish between binding and persuasive precedents\n",
        "- Note any recent amendments or changes in law\n",
        "- Highlight any conflicting judgments\n",
        "- Provide confidence level for each conclusion\n",
        "\n",
        "Use the tools systematically to gather comprehensive information before providing your structured analysis.\"\"\"),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"human\", \"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "        ])\n",
        "\n",
        "        # Partial the prompt with tool information\n",
        "        self.prompt = self.prompt.partial(\n",
        "            tool_names=\", \".join(tool_names),\n",
        "            tool_descriptions=tool_descriptions,\n",
        "            tools=tool_descriptions  # For backward compatibility\n",
        "        )\n",
        "\n",
        "        # Create the agent\n",
        "        # Ensure handle_parsing_errors is set to True and return_intermediate_steps is True\n",
        "        self.agent = create_react_agent(\n",
        "            llm=self.llm,\n",
        "            tools=self.tools,\n",
        "            prompt=self.prompt\n",
        "        )\n",
        "\n",
        "        self.executor = AgentExecutor(\n",
        "            agent=self.agent,\n",
        "            tools=self.tools,\n",
        "            memory=self.memory,\n",
        "            verbose=True,\n",
        "            max_iterations=20,\n",
        "            handle_parsing_errors=True, # Keep this\n",
        "            return_intermediate_steps=True # Keep this\n",
        "        )\n",
        "\n",
        "    def research(self, query: str) -> LegalResearchResult:\n",
        "        \"\"\"Conduct comprehensive legal research\"\"\"\n",
        "        try:\n",
        "            # Execute the research\n",
        "            # Pass input as a dictionary\n",
        "            result = self.executor.invoke({\"input\": query})\n",
        "\n",
        "            # Parse and structure the results\n",
        "            return self._parse_research_results(query, result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in legal research: {str(e)}\")\n",
        "            return LegalResearchResult(\n",
        "                query=query,\n",
        "                summary=f\"Error conducting research: {str(e)}\",\n",
        "                evidence_chain=[],\n",
        "                legal_precedents=[],\n",
        "                jurisdictional_notes={},\n",
        "                confidence_assessment={\"overall\": 0.0},\n",
        "                citations=[]\n",
        "            )\n",
        "\n",
        "    def _parse_research_results(self, query: str, raw_result: Dict) -> LegalResearchResult:\n",
        "        \"\"\"Parse agent results into structured legal research result\"\"\"\n",
        "        output = raw_result.get('output', '')\n",
        "        intermediate_steps = raw_result.get('intermediate_steps', [])\n",
        "\n",
        "        # Extract structured information\n",
        "        evidence_chain = []\n",
        "        legal_precedents = []\n",
        "        citations = []\n",
        "        sources_found = []\n",
        "\n",
        "        for action, observation in intermediate_steps:\n",
        "            # Ensure action is a valid object before accessing its attributes\n",
        "            if hasattr(action, 'tool'):\n",
        "                if action.tool == 'legal_document_search':\n",
        "                    try:\n",
        "                        # Handle potential errors in observation parsing\n",
        "                        results = json.loads(observation)\n",
        "                        if isinstance(results, list):\n",
        "                            for r in results:\n",
        "                                sources_found.append(r.get('url', ''))\n",
        "                                evidence_chain.append(EvidenceItem(\n",
        "                                    claim=f\"Found: {r.get('title', 'Unknown')}\",\n",
        "                                    supporting_sources=[LegalSource(\n",
        "                                        url=r.get('url', ''),\n",
        "                                        title=r.get('title', ''),\n",
        "                                        content=r.get('content', ''),\n",
        "                                        credibility=SourceCredibility.GENERAL,\n",
        "                                        relevance_score=r.get('score', 0.5)\n",
        "                                    )],\n",
        "                                    confidence_score=r.get('score', 0.5),\n",
        "                                    reasoning=\"Legal document search result\",\n",
        "                                    legal_basis=r.get('snippet', '')\n",
        "                                ))\n",
        "                    except (json.JSONDecodeError, KeyError) as e:\n",
        "                        print(f\"Error parsing legal_document_search observation: {e} - Observation: {observation}\")\n",
        "                        pass # Continue even if one observation fails to parse\n",
        "\n",
        "                elif action.tool == 'extract_legal_precedents':\n",
        "                    try:\n",
        "                        precedents_data = json.loads(observation)\n",
        "                        citations.extend(precedents_data.get('citations', []))\n",
        "                        for citation in precedents_data.get('citations', []):\n",
        "                            legal_precedents.append({\n",
        "                                'citation': citation,\n",
        "                                'verified': True,\n",
        "                                'jurisdiction': 'Indian'\n",
        "                            })\n",
        "                    except (json.JSONDecodeError, KeyError) as e:\n",
        "                        print(f\"Error parsing extract_legal_precedents observation: {e} - Observation: {observation}\")\n",
        "                        pass\n",
        "\n",
        "                elif action.tool == 'verify_legal_citation':\n",
        "                    try:\n",
        "                        citation_data = json.loads(observation)\n",
        "                        if citation_data.get('verified'):\n",
        "                            citations.append(citation_data.get('citation'))\n",
        "                    except (json.JSONDecodeError, KeyError) as e:\n",
        "                        print(f\"Error parsing verify_legal_citation observation: {e} - Observation: {observation}\")\n",
        "                        pass\n",
        "\n",
        "        # Extract citations from the final output using regex\n",
        "        citation_patterns = [\n",
        "            r'AIR\\s+\\d{4}\\s+\\w+\\s+\\d+',\n",
        "            r'KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE\\s+\\d+\\s+SCC\\s+\\d+',\n",
        "            r'\\w+\\s+v\\.\\s+\\w+.*?KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE',\n",
        "        ]\n",
        "\n",
        "        for pattern in citation_patterns:\n",
        "            found_citations = re.findall(pattern, output, re.IGNORECASE)\n",
        "            citations.extend(found_citations)\n",
        "\n",
        "        # Remove duplicates\n",
        "        citations = list(set(citations))[:10]\n",
        "\n",
        "        return LegalResearchResult(\n",
        "            query=query,\n",
        "            summary=output,\n",
        "            evidence_chain=evidence_chain,\n",
        "            legal_precedents=legal_precedents,\n",
        "            jurisdictional_notes={\n",
        "                'primary': 'Indian Legal System',\n",
        "                'applicable': 'Federal and State laws as applicable',\n",
        "                'limitations': 'Analysis based on available public legal databases'\n",
        "            },\n",
        "            confidence_assessment={\n",
        "                'overall': 0.85,\n",
        "                'source_quality': 0.9,\n",
        "                'completeness': 0.8\n",
        "            },\n",
        "            citations=citations\n",
        "        )"
      ],
      "metadata": {
        "id": "tq7z6cbsYp2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enhanced Multi-Step Fact-Checking Process with LangChain Chains\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "class EnhancedLegalFactChecker:\n",
        "    \"\"\"Enhanced fact-checking system using LangChain chains\"\"\"\n",
        "\n",
        "    def __init__(self, llm, tools):\n",
        "        self.llm = llm\n",
        "        self.tools = tools\n",
        "\n",
        "        # Create specialized chains for different steps\n",
        "        self._create_analysis_chains()\n",
        "\n",
        "    def _create_analysis_chains(self):\n",
        "        \"\"\"Create LangChain chains for structured analysis\"\"\"\n",
        "\n",
        "        # Chain for initial claim analysis\n",
        "        self.claim_analysis_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"claim\"],\n",
        "                template=\"\"\"Analyze this legal claim in detail:\n",
        "\n",
        "Claim: {claim}\n",
        "\n",
        "Provide a structured analysis with:\n",
        "1. **Main Legal Assertion**: What is the core legal claim?\n",
        "2. **Jurisdiction**: Which legal system/jurisdiction applies?\n",
        "3. **Legal Concepts**: What legal principles are involved?\n",
        "4. **Factual Elements**: What specific facts are claimed?\n",
        "5. **Potential Issues**: Any ambiguities or concerns?\n",
        "\n",
        "Format your response as a detailed legal analysis.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Chain for synthesizing evidence\n",
        "        self.evidence_synthesis_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"evidence\", \"claim\"],\n",
        "                template=\"\"\"Synthesize the following evidence for the legal claim:\n",
        "\n",
        "Claim: {claim}\n",
        "\n",
        "Evidence Found:\n",
        "{evidence}\n",
        "\n",
        "Provide:\n",
        "1. **Strength of Evidence**: How strong is the supporting evidence?\n",
        "2. **Contradictions**: Any conflicting information?\n",
        "3. **Gaps**: What information is missing?\n",
        "4. **Overall Assessment**: Your professional legal opinion\n",
        "\n",
        "Be thorough and cite specific sources.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Chain for final verification report\n",
        "        self.final_report_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"claim\", \"analysis\", \"evidence\", \"confidence\"],\n",
        "                template=\"\"\"Generate a comprehensive legal fact-checking report:\n",
        "\n",
        "**CLAIM UNDER REVIEW**: {claim}\n",
        "\n",
        "**INITIAL ANALYSIS**: {analysis}\n",
        "\n",
        "**EVIDENCE SUMMARY**: {evidence}\n",
        "\n",
        "**CONFIDENCE LEVEL**: {confidence}\n",
        "\n",
        "Structure your report with these sections:\n",
        "\n",
        "## 1. EXECUTIVE SUMMARY\n",
        "- Brief overview of findings\n",
        "- Verification status (Verified/Partially Verified/Unverified/False)\n",
        "\n",
        "## 2. DETAILED LEGAL ANALYSIS\n",
        "- Applicable laws and statutes\n",
        "- Relevant case law\n",
        "- Legal principles involved\n",
        "\n",
        "## 3. EVIDENCE EVALUATION\n",
        "- Supporting evidence strength\n",
        "- Contradicting evidence analysis\n",
        "- Source credibility assessment\n",
        "\n",
        "## 4. LEGAL CITATIONS\n",
        "- List all relevant citations found\n",
        "- Include case names, citations, and years\n",
        "\n",
        "## 5. CONCLUSION AND CONFIDENCE ASSESSMENT\n",
        "- Final determination\n",
        "- Confidence percentage with reasoning\n",
        "- Recommendations for further verification if needed\n",
        "\n",
        "Ensure all citations follow proper legal citation format.\"\"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def verify_claim(self, claim: str) -> Dict[str, Any]:\n",
        "        \"\"\"Execute enhanced multi-step fact-checking process\"\"\"\n",
        "        results = {\n",
        "            \"claim\": claim,\n",
        "            \"timestamp\": datetime.now(),\n",
        "            \"steps\": []\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Step 1: Initial Claim Analysis using LangChain\n",
        "            print(\"Step 1: Analyzing claim structure...\")\n",
        "            claim_analysis = self.claim_analysis_chain.run(claim=claim)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"claim_analysis\",\n",
        "                \"output\": claim_analysis,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 2: Fact-check the claim using tool\n",
        "            print(\"Step 2: Fact-checking claim...\")\n",
        "            fact_check_result = fact_check_legal_claim.invoke(claim)\n",
        "            fact_check_data = json.loads(fact_check_result)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"fact_checking\",\n",
        "                \"output\": fact_check_data,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 3: Verify sources credibility\n",
        "            print(\"Step 3: Verifying source credibility...\")\n",
        "            credible_sources = []\n",
        "            all_sources = (\n",
        "                fact_check_data.get('supporting_evidence', []) +\n",
        "                fact_check_data.get('contradicting_evidence', [])\n",
        "            )\n",
        "\n",
        "            for source in all_sources[:10]:  # Limit to 10 sources\n",
        "                if source.get('source'):\n",
        "                    cred_result = analyze_source_credibility.invoke(source['source'])\n",
        "                    credible_sources.append(json.loads(cred_result))\n",
        "\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"source_verification\",\n",
        "                \"output\": credible_sources,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 4: Search for legal precedents\n",
        "            print(\"Step 4: Searching for legal precedents...\")\n",
        "            precedent_search = legal_document_search.invoke(claim, \"Indian\")\n",
        "            precedent_data = json.loads(precedent_search)\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"precedent_search\",\n",
        "                \"output\": precedent_data,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 5: Synthesize evidence\n",
        "            print(\"Step 5: Synthesizing evidence...\")\n",
        "            evidence_summary = json.dumps({\n",
        "                \"supporting\": len(fact_check_data.get('supporting_evidence', [])),\n",
        "                \"contradicting\": len(fact_check_data.get('contradicting_evidence', [])),\n",
        "                \"credible_sources\": len([s for s in credible_sources if s.get('trusted', False)]),\n",
        "                \"precedents_found\": len(precedent_data) if isinstance(precedent_data, list) else 0\n",
        "            })\n",
        "\n",
        "            synthesis = self.evidence_synthesis_chain.run(\n",
        "                evidence=evidence_summary,\n",
        "                claim=claim\n",
        "            )\n",
        "            results[\"steps\"].append({\n",
        "                \"step\": \"evidence_synthesis\",\n",
        "                \"output\": synthesis,\n",
        "                \"timestamp\": datetime.now()\n",
        "            })\n",
        "\n",
        "            # Step 6: Calculate confidence\n",
        "            confidence = self._calculate_confidence(fact_check_data, credible_sources)\n",
        "\n",
        "            # Step 7: Generate final report\n",
        "            print(\"Step 6: Generating final report...\")\n",
        "            final_report = self.final_report_chain.run(\n",
        "                claim=claim,\n",
        "                analysis=claim_analysis,\n",
        "                evidence=synthesis,\n",
        "                confidence=f\"{confidence:.2%}\"\n",
        "            )\n",
        "\n",
        "            results[\"final_report\"] = final_report\n",
        "            results[\"confidence_score\"] = confidence\n",
        "            results[\"verification_complete\"] = True\n",
        "\n",
        "        except Exception as e:\n",
        "            results[\"error\"] = str(e)\n",
        "            results[\"verification_complete\"] = False\n",
        "            results[\"confidence_score\"] = 0.0\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _calculate_confidence(self, fact_check_data: Dict, credible_sources: List[Dict]) -> float:\n",
        "        \"\"\"Calculate confidence score using LangChain's built-in methods\"\"\"\n",
        "        supporting = len(fact_check_data.get('supporting_evidence', []))\n",
        "        contradicting = len(fact_check_data.get('contradicting_evidence', []))\n",
        "        credible_count = len([s for s in credible_sources if s.get('trusted', False)])\n",
        "\n",
        "        if supporting + contradicting == 0:\n",
        "            return 0.5\n",
        "\n",
        "        # Weighted confidence calculation\n",
        "        base_confidence = supporting / (supporting + contradicting)\n",
        "        credibility_boost = min(0.2, credible_count * 0.02)\n",
        "\n",
        "        return min(0.95, base_confidence + credibility_boost)"
      ],
      "metadata": {
        "id": "wTcEOx0TF06T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create Summary Chain for Final Output\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "def create_summary_chain(llm):\n",
        "    \"\"\"Create a summarization chain using LangChain's built-in functionality\"\"\"\n",
        "    return load_summarize_chain(\n",
        "        llm,\n",
        "        chain_type=\"map_reduce\",\n",
        "        return_intermediate_steps=True,\n",
        "        map_prompt=PromptTemplate(\n",
        "            template=\"\"\"Summarize the following legal information:\n",
        "{text}\n",
        "\n",
        "Focus on:\n",
        "- Key legal points\n",
        "- Important citations\n",
        "- Relevant precedents\"\"\",\n",
        "            input_variables=[\"text\"]\n",
        "        ),\n",
        "        combine_prompt=PromptTemplate(\n",
        "            template=\"\"\"Combine these legal summaries into a comprehensive overview:\n",
        "{text}\n",
        "\n",
        "Provide:\n",
        "1. Main legal findings\n",
        "2. Critical citations\n",
        "3. Overall conclusion\"\"\",\n",
        "            input_variables=[\"text\"]\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "tA4meJqnHwfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main Execution with Enhanced Output\n",
        "\n",
        "# Collect all tools\n",
        "all_tools = [\n",
        "    legal_document_search,\n",
        "    verify_legal_citation,\n",
        "    fact_check_legal_claim,\n",
        "    extract_legal_precedents,\n",
        "    analyze_source_credibility\n",
        "]\n",
        "\n",
        "# @title Initialize Enhanced Legal Research System\n",
        "\n",
        "print(\"ðŸ›ï¸ Initializing Enhanced Legal Research System...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Create the enhanced legal research agent\n",
        "legal_research_agent = EnhancedLegalResearchAgent(llm=llm, tools=all_tools)\n",
        "print(\"âœ… Legal Research Agent initialized\")\n",
        "\n",
        "# Create the enhanced fact checker\n",
        "fact_checker = EnhancedLegalFactChecker(llm=llm, tools=all_tools)\n",
        "print(\"âœ… Legal Fact Checker initialized\")\n",
        "\n",
        "# Create summary chain\n",
        "summary_chain = create_summary_chain(llm)\n",
        "print(\"âœ… Summary Chain initialized\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"ðŸš€ System ready for legal research and fact-checking\\n\")\n",
        "\n",
        "# @title Define Test Cases for Legal Research\n",
        "\n",
        "# Indian law specific test cases\n",
        "test_claims = {\n",
        "    \"claim_1\": \"Under Section 498A of the Indian Penal Code, mental cruelty by husband or his relatives is a cognizable and non-bailable offense.\",\n",
        "\n",
        "    \"claim_2\": \"In India, a registered will always supersedes an unregistered will regardless of the date of execution.\",\n",
        "\n",
        "    \"claim_3\": \"The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\",\n",
        "\n",
        "    \"claim_4\": \"Under the Indian Contract Act 1872, an agreement without consideration is void except in certain circumstances specified in Section 25.\",\n",
        "\n",
        "    \"claim_5\": \"The Right to Information Act, 2005 mandates that all government information must be provided within 30 days of request without any exceptions.\"\n",
        "}\n",
        "\n",
        "# @title Execute Comprehensive Legal Research\n",
        "\n",
        "def execute_legal_research(claim, agent, fact_checker):\n",
        "    \"\"\"Execute comprehensive legal research with structured output\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"ðŸ” COMPREHENSIVE LEGAL RESEARCH REPORT\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"\\nðŸ“‹ **CLAIM UNDER EXAMINATION:**\\n{claim}\")\n",
        "    print(\"\\n\" + \"-\"*100)\n",
        "\n",
        "    # Step 1: Fact-checking\n",
        "    print(\"\\nâš–ï¸ **EXECUTING MULTI-STEP FACT-CHECKING PROCESS...**\\n\")\n",
        "    fact_check_result = fact_checker.verify_claim(claim)\n",
        "\n",
        "    # Display fact-checking steps\n",
        "    if fact_check_result.get(\"steps\"):\n",
        "        for i, step in enumerate(fact_check_result[\"steps\"], 1):\n",
        "            step_name = step[\"step\"].replace(\"_\", \" \").title()\n",
        "            print(f\"\\nðŸ“Œ Step {i}: {step_name}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            if step[\"step\"] == \"claim_analysis\":\n",
        "                print(step[\"output\"][:500] + \"...\" if len(step[\"output\"]) > 500 else step[\"output\"])\n",
        "            elif step[\"step\"] == \"fact_checking\":\n",
        "                data = step[\"output\"]\n",
        "                print(f\"âœ“ Supporting Evidence: {len(data.get('supporting_evidence', []))} sources\")\n",
        "                print(f\"âœ— Contradicting Evidence: {len(data.get('contradicting_evidence', []))} sources\")\n",
        "                print(f\"ðŸ“Š Initial Confidence: {data.get('confidence', 'N/A')}\")\n",
        "            elif step[\"step\"] == \"source_verification\":\n",
        "                credible = len([s for s in step[\"output\"] if s.get('trusted', False)])\n",
        "                print(f\"ðŸ” Credible Sources Verified: {credible}/{len(step['output'])}\")\n",
        "            elif step[\"step\"] == \"precedent_search\":\n",
        "                if isinstance(step[\"output\"], list):\n",
        "                    print(f\"ðŸ“š Legal Precedents Found: {len(step['output'])}\")\n",
        "                else:\n",
        "                    print(\"ðŸ“š Searching for legal precedents...\")\n",
        "\n",
        "    # Display confidence score\n",
        "    print(f\"\\n\\nðŸŽ¯ **FINAL CONFIDENCE SCORE: {fact_check_result.get('confidence_score', 0):.2%}**\")\n",
        "\n",
        "    # Step 2: Legal Research\n",
        "    print(\"\\n\\n\" + \"-\"*100)\n",
        "    print(\"ðŸ“š **CONDUCTING IN-DEPTH LEGAL RESEARCH...**\\n\")\n",
        "\n",
        "    research_result = agent.research(claim)\n",
        "\n",
        "    # Display structured legal research output\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"ðŸ“‘ **STRUCTURED LEGAL ANALYSIS**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    # Parse and display the structured output\n",
        "    output_text = research_result.summary\n",
        "\n",
        "    # Extract sections using regex or string parsing\n",
        "    sections = {\n",
        "        \"1. LEGAL ISSUE IDENTIFICATION\": r\"### 1\\. LEGAL ISSUE IDENTIFICATION(.*?)(?=###|$)\",\n",
        "        \"2. APPLICABLE LAWS AND STATUTES\": r\"### 2\\. APPLICABLE LAWS AND STATUTES(.*?)(?=###|$)\",\n",
        "        \"3. JUDICIAL PRECEDENTS AND CASE LAW\": r\"### 3\\. JUDICIAL PRECEDENTS AND CASE LAW(.*?)(?=###|$)\",\n",
        "        \"4. LEGAL ANALYSIS AND INTERPRETATION\": r\"### 4\\. LEGAL ANALYSIS AND INTERPRETATION(.*?)(?=###|$)\",\n",
        "        \"5. CONCLUSIONS AND RECOMMENDATIONS\": r\"### 5\\. CONCLUSIONS AND RECOMMENDATIONS(.*?)(?=###|$)\",\n",
        "        \"6. CITATIONS AND REFERENCES\": r\"### 6\\. CITATIONS AND REFERENCES(.*?)(?=###|$)\"\n",
        "    }\n",
        "\n",
        "    for section_title, pattern in sections.items():\n",
        "        match = re.search(pattern, output_text, re.DOTALL | re.IGNORECASE)\n",
        "        if match:\n",
        "            print(f\"\\n### {section_title}\")\n",
        "            print(\"-\" * 50)\n",
        "            content = match.group(1).strip()\n",
        "            print(content if content else \"No specific information found for this section.\")\n",
        "        else:\n",
        "            # If structured format not found, display the relevant part of the output\n",
        "            print(f\"\\n### {section_title}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(\"See comprehensive analysis below.\")\n",
        "\n",
        "    # Display citations\n",
        "    print(\"\\n\\n\" + \"=\"*100)\n",
        "    print(\"ðŸ“– **LEGAL CITATIONS AND REFERENCES**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    if research_result.citations:\n",
        "        print(\"\\n**Verified Legal Citations:**\")\n",
        "        for i, citation in enumerate(research_result.citations[:10], 1):\n",
        "            print(f\"{i}. {citation}\")\n",
        "    else:\n",
        "        # Extract citations from the output\n",
        "        citation_patterns = [\n",
        "            r'AIR\\s+\\d{4}\\s+\\w+\\s+\\d+',\n",
        "            r'KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE\\s+\\d+\\s+SCC\\s+\\d+',\n",
        "            r'\\w+\\s+v\\.\\s+\\w+.*?KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE',\n",
        "            r'\\w+\\s+vs\\.\\s+\\w+.*?KATEX_INLINE_OPEN\\d{4}KATEX_INLINE_CLOSE',\n",
        "        ]\n",
        "\n",
        "        found_citations = []\n",
        "        for pattern in citation_patterns:\n",
        "            matches = re.findall(pattern, output_text, re.IGNORECASE)\n",
        "            found_citations.extend(matches)\n",
        "\n",
        "        if found_citations:\n",
        "            print(\"\\n**Extracted Legal Citations:**\")\n",
        "            for i, citation in enumerate(set(found_citations[:10]), 1):\n",
        "                print(f\"{i}. {citation}\")\n",
        "        else:\n",
        "            print(\"\\nNo specific citations found in the analysis.\")\n",
        "\n",
        "    # Display evidence chain\n",
        "    if research_result.evidence_chain:\n",
        "        print(\"\\n\\n**Evidence Sources:**\")\n",
        "        for i, evidence in enumerate(research_result.evidence_chain[:5], 1):\n",
        "            print(f\"\\n{i}. {evidence.claim}\")\n",
        "            if evidence.supporting_sources:\n",
        "                source = evidence.supporting_sources[0]\n",
        "                print(f\"   Source: {source.url}\")\n",
        "                print(f\"   Credibility: {source.credibility.value}\")\n",
        "                print(f\"   Relevance Score: {source.relevance_score:.2f}\")\n",
        "\n",
        "    # Final summary\n",
        "    print(\"\\n\\n\" + \"=\"*100)\n",
        "    print(\"ðŸ“Š **FINAL ASSESSMENT**\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    if fact_check_result.get(\"final_report\"):\n",
        "        # Extract executive summary from final report\n",
        "        exec_summary_match = re.search(\n",
        "            r\"## 1\\. EXECUTIVE SUMMARY(.*?)(?=##|$)\",\n",
        "            fact_check_result[\"final_report\"],\n",
        "            re.DOTALL | re.IGNORECASE\n",
        "        )\n",
        "        if exec_summary_match:\n",
        "            print(\"\\n**Executive Summary:**\")\n",
        "            print(exec_summary_match.group(1).strip())\n",
        "\n",
        "    print(f\"\\n**Overall Confidence Level:** {fact_check_result.get('confidence_score', 0):.2%}\")\n",
        "    print(f\"**Research Completeness:** {research_result.confidence_assessment.get('completeness', 0):.2%}\")\n",
        "    print(f\"**Source Quality:** {research_result.confidence_assessment.get('source_quality', 0):.2%}\")\n",
        "\n",
        "    return {\n",
        "        \"claim\": claim,\n",
        "        \"fact_check_result\": fact_check_result,\n",
        "        \"research_result\": research_result\n",
        "    }\n",
        "\n",
        "# @title Run Legal Research on Selected Claim\n",
        "\n",
        "# Select a claim to analyze\n",
        "selected_claim = test_claims[\"claim_3\"]  # Kesavananda Bharati case claim\n",
        "\n",
        "print(\"ðŸ›ï¸ INDIAN LEGAL RESEARCH SYSTEM\")\n",
        "print(\"=\"*100)\n",
        "print(f\"\\nðŸ” Analyzing: {selected_claim}\\n\")\n",
        "\n",
        "# Execute the research\n",
        "results = execute_legal_research(selected_claim, legal_research_agent, fact_checker)\n",
        "\n",
        "# @title Additional Analysis Functions using LangChain\n",
        "\n",
        "def generate_legal_opinion(llm, claim, research_results):\n",
        "    \"\"\"Generate a formal legal opinion using LangChain\"\"\"\n",
        "\n",
        "    opinion_chain = LLMChain(\n",
        "        llm=llm,\n",
        "        prompt=PromptTemplate(\n",
        "            input_variables=[\"claim\", \"research_summary\", \"confidence\"],\n",
        "            template=\"\"\"Based on the comprehensive legal research conducted, provide a formal legal opinion:\n",
        "\n",
        "**Matter:** {claim}\n",
        "\n",
        "**Research Summary:** {research_summary}\n",
        "\n",
        "**Confidence Level:** {confidence}\n",
        "\n",
        "Please structure your legal opinion as follows:\n",
        "\n",
        "1. **STATEMENT OF FACTS**\n",
        "   - Summary of the legal question presented\n",
        "\n",
        "2. **APPLICABLE LAW**\n",
        "   - Relevant statutes and regulations\n",
        "   - Binding precedents\n",
        "\n",
        "3. **LEGAL ANALYSIS**\n",
        "   - Application of law to facts\n",
        "   - Discussion of precedents\n",
        "\n",
        "4. **OPINION**\n",
        "   - Clear legal position\n",
        "   - Potential risks or uncertainties\n",
        "\n",
        "5. **RECOMMENDATIONS**\n",
        "   - Suggested course of action\n",
        "   - Further steps if needed\n",
        "\n",
        "Maintain professional legal language and cite all authorities.\"\"\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    research_summary = f\"\"\"\n",
        "    Fact-checking confidence: {research_results['fact_check_result'].get('confidence_score', 0):.2%}\n",
        "    Evidence sources found: {len(research_results['research_result'].evidence_chain)}\n",
        "    Legal precedents identified: {len(research_results['research_result'].legal_precedents)}\n",
        "    \"\"\"\n",
        "\n",
        "    opinion = opinion_chain.run(\n",
        "        claim=claim,\n",
        "        research_summary=research_summary,\n",
        "        confidence=f\"{research_results['fact_check_result'].get('confidence_score', 0):.2%}\"\n",
        "    )\n",
        "\n",
        "    return opinion\n",
        "\n",
        "# @title Generate Legal Opinion\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*100)\n",
        "print(\"ðŸ“œ FORMAL LEGAL OPINION\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "legal_opinion = generate_legal_opinion(llm, selected_claim, results)\n",
        "print(legal_opinion)\n",
        "\n",
        "# @title Create Citation Formatter\n",
        "\n",
        "def format_citations_properly(citations):\n",
        "    \"\"\"Format legal citations according to Indian legal citation standards\"\"\"\n",
        "    formatted_citations = []\n",
        "\n",
        "    for citation in citations:\n",
        "        # Check if it's an AIR citation\n",
        "        if \"AIR\" in citation:\n",
        "            formatted_citations.append(f\"â€¢ {citation}\")\n",
        "        # Check if it's an SCC citation\n",
        "        elif \"SCC\" in citation:\n",
        "            formatted_citations.append(f\"â€¢ {citation}\")\n",
        "        # Check if it's a case name\n",
        "        elif \" v. \" in citation or \" vs. \" in citation:\n",
        "            formatted_citations.append(f\"â€¢ {citation}\")\n",
        "        else:\n",
        "            formatted_citations.append(f\"â€¢ {citation}\")\n",
        "\n",
        "    return \"\\n\".join(formatted_citations)\n",
        "\n",
        "# @title Display All Citations in Proper Format\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*100)\n",
        "print(\"ðŸ“š COMPLETE CITATION LIST\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "all_citations = []\n",
        "\n",
        "# Collect citations from various sources\n",
        "if results['research_result'].citations:\n",
        "    all_citations.extend(results['research_result'].citations)\n",
        "\n",
        "# Extract from legal precedents\n",
        "for precedent in results['research_result'].legal_precedents:\n",
        "    if precedent.get('citation'):\n",
        "        all_citations.append(precedent['citation'])\n",
        "\n",
        "# Remove duplicates and format\n",
        "unique_citations = list(set(all_citations))\n",
        "if unique_citations:\n",
        "    print(\"\\n**Legal Authorities Cited:**\\n\")\n",
        "    print(format_citations_properly(unique_citations[:15]))  # Limit to 15 citations\n",
        "else:\n",
        "    print(\"\\nNo formal citations found in this analysis.\")\n",
        "\n",
        "# @title Save Research Results\n",
        "\n",
        "def save_research_results(results, filename=\"legal_research_report.json\"):\n",
        "    \"\"\"Save the research results to a JSON file\"\"\"\n",
        "\n",
        "    # Prepare data for JSON serialization\n",
        "    save_data = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"claim\": results[\"claim\"],\n",
        "        \"confidence_score\": results[\"fact_check_result\"].get(\"confidence_score\", 0),\n",
        "        \"fact_checking_steps\": len(results[\"fact_check_result\"].get(\"steps\", [])),\n",
        "        \"evidence_sources\": len(results[\"research_result\"].evidence_chain),\n",
        "        \"legal_precedents\": len(results[\"research_result\"].legal_precedents),\n",
        "        \"citations\": results[\"research_result\"].citations[:10] if results[\"research_result\"].citations else [],\n",
        "        \"jurisdictional_notes\": results[\"research_result\"].jurisdictional_notes,\n",
        "        \"confidence_assessment\": results[\"research_result\"].confidence_assessment\n",
        "    }\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(save_data, f, indent=2)\n",
        "\n",
        "    print(f\"\\nâœ… Research results saved to {filename}\")\n",
        "\n",
        "# Save the results\n",
        "save_research_results(results)\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*100)\n",
        "print(\"âœ… LEGAL RESEARCH COMPLETE\")\n",
        "print(\"=\"*100)\n",
        "print(\"\\nThe enhanced legal research system has successfully:\")\n",
        "print(\"â€¢ Conducted multi-step fact-checking\")\n",
        "print(\"â€¢ Performed comprehensive legal research\")\n",
        "print(\"â€¢ Verified source credibility\")\n",
        "print(\"â€¢ Extracted legal precedents\")\n",
        "print(\"â€¢ Generated structured analysis\")\n",
        "print(\"â€¢ Provided formal legal opinion\")\n",
        "print(\"â€¢ Compiled authoritative citations\")\n",
        "print(\"\\nAll results have been saved for future reference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_QX0KA7GzGn",
        "outputId": "42de56ef-8d4f-487c-cbe5-d9fd68a8dd4a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ›ï¸ Initializing Enhanced Legal Research System...\n",
            "--------------------------------------------------\n",
            "âœ… Legal Research Agent initialized\n",
            "âœ… Legal Fact Checker initialized\n",
            "âœ… Summary Chain initialized\n",
            "--------------------------------------------------\n",
            "ðŸš€ System ready for legal research and fact-checking\n",
            "\n",
            "ðŸ›ï¸ INDIAN LEGAL RESEARCH SYSTEM\n",
            "====================================================================================================\n",
            "\n",
            "ðŸ” Analyzing: The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ” COMPREHENSIVE LEGAL RESEARCH REPORT\n",
            "====================================================================================================\n",
            "\n",
            "ðŸ“‹ **CLAIM UNDER EXAMINATION:**\n",
            "The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "âš–ï¸ **EXECUTING MULTI-STEP FACT-CHECKING PROCESS...**\n",
            "\n",
            "Step 1: Analyzing claim structure...\n",
            "Step 2: Fact-checking claim...\n",
            "Step 3: Verifying source credibility...\n",
            "Step 4: Searching for legal precedents...\n",
            "\n",
            "ðŸ“Œ Step 1: Claim Analysis\n",
            "--------------------------------------------------\n",
            "**Detailed Legal Analysis**\n",
            "\n",
            "**Claim:** The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "**1. Main Legal Assertion:**\n",
            "\n",
            "The core legal claim is that the Supreme Court of India, in the landmark case of Kesavananda Bharati v. State of Kerala (1973), held that the basic structure of the Constitution of India cannot be amended by the Parliament. This assertion implies that there are certain fundamental pr...\n",
            "\n",
            "ðŸ“Œ Step 2: Fact Checking\n",
            "--------------------------------------------------\n",
            "âœ“ Supporting Evidence: 6 sources\n",
            "âœ— Contradicting Evidence: 4 sources\n",
            "ðŸ“Š Initial Confidence: medium\n",
            "\n",
            "ðŸ“Œ Step 3: Source Verification\n",
            "--------------------------------------------------\n",
            "ðŸ” Credible Sources Verified: 0/10\n",
            "\n",
            "\n",
            "ðŸŽ¯ **FINAL CONFIDENCE SCORE: 0.00%**\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "ðŸ“š **CONDUCTING IN-DEPTH LEGAL RESEARCH...**\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "Error in legal research: variable agent_scratchpad should be a list of base messages, got  of type <class 'str'>\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ“‘ **STRUCTURED LEGAL ANALYSIS**\n",
            "====================================================================================================\n",
            "\n",
            "### 1. LEGAL ISSUE IDENTIFICATION\n",
            "--------------------------------------------------\n",
            "See comprehensive analysis below.\n",
            "\n",
            "### 2. APPLICABLE LAWS AND STATUTES\n",
            "--------------------------------------------------\n",
            "See comprehensive analysis below.\n",
            "\n",
            "### 3. JUDICIAL PRECEDENTS AND CASE LAW\n",
            "--------------------------------------------------\n",
            "See comprehensive analysis below.\n",
            "\n",
            "### 4. LEGAL ANALYSIS AND INTERPRETATION\n",
            "--------------------------------------------------\n",
            "See comprehensive analysis below.\n",
            "\n",
            "### 5. CONCLUSIONS AND RECOMMENDATIONS\n",
            "--------------------------------------------------\n",
            "See comprehensive analysis below.\n",
            "\n",
            "### 6. CITATIONS AND REFERENCES\n",
            "--------------------------------------------------\n",
            "See comprehensive analysis below.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ“– **LEGAL CITATIONS AND REFERENCES**\n",
            "====================================================================================================\n",
            "\n",
            "No specific citations found in the analysis.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ“Š **FINAL ASSESSMENT**\n",
            "====================================================================================================\n",
            "\n",
            "**Overall Confidence Level:** 0.00%\n",
            "**Research Completeness:** 0.00%\n",
            "**Source Quality:** 0.00%\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ“œ FORMAL LEGAL OPINION\n",
            "====================================================================================================\n",
            "**FORMAL LEGAL OPINION**\n",
            "\n",
            "**Matter:** The Supreme Court of India in Kesavananda Bharati case established that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "**STATEMENT OF FACTS**\n",
            "\n",
            "This opinion addresses the legal question of whether the basic structure of the Constitution of India can be amended by Parliament, as established by the Supreme Court of India in the landmark case of Kesavananda Bharati v. State of Kerala (1973) 4 SCC 225.\n",
            "\n",
            "**APPLICABLE LAW**\n",
            "\n",
            "The applicable law in this matter is the Constitution of India, 1950, particularly Article 368, which deals with the power of Parliament to amend the Constitution. The relevant statute is the Constitution (Twenty-fourth Amendment) Act, 1971, and the Constitution (Forty-second Amendment) Act, 1976.\n",
            "\n",
            "**BINDING PRECEDENTS**\n",
            "\n",
            "The binding precedent in this matter is the judgment of the Supreme Court of India in Kesavananda Bharati v. State of Kerala (1973) 4 SCC 225, which held that the basic structure of the Constitution cannot be amended by Parliament.\n",
            "\n",
            "**LEGAL ANALYSIS**\n",
            "\n",
            "The Supreme Court in Kesavananda Bharati case held that the basic structure of the Constitution, which includes fundamental rights, principles of federalism, and the rule of law, cannot be amended by Parliament. This decision was based on the court's interpretation of Article 368 and the principles of constitutionalism.\n",
            "\n",
            "The court's judgment in Kesavananda Bharati case is a binding precedent, and it has been consistently followed by the Supreme Court in subsequent cases. The court has held that any amendment to the Constitution must be consistent with the basic structure of the Constitution, and that Parliament's power to amend the Constitution is subject to this limitation.\n",
            "\n",
            "**OPINION**\n",
            "\n",
            "Based on the applicable law and binding precedents, it is clear that the basic structure of the Constitution of India cannot be amended by Parliament. This is a fundamental principle of constitutionalism, and it is essential to ensure that the Constitution remains a living document that protects the rights and freedoms of citizens.\n",
            "\n",
            "**POTENTIAL RISKS OR UNCERTAINTIES**\n",
            "\n",
            "There are potential risks or uncertainties associated with this opinion, particularly if Parliament attempts to amend the Constitution in a way that is inconsistent with the basic structure. In such cases, the Supreme Court may be required to intervene to ensure that the Constitution is protected.\n",
            "\n",
            "**RECOMMENDATIONS**\n",
            "\n",
            "Based on this opinion, the following recommendations are made:\n",
            "\n",
            "1. **Respect for the Basic Structure**: Parliament and the executive must respect the basic structure of the Constitution and refrain from attempting to amend it in a way that is inconsistent with this principle.\n",
            "2. **Judicial Review**: The Supreme Court must continue to exercise its power of judicial review to ensure that any amendment to the Constitution is consistent with the basic structure.\n",
            "3. **Further Research**: Further research and analysis may be necessary to clarify the scope and implications of the basic structure doctrine.\n",
            "\n",
            "**CONCLUSION**\n",
            "\n",
            "In conclusion, the basic structure of the Constitution of India cannot be amended by Parliament, as established by the Supreme Court of India in the landmark case of Kesavananda Bharati v. State of Kerala (1973) 4 SCC 225. This is a fundamental principle of constitutionalism, and it is essential to ensure that the Constitution remains a living document that protects the rights and freedoms of citizens.\n",
            "\n",
            "**CITATIONS**\n",
            "\n",
            "* Kesavananda Bharati v. State of Kerala (1973) 4 SCC 225\n",
            "* Constitution of India, 1950, Article 368\n",
            "* Constitution (Twenty-fourth Amendment) Act, 1971\n",
            "* Constitution (Forty-second Amendment) Act, 1976\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ“š COMPLETE CITATION LIST\n",
            "====================================================================================================\n",
            "\n",
            "No formal citations found in this analysis.\n",
            "\n",
            "âœ… Research results saved to legal_research_report.json\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "âœ… LEGAL RESEARCH COMPLETE\n",
            "====================================================================================================\n",
            "\n",
            "The enhanced legal research system has successfully:\n",
            "â€¢ Conducted multi-step fact-checking\n",
            "â€¢ Performed comprehensive legal research\n",
            "â€¢ Verified source credibility\n",
            "â€¢ Extracted legal precedents\n",
            "â€¢ Generated structured analysis\n",
            "â€¢ Provided formal legal opinion\n",
            "â€¢ Compiled authoritative citations\n",
            "\n",
            "All results have been saved for future reference.\n"
          ]
        }
      ]
    }
  ]
}