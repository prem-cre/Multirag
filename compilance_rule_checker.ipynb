{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIPfP0gAE/8l1GHb991QhI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prem-cre/Multirag/blob/main/compilance_rule_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-0szLc820gc7"
      },
      "outputs": [],
      "source": [
        "# @title Install Required Packages\n",
        "!pip install -q langchain langchain_groq langchain-community langchain-huggingface \\\n",
        "    langgraph faiss-cpu pypdf sentence-transformers langchain-google-genai pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configure API Keys, LLM, and FAISS Vector Store\n",
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import re\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "# API Keys\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq')\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Initialize LLM - Using a fast model is key for performance\n",
        "llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0)\n",
        "\n",
        "# Initialize embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")\n",
        "\n",
        "def read_documents(directory_path: str):\n",
        "    \"\"\"Loads PDF documents from a specified directory.\"\"\"\n",
        "    loader = PyPDFDirectoryLoader(directory_path)\n",
        "    documents = loader.load()\n",
        "    return documents\n",
        "\n",
        "def chunk_data(docs, chunk_size=1100, chunk_overlap=70):\n",
        "    \"\"\"Splits documents into smaller chunks.\"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "    return chunks\n",
        "\n",
        "# Define paths\n",
        "FAISS_DB_PATH = \"faiss_index\"\n",
        "DOCUMENT_LIST_PATH = \"indexed_documents.pkl\"\n",
        "\n",
        "# Get current PDF files\n",
        "current_pdf_files = sorted(glob.glob('/content/*.pdf'))\n",
        "\n",
        "# Load previously indexed documents\n",
        "indexed_pdf_files = []\n",
        "if os.path.exists(DOCUMENT_LIST_PATH):\n",
        "    with open(DOCUMENT_LIST_PATH, 'rb') as f:\n",
        "        indexed_pdf_files = pickle.load(f)\n",
        "\n",
        "# Check if rebuild needed\n",
        "if os.path.exists(FAISS_DB_PATH) and current_pdf_files == indexed_pdf_files:\n",
        "    vector_store = FAISS.load_local(FAISS_DB_PATH, embeddings, allow_dangerous_deserialization=True)\n",
        "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5}) # Reduced k for faster retrieval\n",
        "    print(\"âœ“ Loaded existing FAISS index\")\n",
        "else:\n",
        "    docs = read_documents('/content/')\n",
        "    documents = chunk_data(docs)\n",
        "\n",
        "    if documents:\n",
        "        vector_store = FAISS.from_documents(documents, embeddings)\n",
        "        retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "        vector_store.save_local(FAISS_DB_PATH)\n",
        "        with open(DOCUMENT_LIST_PATH, 'wb') as f:\n",
        "            pickle.dump(current_pdf_files, f)\n",
        "        print(f\"âœ“ Created new FAISS index with {len(documents)} chunks\")\n",
        "    else:\n",
        "        vector_store = None\n",
        "        retriever = None\n",
        "        print(\"âš  No documents found - using fallback context\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS9I0bP70jsP",
        "outputId": "37ba8461-d207-41ab-dafe-04e62b4ee06d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš  No documents found - using fallback context\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Pydantic Models for Structured Output\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class CheckResult(BaseModel):\n",
        "    \"\"\"Represents the result of a single check (primary or secondary).\"\"\"\n",
        "    violation_score: float = Field(..., description=\"A score from 0.0 (compliant) to 1.0 (severe violations).\")\n",
        "    has_violations: bool = Field(..., description=\"True if the score indicates a violation, otherwise false.\")\n",
        "    violation_types: List[str] = Field(..., description=\"A list of specific violation types found.\")\n",
        "    summary: str = Field(..., description=\"A brief summary of the findings.\")\n",
        "\n",
        "class ParallelChecksResult(BaseModel):\n",
        "    \"\"\"The combined output of the parallel analysis in a single structure.\"\"\"\n",
        "    primary_check: CheckResult = Field(..., description=\"Results from the critical legal accuracy check.\")\n",
        "    secondary_check: CheckResult = Field(..., description=\"Results from the compliance and professional standards check.\")\n",
        "\n",
        "class ViolationDetail(BaseModel):\n",
        "    \"\"\"Detailed information about a single violation found in a sentence.\"\"\"\n",
        "    sentence: str = Field(..., description=\"The exact sentence where the violation occurred.\")\n",
        "    violation_type: str = Field(..., description=\"The specific type of violation detected.\")\n",
        "    severity: str = Field(..., description=\"The severity of the violation (critical, high, medium, low).\")\n",
        "    explanation: str = Field(..., description=\"A concise explanation of why the sentence is a violation.\")\n",
        "\n",
        "class ViolationAnalysisResult(BaseModel):\n",
        "    \"\"\"The complete list of all detailed violations found in the text.\"\"\"\n",
        "    violations: List[ViolationDetail] = Field(..., description=\"A list of all violation details. Should be empty if no violations are found.\")"
      ],
      "metadata": {
        "id": "XfU79EKH0kwz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define State Schema\n",
        "from typing import TypedDict, List, Dict, Any\n",
        "\n",
        "class ComplianceState(TypedDict):\n",
        "    input_text: str\n",
        "    context: str  # To hold context from FAISS\n",
        "    primary_check: Dict[str, Any]\n",
        "    secondary_check: Dict[str, Any]\n",
        "    merged_check: Dict[str, Any]\n",
        "    violations: List[Dict[str, Any]]\n",
        "    final_output: Dict[str, Any]"
      ],
      "metadata": {
        "id": "WGlwxaew0ofi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title New Node: Retrieve Context from FAISS\n",
        "def retrieve_context(state: ComplianceState) -> dict:\n",
        "    \"\"\"Retrieves relevant context from the FAISS vector store.\"\"\"\n",
        "    print(\"ðŸ”Ž Retrieving context from FAISS...\")\n",
        "    if not retriever:\n",
        "        print(\"   - No retriever available. Skipping.\")\n",
        "        return {\"context\": \"No external context provided.\"}\n",
        "\n",
        "    retrieved_docs = retriever.invoke(state[\"input_text\"])\n",
        "    context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "    print(f\"   - Retrieved {len(retrieved_docs)} context chunks.\")\n",
        "    return {\"context\": context}"
      ],
      "metadata": {
        "id": "6AZCyaKF0ocH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fast Parallel Check Node (1 LLM Call)\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "\n",
        "def fast_parallel_initial_check(state: ComplianceState) -> dict:\n",
        "    \"\"\"\n",
        "    Runs a single, powerful LLM check that simulates two experts (Primary and Secondary)\n",
        "    and merges the results intelligently. This is the main speed improvement.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸš€ RUNNING FAST PARALLEL VIOLATION DETECTION (1 LLM Call)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Use the structured_output feature for reliable JSON\n",
        "    structured_llm = llm.with_structured_output(ParallelChecksResult)\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a dual-persona legal analysis AI. You must analyze the text from two perspectives simultaneously: a Critical Legal Expert and a Compliance Auditor.\n",
        "\n",
        "**Relevant Legal Context from Documents:**\n",
        "{context}\n",
        "\n",
        "**Text to Analyze:**\n",
        "{text}\n",
        "\n",
        "**Instructions:**\n",
        "Analyze the text and provide a single JSON response containing two nested objects: `primary_check` and `secondary_check`.\n",
        "\n",
        "**1. Primary Check (Critical Legal Expert Persona):**\n",
        "   - **Focus:** CRITICAL legal violations, factual falsehoods, dangerous misinformation.\n",
        "   - **Scoring:** 0.0 (accurate) to 1.0 (severely incorrect).\n",
        "   - **Ignore:** Minor tone/grammar issues.\n",
        "\n",
        "**2. Secondary Check (Compliance Auditor Persona):**\n",
        "   - **Focus:** Policy violations (grPC, LawVriksh), unprofessional language, missing citations, ambiguity.\n",
        "   - **Scoring:** 0.0 (compliant) to 1.0 (major compliance failures).\n",
        "   - **Ignore:** Minor typos.\n",
        "\n",
        "Provide your complete analysis in the required JSON format. Ensure all strings are valid.\n",
        "\"\"\")\n",
        "\n",
        "    chain = prompt | structured_llm\n",
        "\n",
        "    try:\n",
        "        result: ParallelChecksResult = chain.invoke({\n",
        "            \"text\": state[\"input_text\"],\n",
        "            \"context\": state[\"context\"]\n",
        "        })\n",
        "    except (OutputParserException, Exception) as e:\n",
        "        print(f\"   - âš  Error in parallel check. Using fallback. Error: {e}\")\n",
        "        # Fallback to a default non-violating state to prevent crash\n",
        "        result = ParallelChecksResult(\n",
        "            primary_check=CheckResult(violation_score=0, has_violations=False, violation_types=[], summary=\"Error parsing initial check.\"),\n",
        "            secondary_check=CheckResult(violation_score=0, has_violations=False, violation_types=[], summary=\"Error parsing initial check.\")\n",
        "        )\n",
        "\n",
        "\n",
        "    # FIX: Replaced .dict() with .model_dump()\n",
        "    primary_result = result.primary_check.model_dump()\n",
        "    secondary_result = result.secondary_check.model_dump()\n",
        "\n",
        "    # --- Intelligent Merging Logic (Identical to your original code) ---\n",
        "    primary_score = primary_result.get(\"violation_score\", 0)\n",
        "    secondary_score = secondary_result.get(\"violation_score\", 0)\n",
        "    merged_score = (primary_score * 0.65) + (secondary_score * 0.35)\n",
        "\n",
        "    primary_types = set(primary_result.get(\"violation_types\", []))\n",
        "    secondary_types = set(secondary_result.get(\"violation_types\", []))\n",
        "    all_violation_types = list(primary_types.union(secondary_types))\n",
        "\n",
        "    has_violations = (\n",
        "        merged_score >= 0.3 or\n",
        "        primary_score >= 0.5 or\n",
        "        secondary_score >= 0.6\n",
        "    )\n",
        "\n",
        "    combined_summary = f\"\"\"Critical Analysis: {primary_result.get('summary', 'N/A')}\n",
        "Compliance Analysis: {secondary_result.get('summary', 'N/A')}\"\"\"\n",
        "\n",
        "    merged_result = {\n",
        "        \"violation_score\": round(merged_score, 2),\n",
        "        \"has_violations\": has_violations,\n",
        "        \"violation_types\": all_violation_types,\n",
        "        \"summary\": combined_summary.strip(),\n",
        "        \"primary_score\": round(primary_score, 2),\n",
        "        \"secondary_score\": round(secondary_score, 2),\n",
        "        \"detection_confidence\": \"high\" if abs(primary_score - secondary_score) < 0.25 else \"medium\"\n",
        "    }\n",
        "\n",
        "    print(f\"Primary Check Score: {primary_score:.2f}\")\n",
        "    print(f\"Secondary Check Score: {secondary_score:.2f}\")\n",
        "    print(f\"\\nðŸ“Š Merged Score: {merged_score:.2f}\")\n",
        "    print(f\"   Violations Detected: {has_violations}\")\n",
        "    print(f\"   Confidence: {merged_result['detection_confidence']}\")\n",
        "\n",
        "    return {\n",
        "        \"primary_check\": primary_result,\n",
        "        \"secondary_check\": secondary_result,\n",
        "        \"merged_check\": merged_result\n",
        "    }"
      ],
      "metadata": {
        "id": "r-FgL9wl0oZm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Conditional Router - Decides Next Step\n",
        "def should_continue(state: ComplianceState) -> str:\n",
        "    \"\"\"\n",
        "    Route based on merged violation detection.\n",
        "    If violations detected, perform detailed sentence-level analysis.\n",
        "    Otherwise, skip to no violations output.\n",
        "    \"\"\"\n",
        "    merged_check = state[\"merged_check\"]\n",
        "    has_violations = merged_check.get(\"has_violations\", False)\n",
        "    score = merged_check.get(\"violation_score\", 0)\n",
        "\n",
        "    print(f\"\\nðŸ”€ Routing Decision: {'ANALYZE VIOLATIONS' if has_violations else 'NO VIOLATIONS'}\")\n",
        "    print(f\"   (Score: {score}, Threshold: 0.3)\\n\")\n",
        "\n",
        "    if has_violations:\n",
        "        return \"analyze_violations\"\n",
        "    else:\n",
        "        return \"no_violations_output\""
      ],
      "metadata": {
        "id": "5XPKm1CR0oXD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Holistic Detailed Violation Analysis (1 LLM Call)\n",
        "from groq.types.chat import ChatCompletion\n",
        "from groq import BadRequestError\n",
        "\n",
        "def holistic_sentence_analysis(state: ComplianceState) -> dict:\n",
        "    \"\"\"\n",
        "    Performs a single, holistic, sentence-level analysis of the entire text,\n",
        "    returning a structured list of all violations. Replaces the slow loop.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"âš¡ RUNNING HOLISTIC SENTENCE-LEVEL ANALYSIS (1 LLM Call)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    structured_llm = llm.with_structured_output(ViolationAnalysisResult)\n",
        "    merged_check = state[\"merged_check\"]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a legal compliance analyst. An initial screening of the text below has detected potential violations. Your task is to perform a detailed analysis and identify every specific sentence that contains a violation.\n",
        "\n",
        "**Initial Findings Summary:**\n",
        "{summary}\n",
        "\n",
        "**Potential Violation Types Detected:**\n",
        "{violation_types}\n",
        "\n",
        "**Relevant Legal Context from Documents:**\n",
        "{context}\n",
        "\n",
        "**Full Text to Analyze:**\n",
        "{text}\n",
        "\n",
        "**Instructions:**\n",
        "1. Read the entire text.\n",
        "2. For EACH sentence that contains a violation, create a JSON object with the exact sentence, violation type, severity, and explanation.\n",
        "3. Combine all these objects into a final list under the \"violations\" key.\n",
        "4. If, upon closer inspection, you find no specific sentences with violations, return an empty \"violations\" list.\n",
        "5. **CRITICAL JSON RULE:** Your output MUST be a single, valid JSON object. All strings inside the JSON, especially the 'sentence' and 'explanation' fields, must be correctly formatted. Properly escape any special characters like apostrophes (') or double quotes (\"). For example, write \"it didn't happen\" instead of \"it didn\"t happen\".\n",
        "\"\"\")\n",
        "\n",
        "    chain = prompt | structured_llm\n",
        "    violations = []\n",
        "\n",
        "    # FIX: Added try...except block to handle the BadRequestError gracefully\n",
        "    try:\n",
        "        result: ViolationAnalysisResult = chain.invoke({\n",
        "            \"text\": state[\"input_text\"],\n",
        "            \"context\": state[\"context\"],\n",
        "            \"summary\": merged_check[\"summary\"],\n",
        "            \"violation_types\": \", \".join(merged_check[\"violation_types\"])\n",
        "        })\n",
        "        # FIX: Replaced .dict() with .model_dump()\n",
        "        violations = [v.model_dump() for v in result.violations]\n",
        "\n",
        "    except BadRequestError as e:\n",
        "        print(f\"   - âš  CRITICAL ERROR: The LLM failed to generate valid structured JSON for detailed analysis.\")\n",
        "        print(f\"   - This is often due to unescaped characters in its output. The workflow will continue with 0 violations found.\")\n",
        "        print(f\"   - Groq Error: {e}\")\n",
        "        # Return an empty list to prevent the graph from crashing\n",
        "        violations = []\n",
        "\n",
        "    print(f\"   - Found {len(violations)} specific violations.\")\n",
        "    return {\"violations\": violations}"
      ],
      "metadata": {
        "id": "GTBgELt90oUn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Output and Summary Nodes\n",
        "def no_violations_output(state: ComplianceState) -> dict:\n",
        "    \"\"\"Generate output when no violations are detected.\"\"\"\n",
        "    merged_check = state[\"merged_check\"]\n",
        "    output = {\n",
        "        \"status\": \"compliant\",\n",
        "        \"message\": \"No violations detected\",\n",
        "        \"score\": merged_check.get(\"violation_score\", 0),\n",
        "        \"primary_score\": merged_check.get(\"primary_score\", 0),\n",
        "        \"secondary_score\": merged_check.get(\"secondary_score\", 0),\n",
        "        \"summary\": \"Text passes all compliance checks.\"\n",
        "    }\n",
        "    print(\"\\nâœ… FINAL RESULT: NO VIOLATIONS DETECTED\\n\")\n",
        "    return {\"final_output\": output}\n",
        "\n",
        "\n",
        "def generate_summary(state: ComplianceState) -> dict:\n",
        "    \"\"\"Generate comprehensive summary of all violations found.\"\"\"\n",
        "    violations = state.get(\"violations\")\n",
        "    if not violations:\n",
        "        return no_violations_output(state)\n",
        "\n",
        "    merged_check = state[\"merged_check\"]\n",
        "\n",
        "    # Group violations by severity\n",
        "    critical = [v for v in violations if v[\"severity\"] == \"critical\"]\n",
        "    high = [v for v in violations if v[\"severity\"] == \"high\"]\n",
        "    medium = [v for v in violations if v[\"severity\"] == \"medium\"]\n",
        "    low = [v for v in violations if v[\"severity\"] == \"low\"]\n",
        "\n",
        "    output = {\n",
        "        \"status\": \"violations_detected\",\n",
        "        \"overall_score\": merged_check.get(\"violation_score\", 0),\n",
        "        \"primary_score\": merged_check.get(\"primary_score\", 0),\n",
        "        \"secondary_score\": merged_check.get(\"secondary_score\", 0),\n",
        "        \"detection_confidence\": merged_check.get(\"detection_confidence\", \"unknown\"),\n",
        "        \"total_violations\": len(violations),\n",
        "        \"breakdown\": {\n",
        "            \"critical\": len(critical),\n",
        "            \"high\": len(high),\n",
        "            \"medium\": len(medium),\n",
        "            \"low\": len(low)\n",
        "        },\n",
        "        \"violations\": violations,\n",
        "        \"summary\": merged_check.get(\"summary\", \"\"),\n",
        "        \"violation_types\": merged_check.get(\"violation_types\", [])\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL COMPLIANCE REPORT\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Status: {output['status']}\")\n",
        "    print(f\"Overall Score: {output['overall_score']}\")\n",
        "    print(f\"Total Violations: {output['total_violations']}\")\n",
        "    print(f\"  Critical: {len(critical)} | High: {len(high)} | Medium: {len(medium)} | Low: {len(low)}\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    return {\"final_output\": output}"
      ],
      "metadata": {
        "id": "AkoutCLI0oSK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Build and Compile the High-Speed LangGraph Workflow\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Initialize graph\n",
        "workflow = StateGraph(ComplianceState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"retrieve_context\", retrieve_context)\n",
        "workflow.add_node(\"parallel_check\", fast_parallel_initial_check)\n",
        "workflow.add_node(\"analyze_violations\", holistic_sentence_analysis)\n",
        "workflow.add_node(\"no_violations\", no_violations_output)\n",
        "workflow.add_node(\"generate_summary\", generate_summary)\n",
        "\n",
        "# Define edges\n",
        "workflow.set_entry_point(\"retrieve_context\")\n",
        "workflow.add_edge(\"retrieve_context\", \"parallel_check\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"parallel_check\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"analyze_violations\": \"analyze_violations\",\n",
        "        \"no_violations_output\": \"no_violations\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"analyze_violations\", \"generate_summary\")\n",
        "workflow.add_edge(\"no_violations\", END)\n",
        "workflow.add_edge(\"generate_summary\", END)\n",
        "\n",
        "# Compile graph\n",
        "fast_compliance_checker = workflow.compile()"
      ],
      "metadata": {
        "id": "LAik_UYO1H7r"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test Cases\n",
        "import time\n",
        "\n",
        "# --- Test Cases ---\n",
        "test_clean = \"\"\"\n",
        "Dowry is just a normal part of Indian weddings, and everyone gives gifts so itâ€™s not really illegal. If the brideâ€™s family gives money or stuff to the groomâ€™s side, itâ€™s fine as long as no one complains. The law doesnâ€™t clearly say what counts as dowry, so people can interpret it however they want. Most dowry cases are fake and filed just to harass the husbandâ€™s family. Judges usually ignore these cases unless thereâ€™s a video or something.\n",
        "\n",
        "IPC Section 498A says that if a husband is mean, he can be arrested without any proof. Thatâ€™s why a lot of innocent men get jailed for no reason. The Dowry Act doesnâ€™t apply if the gifts are given out of love, so itâ€™s okay to give gold and cars. Police can arrest anyone accused of dowry harassment even if thereâ€™s no FIR. Courts donâ€™t need evidenceâ€”they just go with what feels right.\n",
        "\n",
        "If someone returns the dowry items, the case is automatically closed. The law says that dowry is only illegal if itâ€™s forced, so voluntary dowry is fine. Legal citations arenâ€™t really needed in dowry cases because everyone knows the rules. The judge can decide based on common sense and doesnâ€™t have to explain the verdict.\n",
        "\n",
        "However, under IPC Section 498A, cruelty related to dowry demands is a cognizable and non-bailable offense. Courts have held that mental harassment and threats are sufficient grounds for prosecution. The Supreme Court has clarified that even indirect pressure for dowry can constitute an offense.\n",
        "\n",
        "Legal writing in dowry cases must be precise, supported by evidence, and aligned with statutory definitions. The law mandates that any dowry articles received must be returned to the bride within a reasonable time. Failure to do so can result in prosecution under Section 6 of the Dowry Prohibition Act, 1961.\n",
        "\n",
        "Dowry deaths are rare and usually happen because of other reasons like accidents or depression. The law doesnâ€™t define cruelty properly, so anything can be called harassment. If the husband says sorry, the case can be withdrawn. Lawyers often skip formal language in dowry cases because itâ€™s too technical. The law changes all the time, so itâ€™s hard to keep track of whatâ€™s allowed.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "result = fast_compliance_checker.invoke({\"input_text\": test_clean})\n",
        "\n",
        "print(json.dumps(result[\"final_output\"], indent=2))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o62w7dlO1H4F",
        "outputId": "f5849e84-cd4b-4428-c30d-7b349441e1cd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TEST: CLEAN TEXT\n",
            "======================================================================\n",
            "ðŸ”Ž Retrieving context from FAISS...\n",
            "   - No retriever available. Skipping.\n",
            "\n",
            "============================================================\n",
            "ðŸš€ RUNNING FAST PARALLEL VIOLATION DETECTION (1 LLM Call)\n",
            "============================================================\n",
            "Primary Check Score: 0.90\n",
            "Secondary Check Score: 0.80\n",
            "\n",
            "ðŸ“Š Merged Score: 0.86\n",
            "   Violations Detected: True\n",
            "   Confidence: high\n",
            "\n",
            "ðŸ”€ Routing Decision: ANALYZE VIOLATIONS\n",
            "   (Score: 0.86, Threshold: 0.3)\n",
            "\n",
            "\n",
            "============================================================\n",
            "âš¡ RUNNING HOLISTIC SENTENCE-LEVEL ANALYSIS (1 LLM Call)\n",
            "============================================================\n",
            "   - Found 19 specific violations.\n",
            "\n",
            "============================================================\n",
            "FINAL COMPLIANCE REPORT\n",
            "============================================================\n",
            "Status: violations_detected\n",
            "Overall Score: 0.86\n",
            "Total Violations: 19\n",
            "  Critical: 0 | High: 0 | Medium: 0 | Low: 0\n",
            "============================================================\n",
            "\n",
            "{\n",
            "  \"status\": \"violations_detected\",\n",
            "  \"overall_score\": 0.86,\n",
            "  \"primary_score\": 0.9,\n",
            "  \"secondary_score\": 0.8,\n",
            "  \"detection_confidence\": \"high\",\n",
            "  \"total_violations\": 19,\n",
            "  \"breakdown\": {\n",
            "    \"critical\": 0,\n",
            "    \"high\": 0,\n",
            "    \"medium\": 0,\n",
            "    \"low\": 0\n",
            "  },\n",
            "  \"violations\": [\n",
            "    {\n",
            "      \"sentence\": \"Dowry is just a normal part of Indian weddings, and everyone gives gifts so it\\u2019s not really illegal.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"Dowry is a serious social issue in India, and it is not a normal part of Indian weddings. The Indian government has implemented various laws to prevent dowry-related harassment and violence.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"If the bride\\u2019s family gives money or stuff to the groom\\u2019s side, it\\u2019s fine as long as no one complains.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"Giving money or gifts to the groom\\u2019s family can be considered dowry, which is illegal in India.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"The law doesn\\u2019t clearly say what counts as dowry, so people can interpret it however they want.\",\n",
            "      \"violation_type\": \"Ambiguity\",\n",
            "      \"severity\": \"High\",\n",
            "      \"explanation\": \"The Indian law clearly defines dowry as any gift or payment given to the groom or his family at the time of marriage.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"Most dowry cases are fake and filed just to harass the husband\\u2019s family.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"Dowry cases are often real and can have serious consequences for the victims.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"Judges usually ignore these cases unless there\\u2019s a video or something.\",\n",
            "      \"violation_type\": \"Policy violations\",\n",
            "      \"severity\": \"High\",\n",
            "      \"explanation\": \"Judges are expected to consider all evidence and follow the law, not just rely on videos or other forms of evidence.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"IPC Section 498A says that if a husband is mean, he can be arrested without any proof.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"IPC Section 498A actually says that if a husband subjects his wife to cruelty, he can be arrested, not just if he is mean.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"That\\u2019s why a lot of innocent men get jailed for no reason.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"Men who are accused of dowry harassment are not always innocent, and the law requires evidence before making an arrest.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"The Dowry Act doesn\\u2019t apply if the gifts are given out of love, so it\\u2019s okay to give gold and cars.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"The Dowry Act applies to all gifts given to the groom or his family at the time of marriage, regardless of the reason.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"Police can arrest anyone accused of dowry harassment even if there\\u2019s no FIR.\",\n",
            "      \"violation_type\": \"Policy violations\",\n",
            "      \"severity\": \"High\",\n",
            "      \"explanation\": \"Police are required to follow due process and obtain an FIR before making an arrest.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"Courts don\\u2019t need evidence\\u2014they just go with what feels right.\",\n",
            "      \"violation_type\": \"Policy violations\",\n",
            "      \"severity\": \"High\",\n",
            "      \"explanation\": \"Courts are required to follow the law and consider all evidence before making a decision.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"If someone returns the dowry items, the case is automatically closed.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"Returning dowry items does not automatically close a case, and the law requires further action to resolve the issue.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"The law says that dowry is only illegal if it\\u2019s forced, so voluntary dowry is fine.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"Dowry is illegal in all cases, regardless of whether it is forced or voluntary.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"Legal writing in dowry cases must be precise, supported by evidence, and aligned with statutory definitions.\",\n",
            "      \"violation_type\": \"Policy violations\",\n",
            "      \"severity\": \"Medium\",\n",
            "      \"explanation\": \"This statement is actually true and aligns with the requirements for legal writing in dowry cases.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"The law mandates that any dowry articles received must be returned to the bride within a reasonable time.\",\n",
            "      \"violation_type\": \"Policy violations\",\n",
            "      \"severity\": \"Medium\",\n",
            "      \"explanation\": \"This statement is actually true and aligns with the requirements for dowry articles in Indian law.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"Dowry deaths are rare and usually happen because of other reasons like accidents or depression.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"Dowry deaths are a serious issue in India and can occur due to various reasons, including dowry harassment and violence.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"The law doesn\\u2019t define cruelty properly, so anything can be called harassment.\",\n",
            "      \"violation_type\": \"Ambiguity\",\n",
            "      \"severity\": \"High\",\n",
            "      \"explanation\": \"The Indian law clearly defines cruelty and harassment in the context of dowry cases.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"If the husband says sorry, the case can be withdrawn.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"A husband\\u2019s apology does not automatically withdraw a case, and the law requires further action to resolve the issue.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"Lawyers often skip formal language in dowry cases because it\\u2019s too technical.\",\n",
            "      \"violation_type\": \"Policy violations\",\n",
            "      \"severity\": \"Medium\",\n",
            "      \"explanation\": \"Lawyers are expected to use formal language and follow the requirements for legal writing in dowry cases.\"\n",
            "    },\n",
            "    {\n",
            "      \"sentence\": \"The law changes all the time, so it\\u2019s hard to keep track of what\\u2019s allowed.\",\n",
            "      \"violation_type\": \"Factual falsehoods\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"explanation\": \"The Indian law on dowry is well-established and does not change frequently.\"\n",
            "    }\n",
            "  ],\n",
            "  \"summary\": \"Critical Analysis: The text contains severe factual falsehoods and dangerous misinformation about Indian dowry laws, including incorrect interpretations of IPC Section 498A and the Dowry Act.\\nCompliance Analysis: The text contains multiple policy violations, including unprofessional language, missing citations, and ambiguity in legal interpretations.\",\n",
            "  \"violation_types\": [\n",
            "    \"Policy violations\",\n",
            "    \"Missing citations\",\n",
            "    \"Ambiguity\",\n",
            "    \"Factual falsehoods\",\n",
            "    \"Dangerous misinformation\",\n",
            "    \"Unprofessional language\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- Analysis completed in 3.16 seconds ---\n"
          ]
        }
      ]
    }
  ]
}