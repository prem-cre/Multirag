{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFW+HmTEQkik4jbUjdTaKw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prem-cre/Multirag/blob/main/citation2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "WdA0CpFHurlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38143ace-efe8-4257-bd50-c1e0c332503a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install all required libraries\n",
        "!pip install -qU langchain langgraph langchain_groq langchain_huggingface\n",
        "!pip install -qU faiss-cpu pypdf tiktoken\n",
        "!pip install -qU langchain-community\n",
        "!pip install -qU wikipedia\n",
        "!pip install -qU langchain-google-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configure API Keys, LLM, and FAISS Vector Store\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_api_key')\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "\n",
        "llm = ChatGroq(model_name=\"gemma2-9b-it\", temperature=0)\n",
        "\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "def read_documents(directory_path: str):\n",
        "    \"\"\"Loads PDF documents from a specified directory.\"\"\"\n",
        "    loader = PyPDFDirectoryLoader(directory_path)\n",
        "    documents = loader.load()\n",
        "    print(f\"Files found by PyPDFDirectoryLoader: {[doc.metadata.get('source') for doc in documents]}\") # Added print statement\n",
        "    return documents\n",
        "\n",
        "def chunk_data(docs, chunk_size=1100, chunk_overlap=70):\n",
        "    \"\"\"Splits documents into smaller chunks.\"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "    return chunks\n",
        "\n",
        "# Load, chunk, and index the documents\n",
        "print(\"Loading documents that are uploaded...\")\n",
        "docs = read_documents('/content/')\n",
        "print(f\"Documents loaded before chunking: {docs}\")\n",
        "documents = chunk_data(docs)\n",
        "print(f\"Total chunks created: {len(documents)}\")\n",
        "\n",
        "\n",
        "print(\"Creating FAISS vector store...\")\n",
        "vector_store = None # Initialize vector_store to None\n",
        "retriever = None # Initialize retriever to None\n",
        "\n",
        "if documents: # Check if the documents list is not empty\n",
        "    vector_store = FAISS.from_documents(documents, embeddings)\n",
        "    retriever = vector_store.as_retriever()\n",
        "    print(\"FAISS vector store and retriever are ready.\")\n",
        "else:\n",
        "    print(\"No documents loaded or chunked. Skipping FAISS vector store creation.\")\n",
        "\n",
        "\n",
        "# Test the retriever\n",
        "test_query = 'How does the radical separation of law and religion contribute to the integrity crisis in Western civilization, and can reintegrating their underlying values restore societal cohesion without compromising secular governance?'\n",
        "if retriever: # Check if retriever is not None before invoking\n",
        "    retrieved_docs = retriever.invoke(test_query)\n",
        "    print(retrieved_docs)\n",
        "    print(f\"\\n✅ Retriever test successful. Found {len(retrieved_docs)} related docs.\")\n",
        "    # print(retrieved_docs[0].page_content)\n",
        "else:\n",
        "    print(\"\\nSkipping retriever test as no documents were loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIE8Eyrnu0K4",
        "outputId": "27635250-3bb0-448e-c027-2b1dd03279a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading documents that are uploaded...\n",
            "Files found by PyPDFDirectoryLoader: []\n",
            "Documents loaded before chunking: []\n",
            "Total chunks created: 0\n",
            "Creating FAISS vector store...\n",
            "No documents loaded or chunked. Skipping FAISS vector store creation.\n",
            "\n",
            "Skipping retriever test as no documents were loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Real API Tools and Reranking Logic\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from langchain_core.documents import Document\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from typing import List # Import List\n",
        "\n",
        "# --- 1. Wikipedia Tool (Other APIs Stand-in) ---\n",
        "wikipedia_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_wrapper)\n",
        "\n",
        "def other_apis_call(question: str) -> List[Document]:\n",
        "    \"\"\"Calls Wikipedia API for general knowledge as a stand-in for 'Other APIs'.\"\"\"\n",
        "    print(\"---(API Call): Calling Wikipedia API---\")\n",
        "    try:\n",
        "        wiki_docs_raw = wikipedia_tool.invoke(question)\n",
        "        # WikipediaQueryRun returns a string, so we need to wrap it\n",
        "        return [Document(page_content=wiki_docs_raw, metadata={\"source\": \"Wikipedia\"})]\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling Wikipedia: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = userdata.get('GOOGLE_CSE_ID')\n",
        "google_search_wrapper = GoogleSearchAPIWrapper(k=7)\n",
        "\n",
        "def kannon_api_call(question: str) -> List[Document]:\n",
        "    \"\"\"Calls Google Search API for specialized legal search as a stand-in for 'Kannon API'.\"\"\"\n",
        "    print(\"---(API Call): Calling Google Search (Kannon API Stand-in)---\")\n",
        "    try:\n",
        "        search_results = google_search_wrapper.results(question, num_results=7)\n",
        "        docs = []\n",
        "        for res in search_results:\n",
        "            docs.append(Document(\n",
        "                page_content=f\"Title: {res.get('title', 'N/A')}\\nSnippet: {res.get('snippet', 'N/A')}\",\n",
        "                metadata={\"source\": \"Google Search\", \"link\": res.get('link', 'N/A')}\n",
        "            ))\n",
        "        return docs\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling Google Search: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- 3. Reranking Logic ---\n",
        "def semantic_rerank(query: str, documents: List[Document], top_k: int = 5) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Reranks documents based on semantic similarity to the query using embeddings.\n",
        "    Returns the top_k most relevant documents.\n",
        "    \"\"\"\n",
        "    if not documents:\n",
        "        return []\n",
        "\n",
        "    print(f\"---(Rerank): Reranking {len(documents)} documents for top {top_k}---\")\n",
        "    query_embedding = embeddings.embed_query(query)\n",
        "    doc_embeddings = embeddings.embed_documents([doc.page_content for doc in documents])\n",
        "\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    ranked_indices = np.argsort(similarities)[::-1] # Sort descending\n",
        "\n",
        "    top_k_docs = [documents[i] for i in ranked_indices[:top_k]]\n",
        "    return top_k_docs"
      ],
      "metadata": {
        "id": "fvW_iKRtwVd9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Graph State and Nodes (Updated for Real APIs and Citations)\n",
        "from typing import List, TypedDict, Dict, Any\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field # For structured output\n",
        "from langchain_core.documents import Document # Import Document\n",
        "from langchain_core.messages import HumanMessage, SystemMessage # Import message types\n",
        "\n",
        "# --- 1. DEFINE GRAPH STATE ---\n",
        "class Citation(BaseModel):\n",
        "    \"\"\"A citation for a generated legal statement.\"\"\"\n",
        "    source: str = Field(description=\"The source of the information (e.g., 'Wikipedia', 'FAISS DB', 'Google Search').\")\n",
        "    description: str = Field(description=\"A brief description of the content from the source.\")\n",
        "    link: str = Field(default=None, description=\"Optional: A URL link to the source if available.\")\n",
        "\n",
        "class GenerationWithCitations(BaseModel):\n",
        "    \"\"\"The final legal answer with supporting citations.\"\"\"\n",
        "    answer: str = Field(description=\"The comprehensive legal answer to the user's query.\")\n",
        "    citations: List[Citation] = Field(description=\"A list of relevant citations that support the answer. Provide citations for *any* factual information used from the context, even if the overall answer is that the information is not sufficient.\")\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: The user's query.\n",
        "        doc_uploaded: A boolean flag indicating if documents are part of the context.\n",
        "        documents: A list of retrieved documents (from VectorDB or APIs).\n",
        "        generation: The final, refined answer from the LLM (potentially a GenerationWithCitations object or string).\n",
        "        # Removed user_feedback\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    doc_uploaded: bool\n",
        "    documents: List[Document]\n",
        "    generation: Any # Allow for structured output or string\n",
        "\n",
        "\n",
        "# --- 2. DEFINE GRAPH NODES ---\n",
        "\n",
        "def retrieve_from_vector_db(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"Node to retrieve documents from the FAISS vector store.\"\"\"\n",
        "    print(\"---(Node): Retrieving from Vector DB---\")\n",
        "    question = state[\"question\"]\n",
        "    docs = retriever.invoke(question) # Already configured to get top 5\n",
        "    return {\"documents\": docs}\n",
        "\n",
        "def call_apis(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"Node that runs API calls and cache checks.\"\"\"\n",
        "    print(\"---(Node): Calling External APIs---\") # Updated print statement\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Run API calls in what appears as parallel (async if using actual async tools)\n",
        "    kannon_results = kannon_api_call(question)\n",
        "    other_api_results = other_apis_call(question)\n",
        "\n",
        "    all_api_docs = kannon_results + other_api_results # Removed cache_results\n",
        "    return {\"documents\": all_api_docs}\n",
        "\n",
        "\n",
        "def merge_and_rerank(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Node to merge documents from all sources and then rerank them\n",
        "    to select the top 5 most relevant.\n",
        "    \"\"\"\n",
        "\n",
        "    existing_docs = state.get(\"documents\", [])\n",
        "\n",
        "\n",
        "    question = state[\"question\"]\n",
        "    all_combined_docs = state[\"documents\"]\n",
        "\n",
        "    if not all_combined_docs:\n",
        "        print(\"No documents to rerank.\")\n",
        "        return {\"documents\": []}\n",
        "\n",
        "    # Remove duplicates if any (e.g., same content from different sources or slight variations)\n",
        "    unique_docs = {}\n",
        "    for doc in all_combined_docs:\n",
        "        # Use a hash of content to identify uniqueness, or just content itself\n",
        "        if doc.page_content not in unique_docs:\n",
        "            unique_docs[doc.page_content] = doc\n",
        "        else:\n",
        "            # If content is same, try to merge metadata, e.g., add more sources\n",
        "            existing_meta = unique_docs[doc.page_content].metadata\n",
        "            new_meta = doc.metadata\n",
        "            for key, value in new_meta.items():\n",
        "                if key not in existing_meta:\n",
        "                    existing_meta[key] = value\n",
        "                elif existing_meta[key] != value and isinstance(existing_meta[key], str):\n",
        "                    # Simple merge: append if different and string\n",
        "                    existing_meta[key] = f\"{existing_meta[key]}; {value}\"\n",
        "            unique_docs[doc.page_content].metadata = existing_meta\n",
        "\n",
        "    cleaned_docs = list(unique_docs.values())\n",
        "    print(f\"Combined {len(cleaned_docs)} unique documents before reranking.\")\n",
        "\n",
        "    # Rerank and select top 5\n",
        "    top_5_docs = semantic_rerank(question, cleaned_docs, top_k=5)\n",
        "    print(f\"Selected top {len(top_5_docs)} documents after reranking.\")\n",
        "    return {\"documents\": top_5_docs}\n",
        "\n",
        "\n",
        "def refine_with_llm(state: GraphState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Node to generate or refine the final answer with structured citations using the LLM\n",
        "    based on all retrieved context. (Removed user feedback logic)\n",
        "    \"\"\"\n",
        "    print(\"---(Node): Refining with LLM and Generating Citations---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "\n",
        "    # Format the context for the LLM, including source information for citations\n",
        "    formatted_context = []\n",
        "    for i, doc in enumerate(documents):\n",
        "        source_info = doc.metadata.get(\"source\", \"Unknown Source\")\n",
        "        link_info = doc.metadata.get(\"link\", \"No Link\")\n",
        "        formatted_context.append(\n",
        "            f\"--- Document {i+1} (Source: {source_info}, Link: {link_info}) ---\\n{doc.page_content}\"\n",
        "        )\n",
        "    context_str = \"\\n\\n\".join(formatted_context)\n",
        "\n",
        "    # Removed revision_instruction logic\n",
        "\n",
        "    # Prompt for structured output with citations\n",
        "    system_message = (\n",
        "        \"You are Lawvriksh, an expert legal AI assistant. Your task is to provide a comprehensive, \"\n",
        "        \"clear, concise, and accurate legal answer to the user's query based on the provided context. \"\n",
        "        \"I have first checked the uploaded documents for relevant information. If sufficient information was not found there, \"\n",
        "        \"I have then used external APIs (like Google Search and Wikipedia as stand-ins) to retrieve additional context. \"\n",
        "        \"Synthesize information from *all* provided context documents (which may include content from uploaded files and external API results). \"\n",
        "        \"If the combined context still does not contain enough information to fully answer the question, \"\n",
        "        \"state this clearly and explain what information is missing based *only* on the context you were provided. \"\n",
        "        \"**Crucially, you must provide supporting citations for every factual statement or piece of information you use from the provided context**, \"\n",
        "        \"even if the overall answer is that the information is not sufficient. \"\n",
        "        \"Use the format specified in the `Citation` and `GenerationWithCitations` Pydantic models. \"\n",
        "        \"Each citation must accurately reflect the source and content description from the provided documents.\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_message),\n",
        "        (\"human\", f\"Based on the following documents, answer the question '{question}':\\n\\nContext:\\n{context_str}\")\n",
        "    ])\n",
        "\n",
        "    # Chain the prompt with the LLM and its structured output method\n",
        "    chain = prompt | llm.with_structured_output(GenerationWithCitations)\n",
        "\n",
        "    # Invoke the chain\n",
        "    print(\"---(LLM Generation with Citations):---\")\n",
        "    structured_output = None # Initialize to None\n",
        "    try:\n",
        "        structured_output = chain.invoke({\"question\": question, \"context\": context_str})\n",
        "        print(\"Structured output generated successfully.\")\n",
        "        print(f\"Answer: {structured_output.answer}\")\n",
        "        print(\"Citations:\")\n",
        "        for cit in structured_output.citations:\n",
        "            print(f\"- Source: {cit.source}, Description: {cit.description}, Link: {cit.link or 'N/A'}\")\n",
        "        return {\"generation\": structured_output}\n",
        "    except Exception as e:\n",
        "        print(f\"Error during structured generation: {e}\")\n",
        "        print(\"Attempting fallback generation...\")\n",
        "        # Fallback for structured output failure - still try to include sources\n",
        "        fallback_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", f\"You are Lawvriksh. Based on the provided context, provide a concise answer to the question: '{question}'. If the context does not contain sufficient information, state this clearly. Always list the sources you used from the context at the end of your answer, referencing the Document number and its source/link.\"),\n",
        "             (\"human\", f\"Context:\\n{context_str}\\n\\nAnswer:\")\n",
        "        ])\n",
        "        fallback_chain = fallback_prompt | llm\n",
        "        fallback_response = fallback_chain.invoke({\"question\": question, \"context\": context_str})\n",
        "        print(\"---(Fallback LLM Generation):---\")\n",
        "        print(fallback_response.content)\n",
        "\n",
        "        # Attempt to parse sources from fallback response or list all provided document sources\n",
        "        fallback_sources_list = []\n",
        "        for i, doc in enumerate(documents):\n",
        "             source_info = doc.metadata.get(\"source\", \"Unknown Source\")\n",
        "             link_info = doc.metadata.get(\"link\", \"No Link\")\n",
        "             fallback_sources_list.append(f\"Document {i+1} (Source: {source_info}, Link: {link_info})\")\n",
        "\n",
        "        fallback_answer_with_sources = f\"{fallback_response.content}\\n\\nSources Used:\\n\" + \"\\n\".join(fallback_sources_list)\n",
        "\n",
        "\n",
        "        # Return a dictionary that mimics the structure or just the string with sources\n",
        "        return {\"generation\": fallback_answer_with_sources}"
      ],
      "metadata": {
        "id": "inj3g_Bi1qh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b221560-7810-4a3d-f8f7-cb0b440042b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Conditional Edges and Build the Graph (No Changes Here)\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "# --- 1. DEFINE CONDITIONAL EDGE FOR INITIAL ROUTING ---\n",
        "def route_query(state: GraphState) -> str:\n",
        "    \"\"\"\n",
        "    The main router that decides the workflow path based on whether a document\n",
        "    was part of the initial context.\n",
        "    \"\"\"\n",
        "    print(\"---(Router): Deciding initial path...---\")\n",
        "    if state[\"doc_uploaded\"]:\n",
        "        print(\"---(Router): Path -> Doc Branch (Vector DB + APIs)---\")\n",
        "        return \"doc_branch\"\n",
        "    else:\n",
        "        print(\"---(Router): Path -> No-Doc Branch (Only APIs)---\")\n",
        "        return \"no_doc_branch\"\n",
        "\n",
        "\n",
        "\n",
        "# --- 3. BUILD THE GRAPH ---\n",
        "graph_builder = StateGraph(GraphState)\n",
        "\n",
        "# Add all the nodes to the graph\n",
        "graph_builder.add_node(\"retrieve_vector_db\", retrieve_from_vector_db)\n",
        "graph_builder.add_node(\"call_apis\", call_apis)\n",
        "graph_builder.add_node(\"merge_rerank\", merge_and_rerank)\n",
        "graph_builder.add_node(\"refine_llm\", refine_with_llm)\n",
        "\n",
        "# Set the entry point router\n",
        "graph_builder.add_conditional_edges(\n",
        "    START,\n",
        "    route_query,\n",
        "    {\n",
        "        \"doc_branch\": \"retrieve_vector_db\",\n",
        "        \"no_doc_branch\": \"call_apis\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Connect the nodes for the 'Doc Branch'\n",
        "graph_builder.add_edge(\"retrieve_vector_db\", \"call_apis\")\n",
        "graph_builder.add_edge(\"call_apis\", \"merge_rerank\")\n",
        "graph_builder.add_edge(\"merge_rerank\", \"refine_llm\")\n",
        "graph_builder.add_edge(\"refine_llm\", END)\n",
        "\n",
        "\n",
        "# Compile the graph\n",
        "app = graph_builder.compile()\n",
        "\n",
        "# Visualize the graph\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Could not generate graph visualization: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "ZwRssc5x14CO",
        "outputId": "1c3e5ca8-3caa-4ac4-fc1f-a825ca23c8e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run Scenario 1: Doc Branch with Human-in-Loop\n",
        "from pprint import pprint\n",
        "\n",
        "# Input for the graph\n",
        "inputs_doc_branch = {\n",
        "    \"question\": \"How does the radical separation of law and religion contribute to the integrity crisis in Western civilization, and can reintegrating their underlying values restore societal cohesion without compromising secular governance?.\",\n",
        "    \"doc_uploaded\": True\n",
        "}\n",
        "\n",
        "print(\"Checking uploaded documents...\")\n",
        "print(\"If the answer is not found in the uploaded documents, I will fetch data by calling an API and provide results based on the LLM.\")\n",
        "\n",
        "print(\"\\n--- Running Scenario 1: Doc Branch (FAISS + APIs) ---\\n\")\n",
        "final_state_doc_branch = app.invoke(inputs_doc_branch, {\"recursion_limit\": 10})\n",
        "\n",
        "print(\"\\n\\n--- FINAL GENERATION (Doc Branch) ---\")\n",
        "if isinstance(final_state_doc_branch.get('generation'), GenerationWithCitations):\n",
        "    pprint(f\"Answer: {final_state_doc_branch['generation'].answer}\")\n",
        "    print(\"\\nCitations:\")\n",
        "    for citation in final_state_doc_branch['generation'].citations:\n",
        "        pprint(f\"- Source: {citation.source}, Description: {citation.description}, Link: {citation.link or 'N/A'}\")\n",
        "else:\n",
        "    pprint(final_state_doc_branch.get('generation'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "adnsIBac1-YM",
        "outputId": "da284528-22f7-424d-a756-9c26e59ed6e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking uploaded documents...\n",
            "If the answer is not found in the uploaded documents, I will fetch data by calling an API and provide results based on the LLM.\n",
            "\n",
            "--- Running Scenario 1: Doc Branch (FAISS + APIs) ---\n",
            "\n",
            "---(Router): Deciding initial path...---\n",
            "---(Router): Path -> Doc Branch (Vector DB + APIs)---\n",
            "---(Node): Retrieving from Vector DB---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'invoke'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2565084826.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Running Scenario 1: Doc Branch (FAISS + APIs) ---\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mfinal_state_doc_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_doc_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"recursion_limit\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n--- FINAL GENERATION (Doc Branch) ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   3027\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2648\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4238519875.py\u001b[0m in \u001b[0;36mretrieve_from_vector_db\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---(Node): Retrieving from Vector DB---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Already configured to get top 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"documents\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'invoke'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run Scenario 2: No-Doc Branch\n",
        "from pprint import pprint\n",
        "\n",
        "# Input for the graph\n",
        "inputs_no_doc_branch = {\n",
        "    \"question\": \"How does the radical separation of law and religion contribute to the integrity crisis in Western civilization, and can reintegrating their underlying values restore societal cohesion without compromising secular governance?\",\n",
        "    \"doc_uploaded\": False\n",
        "}\n",
        "\n",
        "print(\"\\n--- Running Scenario 2: No-Doc Branch (APIs only) ---\\n\")\n",
        "final_state_no_doc_branch = app.invoke(inputs_no_doc_branch, {\"recursion_limit\": 10})\n",
        "\n",
        "print(\"\\n\\n--- FINAL GENERATION (No-Doc Branch) ---\")\n",
        "if isinstance(final_state_no_doc_branch.get('generation'), GenerationWithCitations):\n",
        "    pprint(f\"Answer: {final_state_no_doc_branch['generation'].answer}\")\n",
        "    print(\"\\nCitations:\")\n",
        "    for citation in final_state_no_doc_branch['generation'].citations:\n",
        "        pprint(f\"- Source: {citation.source}, Description: {citation.description}, Link: {citation.link or 'N/A'}\")\n",
        "else:\n",
        "    pprint(final_state_no_doc_branch.get('generation'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0L-Knju-kp0",
        "outputId": "79d5bda9-065f-4bb4-86a5-af2319d74ba3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Scenario 2: No-Doc Branch (APIs only) ---\n",
            "\n",
            "---(Router): Deciding initial path...---\n",
            "---(Router): Path -> No-Doc Branch (Only APIs)---\n",
            "---(Node): Calling External APIs---\n",
            "---(API Call): Calling Google Search (Kannon API Stand-in)---\n",
            "---(API Call): Calling Wikipedia API---\n",
            "Combined 8 unique documents before reranking.\n",
            "---(Rerank): Reranking 8 documents for top 5---\n",
            "Selected top 5 documents after reranking.\n",
            "---(Node): Refining with LLM and Generating Citations---\n",
            "---(LLM Generation with Citations):---\n",
            "Structured output generated successfully.\n",
            "Answer: The provided documents do not contain sufficient information to answer the question about the radical separation of law and religion, its contribution to the integrity crisis in Western civilization, and the potential for reintegration to restore societal cohesion without compromising secular governance.\n",
            "Citations:\n",
            "\n",
            "\n",
            "--- FINAL GENERATION (No-Doc Branch) ---\n",
            "('Answer: The provided documents do not contain sufficient information to '\n",
            " 'answer the question about the radical separation of law and religion, its '\n",
            " 'contribution to the integrity crisis in Western civilization, and the '\n",
            " 'potential for reintegration to restore societal cohesion without '\n",
            " 'compromising secular governance.')\n",
            "\n",
            "Citations:\n"
          ]
        }
      ]
    }
  ]
}